diff --git a/blob/src/main/java/io/crate/blob/BlobTransferTarget.java b/blob/src/main/java/io/crate/blob/BlobTransferTarget.java
index 66c0a64..d72c465 100644
--- a/blob/src/main/java/io/crate/blob/BlobTransferTarget.java
+++ b/blob/src/main/java/io/crate/blob/BlobTransferTarget.java
@@ -169,18 +169,17 @@ public class BlobTransferTarget {
         String senderNodeId = nodes.getLocalNodeId();
 
         BlobTransferInfoResponse transferInfoResponse =
-            (BlobTransferInfoResponse) transportService.submitRequest(
+            (BlobTransferInfoResponse) TransportRequestOptions.EMPTY.submitRequest(
                 recipientNodeId,
                 BlobHeadRequestHandler.Actions.GET_TRANSFER_INFO,
                 new BlobInfoRequest(senderNodeId, request.transferId),
-                TransportRequestOptions.EMPTY,
                 new FutureTransportResponseHandler<TransportResponse>() {
                     @Override
                     public TransportResponse read(StreamInput in) throws IOException {
                         return new BlobTransferInfoResponse(in);
                     }
-                }
-            ).txGet();
+                },
+                transportService).txGet();
 
         BlobShard blobShard = blobIndicesService.blobShardSafe(request.shardId());
 
@@ -197,13 +196,12 @@ public class BlobTransferTarget {
             transferInfoResponse.digest, request.transferId
         );
 
-        transportService.submitRequest(
+        TransportRequestOptions.EMPTY.submitRequest(
             recipientNodeId,
             BlobHeadRequestHandler.Actions.GET_BLOB_HEAD,
             new GetBlobHeadRequest(senderNodeId, request.transferId(), request.currentPos),
-            TransportRequestOptions.EMPTY,
-            EmptyTransportResponseHandler.INSTANCE_SAME
-        ).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME,
+            transportService).txGet();
         return status;
     }
 
diff --git a/blob/src/main/java/io/crate/blob/recovery/BlobRecoveryHandler.java b/blob/src/main/java/io/crate/blob/recovery/BlobRecoveryHandler.java
index 4e19b52..3f7ddbc 100644
--- a/blob/src/main/java/io/crate/blob/recovery/BlobRecoveryHandler.java
+++ b/blob/src/main/java/io/crate/blob/recovery/BlobRecoveryHandler.java
@@ -99,19 +99,18 @@ public class BlobRecoveryHandler extends RecoverySourceHandler {
 
     private Set<BytesArray> getExistingDigestsFromTarget(byte prefix) {
         BlobStartPrefixResponse response =
-            (BlobStartPrefixResponse) transportService.submitRequest(
+            (BlobStartPrefixResponse) TransportRequestOptions.EMPTY.submitRequest(
                 request.targetNode(),
                 BlobRecoveryTarget.Actions.START_PREFIX,
                 new BlobStartPrefixSyncRequest(request.recoveryId(), request.shardId(), prefix),
-                TransportRequestOptions.EMPTY,
                 new FutureTransportResponseHandler<TransportResponse>() {
 
                     @Override
                     public TransportResponse read(StreamInput in) throws IOException {
                         return new BlobStartPrefixResponse(in);
                     }
-                }
-            ).txGet();
+                },
+                transportService).txGet();
 
         Set<BytesArray> result = new HashSet<>();
         for (byte[] digests : response.existingDigests) {
@@ -205,31 +204,28 @@ public class BlobRecoveryHandler extends RecoverySourceHandler {
     }
 
     private void deleteFilesRequest(BytesArray[] digests) {
-        transportService.submitRequest(
+        TransportRequestOptions.EMPTY.submitRequest(
             request.targetNode(),
             BlobRecoveryTarget.Actions.DELETE_FILE,
             new BlobRecoveryDeleteRequest(request.recoveryId(), digests),
-            TransportRequestOptions.EMPTY,
-            EmptyTransportResponseHandler.INSTANCE_SAME
-        ).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME,
+            transportService).txGet();
     }
 
     private void sendFinalizeRecoveryRequest() {
-        transportService.submitRequest(request.targetNode(),
+        TransportRequestOptions.EMPTY.submitRequest(request.targetNode(),
             BlobRecoveryTarget.Actions.FINALIZE_RECOVERY,
             new BlobFinalizeRecoveryRequest(request.recoveryId()),
-            TransportRequestOptions.EMPTY,
-            EmptyTransportResponseHandler.INSTANCE_SAME
-        ).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME,
+            transportService).txGet();
     }
 
     private void sendStartRecoveryRequest() {
-        transportService.submitRequest(request.targetNode(),
+        TransportRequestOptions.EMPTY.submitRequest(request.targetNode(),
             BlobRecoveryTarget.Actions.START_RECOVERY,
             new BlobStartRecoveryRequest(request.recoveryId(), request.shardId()),
-            TransportRequestOptions.EMPTY,
-            EmptyTransportResponseHandler.INSTANCE_SAME
-        ).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME,
+            transportService).txGet();
     }
 
     private class TransferFileRunnable implements CancellableThreads.Interruptable {
@@ -280,13 +276,12 @@ public class BlobRecoveryHandler extends RecoverySourceHandler {
                             relPath,
                             fileSize
                         );
-                        transportService.submitRequest(
+                        TransportRequestOptions.EMPTY.submitRequest(
                             request.targetNode(),
                             BlobRecoveryTarget.Actions.START_TRANSFER,
                             startTransferRequest,
-                            TransportRequestOptions.EMPTY,
-                            EmptyTransportResponseHandler.INSTANCE_SAME
-                        ).txGet();
+                            EmptyTransportResponseHandler.INSTANCE_SAME,
+                            transportService).txGet();
 
                         boolean isLast = false;
                         boolean sentChunks = false;
@@ -303,24 +298,22 @@ public class BlobRecoveryHandler extends RecoverySourceHandler {
                             }
                             content = new BytesArray(buf, 0, bytesRead);
 
-                            transportService.submitRequest(request.targetNode(),
+                            TransportRequestOptions.EMPTY.submitRequest(request.targetNode(),
                                 BlobRecoveryTarget.Actions.TRANSFER_CHUNK,
                                 new BlobRecoveryChunkRequest(request.recoveryId(),
                                     startTransferRequest.transferId(), content, isLast),
-                                TransportRequestOptions.EMPTY,
-                                EmptyTransportResponseHandler.INSTANCE_SAME
-                            ).txGet();
+                                EmptyTransportResponseHandler.INSTANCE_SAME,
+                                transportService).txGet();
                         }
 
                         if (!isLast && sentChunks) {
                             logger.error("Sending isLast because it wasn't sent before for {}", relPath);
-                            transportService.submitRequest(request.targetNode(),
+                            TransportRequestOptions.EMPTY.submitRequest(request.targetNode(),
                                 BlobRecoveryTarget.Actions.TRANSFER_CHUNK,
                                 new BlobRecoveryChunkRequest(request.recoveryId(),
                                     startTransferRequest.transferId(), BytesArray.EMPTY, true),
-                                TransportRequestOptions.EMPTY,
-                                EmptyTransportResponseHandler.INSTANCE_SAME
-                            ).txGet();
+                                EmptyTransportResponseHandler.INSTANCE_SAME,
+                                transportService).txGet();
                         }
                     }
 
diff --git a/blob/src/main/java/io/crate/blob/transfer/PutHeadChunkRunnable.java b/blob/src/main/java/io/crate/blob/transfer/PutHeadChunkRunnable.java
index de07b87..057f2cb 100644
--- a/blob/src/main/java/io/crate/blob/transfer/PutHeadChunkRunnable.java
+++ b/blob/src/main/java/io/crate/blob/transfer/PutHeadChunkRunnable.java
@@ -109,13 +109,12 @@ public class PutHeadChunkRunnable implements Runnable {
                 }
                 remainingBytes -= bytesRead;
 
-                transportService.submitRequest(
+                TransportRequestOptions.EMPTY.submitRequest(
                     recipientNode,
                     BlobHeadRequestHandler.Actions.PUT_BLOB_HEAD_CHUNK,
                     new PutBlobHeadChunkRequest(transferId, new BytesArray(buffer, 0, bytesRead)),
-                    TransportRequestOptions.EMPTY,
-                    EmptyTransportResponseHandler.INSTANCE_SAME
-                ).txGet();
+                    EmptyTransportResponseHandler.INSTANCE_SAME,
+                    transportService).txGet();
             }
 
         } catch (IOException ex) {
diff --git a/blob/src/test/java/io/crate/BlobHeadRequestHandlerTests.java b/blob/src/test/java/io/crate/BlobHeadRequestHandlerTests.java
index 6761731..1587201 100644
--- a/blob/src/test/java/io/crate/BlobHeadRequestHandlerTests.java
+++ b/blob/src/test/java/io/crate/BlobHeadRequestHandlerTests.java
@@ -87,24 +87,22 @@ public class BlobHeadRequestHandlerTests extends CrateUnitTest {
                 @SuppressWarnings("unchecked")
                 TransportFuture<TransportResponse.Empty> result = mock(TransportFuture.class);
 
-                when(transportService.submitRequest(
+                when(any(TransportRequestOptions.class).submitRequest(
                     eq(discoveryNode),
                     eq(BlobHeadRequestHandler.Actions.PUT_BLOB_HEAD_CHUNK),
                     any(TransportRequest.class),
-                    any(TransportRequestOptions.class),
-                    eq(EmptyTransportResponseHandler.INSTANCE_SAME)
-                )).thenReturn(result);
+                    eq(EmptyTransportResponseHandler.INSTANCE_SAME),
+                    transportService)).thenReturn(result);
 
                 runnable.run();
 
                 verify(blobTransferTarget).putHeadChunkTransferFinished(transferId);
-                verify(transportService, times(2)).submitRequest(
+                any(TransportRequestOptions.class).submitRequest(
                     eq(discoveryNode),
                     eq(BlobHeadRequestHandler.Actions.PUT_BLOB_HEAD_CHUNK),
                     any(TransportRequest.class),
-                    any(TransportRequestOptions.class),
-                    eq(EmptyTransportResponseHandler.INSTANCE_SAME)
-                );
+                    eq(EmptyTransportResponseHandler.INSTANCE_SAME),
+                    verify(transportService, times(2)));
             } finally {
                 scheduledExecutor.awaitTermination(1, TimeUnit.SECONDS);
                 scheduledExecutor.shutdownNow();
@@ -136,13 +134,12 @@ public class BlobHeadRequestHandlerTests extends CrateUnitTest {
 
         @SuppressWarnings("unchecked")
         TransportFuture<TransportResponse.Empty> result = mock(TransportFuture.class);
-        when(transportService.submitRequest(
+        when(any(TransportRequestOptions.class).submitRequest(
             eq(discoveryNode),
             eq(BlobHeadRequestHandler.Actions.PUT_BLOB_HEAD_CHUNK),
             any(TransportRequest.class),
-            any(TransportRequestOptions.class),
-            eq(EmptyTransportResponseHandler.INSTANCE_SAME)
-        )).thenReturn(result);
+            eq(EmptyTransportResponseHandler.INSTANCE_SAME),
+            transportService)).thenReturn(result);
 
         runnable.run();
         verify(digestBlob).getContainerFile();
diff --git a/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageService.java b/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageService.java
index 01d9e24..ebd4daf 100644
--- a/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageService.java
+++ b/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageService.java
@@ -21,7 +21,6 @@ package org.elasticsearch.repositories.azure;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.microsoft.azure.storage.AccessCondition;
-import com.microsoft.azure.storage.CloudStorageAccount;
 import com.microsoft.azure.storage.OperationContext;
 import com.microsoft.azure.storage.RetryExponentialRetry;
 import com.microsoft.azure.storage.RetryPolicy;
@@ -90,7 +89,7 @@ public class AzureStorageService {
     }
 
     protected CloudBlobClient buildClient(AzureStorageSettings azureStorageSettings) throws InvalidKeyException, URISyntaxException {
-        final CloudBlobClient client = createClient(azureStorageSettings);
+        final CloudBlobClient client = azureStorageSettings.createClient(this);
         // Set timeout option if the user sets cloud.azure.storage.timeout or
         // cloud.azure.storage.xxx.timeout (it's negative by default)
         final long timeout = azureStorageSettings.getTimeout().getMillis();
@@ -107,11 +106,6 @@ public class AzureStorageService {
         return client;
     }
 
-    protected CloudBlobClient createClient(AzureStorageSettings azureStorageSettings) throws InvalidKeyException, URISyntaxException {
-        final String connectionString = azureStorageSettings.buildConnectionString();
-        return CloudStorageAccount.parse(connectionString).createCloudBlobClient();
-    }
-
     protected OperationContext buildOperationContext(AzureStorageSettings azureStorageSettings) {
         final OperationContext context = new OperationContext();
         context.setProxy(azureStorageSettings.getProxy());
diff --git a/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageSettings.java b/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageSettings.java
index 560b06e..3942b64 100644
--- a/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageSettings.java
+++ b/es/es-repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureStorageSettings.java
@@ -19,7 +19,9 @@
 
 package org.elasticsearch.repositories.azure;
 
+import com.microsoft.azure.storage.CloudStorageAccount;
 import com.microsoft.azure.storage.LocationMode;
+import com.microsoft.azure.storage.blob.CloudBlobClient;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.settings.SecureString;
 import org.elasticsearch.common.settings.Setting;
@@ -27,10 +29,8 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.SettingsException;
 import org.elasticsearch.common.unit.TimeValue;
 
-import java.net.InetAddress;
-import java.net.InetSocketAddress;
-import java.net.Proxy;
-import java.net.UnknownHostException;
+import java.net.*;
+import java.security.InvalidKeyException;
 
 public final class AzureStorageSettings {
 
@@ -174,4 +174,9 @@ public final class AzureStorageSettings {
                ", locationMode='" + locationMode + '\'' +
                '}';
     }
+
+    public CloudBlobClient createClient(AzureStorageService azureStorageService) throws InvalidKeyException, URISyntaxException {
+        final String connectionString = buildConnectionString();
+        return CloudStorageAccount.parse(connectionString).createCloudBlobClient();
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/Version.java b/es/es-server/src/main/java/org/elasticsearch/Version.java
index 1d8a2fe..34de920 100644
--- a/es/es-server/src/main/java/org/elasticsearch/Version.java
+++ b/es/es-server/src/main/java/org/elasticsearch/Version.java
@@ -25,6 +25,7 @@ import org.elasticsearch.common.SuppressForbidden;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.settings.SettingsException;
 import org.elasticsearch.common.xcontent.ToXContentFragment;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.monitor.jvm.JvmInfo;
@@ -358,6 +359,23 @@ public class Version implements Comparable<Version>, ToXContentFragment {
         return versions;
     }
 
+    /**
+     * Returns a parsed version.
+     * @param setting
+     * @param settings
+     */
+    public Version getAsVersion(String setting, Settings settings) throws SettingsException {
+        String sValue = settings.get(setting);
+        if (sValue == null) {
+            return this;
+        }
+        try {
+            return fromId(Integer.parseInt(sValue));
+        } catch (Exception e) {
+            throw new SettingsException("Failed to parse version setting [" + setting + "] with value [" + sValue + "]", e);
+        }
+    }
+
     public enum Property {
         CREATED,
         UPGRADED;
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequest.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequest.java
index f19a3b0..eb0886b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequest.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequest.java
@@ -22,7 +22,6 @@ import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.support.master.MasterNodeRequest;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.coordination.CoordinationMetaData.VotingConfigExclusion;
-import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -31,7 +30,6 @@ import org.elasticsearch.common.unit.TimeValue;
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.Set;
-import java.util.stream.Collectors;
 
 /**
  * A request to add voting config exclusions for certain master-eligible nodes, and wait for these nodes to be removed from the voting
@@ -70,23 +68,9 @@ public class AddVotingConfigExclusionsRequest extends MasterNodeRequest<AddVotin
         timeout = in.readTimeValue();
     }
 
-    Set<VotingConfigExclusion> resolveVotingConfigExclusions(ClusterState currentState) {
-        final DiscoveryNodes allNodes = currentState.nodes();
-        final Set<VotingConfigExclusion> resolvedNodes = Arrays.stream(allNodes.resolveNodes(nodeDescriptions))
-                .map(allNodes::get).filter(DiscoveryNode::isMasterNode).map(VotingConfigExclusion::new).collect(Collectors.toSet());
-
-        if (resolvedNodes.isEmpty()) {
-            throw new IllegalArgumentException("add voting config exclusions request for " + Arrays.asList(nodeDescriptions)
-                + " matched no master-eligible nodes");
-        }
-
-        resolvedNodes.removeIf(n -> currentState.getVotingConfigExclusions().contains(n));
-        return resolvedNodes;
-    }
-
     Set<VotingConfigExclusion> resolveVotingConfigExclusionsAndCheckMaximum(ClusterState currentState, int maxExclusionsCount,
                                                                             String maximumSettingKey) {
-        final Set<VotingConfigExclusion> resolvedExclusions = resolveVotingConfigExclusions(currentState);
+        final Set<VotingConfigExclusion> resolvedExclusions = currentState.resolveVotingConfigExclusions(this);
 
         final int oldExclusionsCount = currentState.getVotingConfigExclusions().size();
         final int newExclusionsCount = resolvedExclusions.size();
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/TransportGetSnapshotsAction.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/TransportGetSnapshotsAction.java
index 5c89f85..fa0dee4 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/TransportGetSnapshotsAction.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/TransportGetSnapshotsAction.java
@@ -29,7 +29,6 @@ import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.regex.Regex;
-import org.elasticsearch.repositories.IndexId;
 import org.elasticsearch.repositories.RepositoryData;
 import org.elasticsearch.snapshots.SnapshotId;
 import org.elasticsearch.snapshots.SnapshotInfo;
@@ -138,7 +137,7 @@ public class TransportGetSnapshotsAction extends TransportMasterNodeAction<GetSn
             } else {
                 if (repositoryData != null) {
                     // want non-current snapshots as well, which are found in the repository data
-                    snapshotInfos = buildSimpleSnapshotInfos(toResolve, repositoryData, currentSnapshots);
+                    snapshotInfos = repositoryData.buildSimpleSnapshotInfos(toResolve, currentSnapshots, this);
                 } else {
                     // only want current snapshots
                     snapshotInfos = currentSnapshots.stream().map(SnapshotInfo::basic).collect(Collectors.toList());
@@ -159,31 +158,4 @@ public class TransportGetSnapshotsAction extends TransportMasterNodeAction<GetSn
         return (snapshots.length == 1 && GetSnapshotsRequest.CURRENT_SNAPSHOT.equalsIgnoreCase(snapshots[0]));
     }
 
-    private List<SnapshotInfo> buildSimpleSnapshotInfos(final Set<SnapshotId> toResolve,
-                                                        final RepositoryData repositoryData,
-                                                        final List<SnapshotInfo> currentSnapshots) {
-        List<SnapshotInfo> snapshotInfos = new ArrayList<>();
-        for (SnapshotInfo snapshotInfo : currentSnapshots) {
-            if (toResolve.remove(snapshotInfo.snapshotId())) {
-                snapshotInfos.add(snapshotInfo.basic());
-            }
-        }
-        Map<SnapshotId, List<String>> snapshotsToIndices = new HashMap<>();
-        for (IndexId indexId : repositoryData.getIndices().values()) {
-            for (SnapshotId snapshotId : repositoryData.getSnapshots(indexId)) {
-                if (toResolve.contains(snapshotId)) {
-                    snapshotsToIndices.computeIfAbsent(snapshotId, (k) -> new ArrayList<>())
-                                      .add(indexId.getName());
-                }
-            }
-        }
-        for (Map.Entry<SnapshotId, List<String>> entry : snapshotsToIndices.entrySet()) {
-            final List<String> indices = entry.getValue();
-            CollectionUtil.timSort(indices);
-            final SnapshotId snapshotId = entry.getKey();
-            snapshotInfos.add(new SnapshotInfo(snapshotId, indices, repositoryData.getSnapshotState(snapshotId)));
-        }
-        CollectionUtil.timSort(snapshotInfos);
-        return Collections.unmodifiableList(snapshotInfos);
-    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/alias/Alias.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/alias/Alias.java
index 75ac6db..202414d 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/alias/Alias.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/alias/Alias.java
@@ -21,6 +21,7 @@ package org.elasticsearch.action.admin.indices.alias;
 
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.Version;
+import org.elasticsearch.action.admin.indices.template.put.PutIndexTemplateRequest;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
@@ -277,4 +278,15 @@ public class Alias implements Streamable, ToXContentFragment {
     public int hashCode() {
         return name != null ? name.hashCode() : 0;
     }
+
+    /**
+     * Adds an alias that will be added when the index gets created.
+     *
+     *
+     * @param putIndexTemplateRequest@return  the index template creation request
+     */
+    public PutIndexTemplateRequest alias(PutIndexTemplateRequest putIndexTemplateRequest) {
+        putIndexTemplateRequest.aliases().add(this);
+        return putIndexTemplateRequest;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java
index 1cec858..b836dab 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java
@@ -48,7 +48,6 @@ import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
 import java.io.InputStream;
-import java.io.UncheckedIOException;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
@@ -207,27 +206,7 @@ public class CreateIndexRequest extends AcknowledgedRequest<CreateIndexRequest>
      * @param xContentType The content type of the source
      */
     public CreateIndexRequest mapping(String type, String source, XContentType xContentType) {
-        return mapping(type, new BytesArray(source), xContentType);
-    }
-
-    /**
-     * Adds mapping that will be added when the index gets created.
-     *
-     * @param type   The mapping type
-     * @param source The mapping source
-     * @param xContentType the content type of the mapping source
-     */
-    private CreateIndexRequest mapping(String type, BytesReference source, XContentType xContentType) {
-        if (mappings.containsKey(type)) {
-            throw new IllegalStateException("mappings for type \"" + type + "\" were already defined");
-        }
-        Objects.requireNonNull(xContentType);
-        try {
-            mappings.put(type, XContentHelper.convertToJson(source, false, false, xContentType));
-            return this;
-        } catch (IOException e) {
-            throw new UncheckedIOException("failed to convert to json", e);
-        }
+        return new BytesArray(source).mapping(type, xContentType, this);
     }
 
     /**
@@ -245,7 +224,7 @@ public class CreateIndexRequest extends AcknowledgedRequest<CreateIndexRequest>
      * @param source The mapping source
      */
     public CreateIndexRequest mapping(String type, XContentBuilder source) {
-        return mapping(type, BytesReference.bytes(source), source.contentType());
+        return BytesReference.bytes(source).mapping(type, source.contentType(), this);
     }
 
     /**
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequest.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequest.java
index 006b41b..8cbbccb 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequest.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequest.java
@@ -135,30 +135,12 @@ public class ResizeRequest extends AcknowledgedRequest<ResizeRequest> implements
     }
 
     /**
-     * Sets the number of shard copies that should be active for creation of the
-     * new shrunken index to return. Defaults to {@link ActiveShardCount#DEFAULT}, which will
-     * wait for one shard copy (the primary) to become active. Set this value to
-     * {@link ActiveShardCount#ALL} to wait for all shards (primary and all replicas) to be active
-     * before returning. Otherwise, use {@link ActiveShardCount#from(int)} to set this value to any
-     * non-negative integer, up to the number of copies per shard (number of replicas + 1),
-     * to wait for the desired amount of shard copies to become active before returning.
-     * Index creation will only wait up until the timeout value for the number of shard copies
-     * to be active before returning.  Check {@link ResizeResponse#isShardsAcknowledged()} to
-     * determine if the requisite shard copies were all started before returning or timing out.
-     *
-     * @param waitForActiveShards number of active shard copies to wait on
-     */
-    public void setWaitForActiveShards(ActiveShardCount waitForActiveShards) {
-        this.getTargetIndexRequest().waitForActiveShards(waitForActiveShards);
-    }
-
-    /**
-     * A shortcut for {@link #setWaitForActiveShards(ActiveShardCount)} where the numerical
+     * A shortcut for {@link ActiveShardCount#setWaitForActiveShards(ResizeRequest)} where the numerical
      * shard count is passed in, instead of having to first call {@link ActiveShardCount#from(int)}
      * to get the ActiveShardCount.
      */
     public void setWaitForActiveShards(final int waitForActiveShards) {
-        setWaitForActiveShards(ActiveShardCount.from(waitForActiveShards));
+        ActiveShardCount.from(waitForActiveShards).setWaitForActiveShards(this);
     }
 
     /**
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequestBuilder.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequestBuilder.java
index 4443dfd..74a4270 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequestBuilder.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/shrink/ResizeRequestBuilder.java
@@ -62,7 +62,7 @@ public class ResizeRequestBuilder extends AcknowledgedRequestBuilder<ResizeReque
      * @param waitForActiveShards number of active shard copies to wait on
      */
     public ResizeRequestBuilder setWaitForActiveShards(ActiveShardCount waitForActiveShards) {
-        this.request.setWaitForActiveShards(waitForActiveShards);
+        waitForActiveShards.setWaitForActiveShards(this.request);
         return this;
     }
 
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java
index 3fabe68..7dcb887 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java
@@ -415,7 +415,7 @@ public class PutIndexTemplateRequest extends MasterNodeRequest<PutIndexTemplateR
             //move to the first alias
             parser.nextToken();
             while ((parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-                alias(Alias.fromXContent(parser));
+                Alias.fromXContent(parser).alias(this);
             }
             return this;
         } catch(IOException e) {
@@ -423,17 +423,6 @@ public class PutIndexTemplateRequest extends MasterNodeRequest<PutIndexTemplateR
         }
     }
 
-    /**
-     * Adds an alias that will be added when the index gets created.
-     *
-     * @param alias   The metadata for the new alias
-     * @return  the index template creation request
-     */
-    public PutIndexTemplateRequest alias(Alias alias) {
-        aliases.add(alias);
-        return this;
-    }
-
     @Override
     public String[] indices() {
         return indexPatterns.toArray(new String[indexPatterns.size()]);
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequestBuilder.java b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequestBuilder.java
index dac240d..514e0d9 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequestBuilder.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequestBuilder.java
@@ -177,7 +177,7 @@ public class PutIndexTemplateRequestBuilder
      * @return the request builder
      */
     public PutIndexTemplateRequestBuilder addAlias(Alias alias) {
-        request.alias(alias);
+        alias.alias(request);
         return this;
     }
 
diff --git a/es/es-server/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java b/es/es-server/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java
index 353ec3d..37e41dd 100644
--- a/es/es-server/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java
+++ b/es/es-server/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java
@@ -20,6 +20,8 @@
 package org.elasticsearch.action.support;
 
 import com.carrotsearch.hppc.cursors.IntObjectCursor;
+import org.elasticsearch.action.admin.indices.shrink.ResizeRequest;
+import org.elasticsearch.action.admin.indices.shrink.ResizeResponse;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.routing.IndexRoutingTable;
@@ -221,4 +223,21 @@ public final class ActiveShardCount implements Writeable {
         }
     }
 
+    /**
+     * Sets the number of shard copies that should be active for creation of the
+     * new shrunken index to return. Defaults to {@link ActiveShardCount#DEFAULT}, which will
+     * wait for one shard copy (the primary) to become active. Set this value to
+     * {@link ActiveShardCount#ALL} to wait for all shards (primary and all replicas) to be active
+     * before returning. Otherwise, use {@link ActiveShardCount#from(int)} to set this value to any
+     * non-negative integer, up to the number of copies per shard (number of replicas + 1),
+     * to wait for the desired amount of shard copies to become active before returning.
+     * Index creation will only wait up until the timeout value for the number of shard copies
+     * to be active before returning.  Check {@link ResizeResponse#isShardsAcknowledged()} to
+     * determine if the requisite shard copies were all started before returning or timing out.
+     *
+     * @param resizeRequest
+     */
+    public void setWaitForActiveShards(ResizeRequest resizeRequest) {
+        resizeRequest.getTargetIndexRequest().waitForActiveShards(this);
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/ClusterState.java b/es/es-server/src/main/java/org/elasticsearch/cluster/ClusterState.java
index 580cf23..d9d2dc7 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/ClusterState.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/ClusterState.java
@@ -22,6 +22,7 @@ package org.elasticsearch.cluster;
 import com.carrotsearch.hppc.cursors.IntObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
+import org.elasticsearch.action.admin.cluster.configuration.AddVotingConfigExclusionsRequest;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.cluster.coordination.CoordinationMetaData;
@@ -59,12 +60,8 @@ import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.discovery.Discovery;
 
 import java.io.IOException;
-import java.util.EnumSet;
-import java.util.HashMap;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Optional;
-import java.util.Set;
+import java.util.*;
+import java.util.stream.Collectors;
 
 /**
  * Represents the current state of the cluster.
@@ -92,6 +89,20 @@ public class ClusterState implements ToXContentFragment, Diffable<ClusterState>
 
     public static final ClusterState EMPTY_STATE = builder(ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).build();
 
+    public Set<VotingConfigExclusion> resolveVotingConfigExclusions(AddVotingConfigExclusionsRequest addVotingConfigExclusionsRequest) {
+        final DiscoveryNodes allNodes = nodes();
+        final Set<VotingConfigExclusion> resolvedNodes = Arrays.stream(allNodes.resolveNodes(addVotingConfigExclusionsRequest.getNodeDescriptions()))
+                .map(allNodes::get).filter(DiscoveryNode::isMasterNode).map(VotingConfigExclusion::new).collect(Collectors.toSet());
+
+        if (resolvedNodes.isEmpty()) {
+            throw new IllegalArgumentException("add voting config exclusions request for " + Arrays.asList(addVotingConfigExclusionsRequest.getNodeDescriptions())
+                + " matched no master-eligible nodes");
+        }
+
+        resolvedNodes.removeIf(n -> getVotingConfigExclusions().contains(n));
+        return resolvedNodes;
+    }
+
     /**
      * An interface that implementors use when a class requires a client to maybe have a feature.
      */
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java b/es/es-server/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java
index 9c5c93b..41bfaf7 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java
@@ -392,16 +392,6 @@ public class SnapshotsInProgress extends AbstractNamedDiffable<Custom> implement
         return this.entries;
     }
 
-    public Entry snapshot(final Snapshot snapshot) {
-        for (Entry entry : entries) {
-            final Snapshot curr = entry.snapshot();
-            if (curr.equals(snapshot)) {
-                return entry;
-            }
-        }
-        return null;
-    }
-
     @Override
     public String getWriteableName() {
         return TYPE;
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java b/es/es-server/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
index fde78fb..2d3cd58 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
@@ -27,7 +27,6 @@ import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.rest.RestStatus;
 
 import java.io.IOException;
 import java.util.EnumMap;
@@ -131,18 +130,6 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         return global(level).size() > 0;
     }
 
-    /**
-     * Is there a global block with the provided status?
-     */
-    public boolean hasGlobalBlockWithStatus(final RestStatus status) {
-        for (ClusterBlock clusterBlock : global) {
-            if (clusterBlock.status().equals(status)) {
-                return true;
-            }
-        }
-        return false;
-    }
-
     public boolean hasIndexBlock(String index, ClusterBlock block) {
         return indicesBlocks.containsKey(index) && indicesBlocks.get(index).contains(block);
     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/FollowersChecker.java b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/FollowersChecker.java
index 4a9be56..59494ab 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/FollowersChecker.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/FollowersChecker.java
@@ -124,7 +124,7 @@ public class FollowersChecker {
      */
     public void setCurrentNodes(DiscoveryNodes discoveryNodes) {
         synchronized (mutex) {
-            final Predicate<DiscoveryNode> isUnknownNode = n -> discoveryNodes.nodeExists(n) == false;
+            final Predicate<DiscoveryNode> isUnknownNode = n -> n.nodeExists(discoveryNodes) == false;
             followerCheckers.keySet().removeIf(isUnknownNode);
             faultyNodes.removeIf(isUnknownNode);
 
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/JoinTaskExecutor.java b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/JoinTaskExecutor.java
index 084ce0d..29d9c8e 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/JoinTaskExecutor.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/JoinTaskExecutor.java
@@ -121,7 +121,7 @@ public class JoinTaskExecutor implements ClusterStateTaskExecutor<JoinTaskExecut
         for (final Task joinTask : joiningNodes) {
             if (joinTask.isBecomeMasterTask() || joinTask.isFinishElectionTask()) {
                 // noop
-            } else if (currentNodes.nodeExists(joinTask.node())) {
+            } else if (joinTask.node().nodeExists(currentNodes)) {
                 logger.debug("received a join request for an existing node [{}]", joinTask.node());
             } else {
                 final DiscoveryNode node = joinTask.node();
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/LeaderChecker.java b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/LeaderChecker.java
index 5bc5ea8..b58175b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/LeaderChecker.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/LeaderChecker.java
@@ -161,7 +161,7 @@ public class LeaderChecker {
         if (discoveryNodes.isLocalNodeElectedMaster() == false) {
             logger.debug("non-master handling {}", request);
             throw new CoordinationStateRejectedException("non-leader rejecting leader check");
-        } else if (discoveryNodes.nodeExists(request.getSender()) == false) {
+        } else if (request.getSender().nodeExists(discoveryNodes) == false) {
             logger.debug("leader check from unknown node: {}", request);
             throw new CoordinationStateRejectedException("leader check from unknown node");
         } else {
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/NodeRemovalClusterStateTaskExecutor.java b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/NodeRemovalClusterStateTaskExecutor.java
index 0722b7f..f022a13 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/NodeRemovalClusterStateTaskExecutor.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/NodeRemovalClusterStateTaskExecutor.java
@@ -71,7 +71,7 @@ public class NodeRemovalClusterStateTaskExecutor implements ClusterStateTaskExec
         final DiscoveryNodes.Builder remainingNodesBuilder = DiscoveryNodes.builder(currentState.nodes());
         boolean removed = false;
         for (final Task task : tasks) {
-            if (currentState.nodes().nodeExists(task.node())) {
+            if (task.node().nodeExists(currentState.nodes())) {
                 remainingNodesBuilder.remove(task.node());
                 removed = true;
             } else {
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java
index c6c2e46..048d399 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java
@@ -178,7 +178,7 @@ public class PublicationTransportHandler {
                             return "publish to self of " + publishRequest;
                         }
                     });
-                } else if (sendFullVersion || !previousState.nodes().nodeExists(destination)) {
+                } else if (sendFullVersion || !destination.nodeExists(previousState.nodes())) {
                     logger.trace("sending full cluster state version {} to {}", newState.version(), destination);
                     PublicationTransportHandler.this.sendFullClusterState(newState, serializedStates, destination, responseActionListener);
                 } else {
@@ -272,7 +272,7 @@ public class PublicationTransportHandler {
                 continue;
             }
             try {
-                if (sendFullVersion || !previousState.nodes().nodeExists(node)) {
+                if (sendFullVersion || !node.nodeExists(previousState.nodes())) {
                     if (serializedStates.containsKey(node.getVersion()) == false) {
                         serializedStates.put(node.getVersion(), serializeFullClusterState(clusterState, node.getVersion()));
                     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/health/ClusterStateHealth.java b/es/es-server/src/main/java/org/elasticsearch/cluster/health/ClusterStateHealth.java
index ad1561e..9bfcf15 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/health/ClusterStateHealth.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/health/ClusterStateHealth.java
@@ -100,7 +100,7 @@ public final class ClusterStateHealth implements Iterable<ClusterIndexHealth>, W
             }
         }
 
-        if (clusterState.blocks().hasGlobalBlockWithStatus(RestStatus.SERVICE_UNAVAILABLE)) {
+        if (RestStatus.SERVICE_UNAVAILABLE.hasGlobalBlockWithStatus(clusterState.blocks())) {
             computeStatus = ClusterHealthStatus.RED;
         }
 
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java b/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
index 077c1e0..e676fa2 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
@@ -53,6 +53,7 @@ import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.gateway.MetaDataStateFormat;
 import org.elasticsearch.index.Index;
+import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.rest.RestStatus;
@@ -86,6 +87,44 @@ public class IndexMetaData implements Diffable<IndexMetaData>, ToXContentFragmen
     public static final ClusterBlock INDEX_METADATA_BLOCK = new ClusterBlock(9, "index metadata (api)", false, false, false, RestStatus.FORBIDDEN, EnumSet.of(ClusterBlockLevel.METADATA_WRITE, ClusterBlockLevel.METADATA_READ));
     public static final ClusterBlock INDEX_READ_ONLY_ALLOW_DELETE_BLOCK = new ClusterBlock(12, "index read-only / allow delete (api)", false, false, true, RestStatus.FORBIDDEN, EnumSet.of(ClusterBlockLevel.METADATA_WRITE, ClusterBlockLevel.WRITE));
 
+    public void assertMappingVersion(
+        final IndexMetaData newIndexMetaData,
+        final Map<String, DocumentMapper> updatedEntries, MapperService mapperService) {
+        if (Assertions.ENABLED
+                && this != null
+                && getCreationVersion().onOrAfter(Version.ES_V_6_5_1)) {
+            if (getMappingVersion() == newIndexMetaData.getMappingVersion()) {
+                // if the mapping version is unchanged, then there should not be any updates and all mappings should be the same
+                assert updatedEntries.isEmpty() : updatedEntries;
+                for (final ObjectCursor<MappingMetaData> mapping : newIndexMetaData.getMappings().values()) {
+                    final CompressedXContent currentSource = mapping(mapping.value.type()).source();
+                    final CompressedXContent newSource = mapping.value.source();
+                    assert currentSource.equals(newSource) :
+                            "expected current mapping [" + currentSource + "] for type [" + mapping.value.type() + "] "
+                                    + "to be the same as new mapping [" + newSource + "]";
+                }
+            } else {
+                // if the mapping version is changed, it should increase, there should be updates, and the mapping should be different
+                final long currentMappingVersion = getMappingVersion();
+                final long newMappingVersion = newIndexMetaData.getMappingVersion();
+                assert currentMappingVersion < newMappingVersion :
+                        "expected current mapping version [" + currentMappingVersion + "] "
+                                + "to be less than new mapping version [" + newMappingVersion + "]";
+                assert updatedEntries.isEmpty() == false;
+                for (final DocumentMapper documentMapper : updatedEntries.values()) {
+                    final MappingMetaData currentMapping = mapping(documentMapper.type());
+                    if (currentMapping != null) {
+                        final CompressedXContent currentSource = currentMapping.source();
+                        final CompressedXContent newSource = documentMapper.mappingSource();
+                        assert currentSource.equals(newSource) == false :
+                                "expected current mapping [" + currentSource + "] for type [" + documentMapper.type() + "] " +
+                                        "to be different than new mapping";
+                    }
+                }
+            }
+        }
+    }
+
     public enum State {
         OPEN((byte) 0),
         CLOSE((byte) 1);
@@ -1074,7 +1113,7 @@ public class IndexMetaData implements Diffable<IndexMetaData>, ToXContentFragmen
                 initialRecoveryFilters = DiscoveryNodeFilters.buildFromKeyValue(OR, initialRecoveryMap);
             }
             Version indexCreatedVersion = Version.indexCreated(settings);
-            Version indexUpgradedVersion = settings.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, indexCreatedVersion);
+            Version indexUpgradedVersion = indexCreatedVersion.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, settings);
 
             if (primaryTerms == null) {
                 initializePrimaryTerms();
@@ -1287,7 +1326,7 @@ public class IndexMetaData implements Diffable<IndexMetaData>, ToXContentFragmen
         if (version != Version.V_EMPTY) {
             builder.put(SETTING_VERSION_CREATED_STRING, version.toString());
         }
-        Version versionUpgraded = settings.getAsVersion(SETTING_VERSION_UPGRADED, null);
+        Version versionUpgraded = null.getAsVersion(SETTING_VERSION_UPGRADED, settings);
         if (versionUpgraded != null) {
             builder.put(SETTING_VERSION_UPGRADED_STRING, versionUpgraded.toString());
         }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
index 06df7ab..8722841 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
@@ -35,6 +35,10 @@ import org.elasticsearch.cluster.NamedDiffableValueSerializer;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlockLevel;
 import org.elasticsearch.cluster.coordination.CoordinationMetaData;
+import org.elasticsearch.cluster.routing.IndexRoutingTable;
+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
+import org.elasticsearch.cluster.routing.RecoverySource;
+import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.UUIDs;
 import org.elasticsearch.common.collect.HppcMaps;
@@ -85,6 +89,67 @@ public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, To
     public static final String ALL = "_all";
     public static final String UNKNOWN_CLUSTER_UUID = "_na_";
 
+    public boolean validate(IndexRoutingTable indexShardRoutingTables) {
+        // check index exists
+        if (!hasIndex(indexShardRoutingTables.getIndex().getName())) {
+            throw new IllegalStateException(indexShardRoutingTables.getIndex() + " exists in routing does not exists in metadata");
+        }
+        IndexMetaData indexMetaData = index(indexShardRoutingTables.getIndex().getName());
+        if (indexMetaData.getIndexUUID().equals(indexShardRoutingTables.getIndex().getUUID()) == false) {
+            throw new IllegalStateException(indexShardRoutingTables.getIndex().getName() + " exists in routing does not exists in metadata with the same uuid");
+        }
+
+        // check the number of shards
+        if (indexMetaData.getNumberOfShards() != indexShardRoutingTables.shards().size()) {
+            Set<Integer> expected = new HashSet<>();
+            for (int i = 0; i < indexMetaData.getNumberOfShards(); i++) {
+                expected.add(i);
+            }
+            for (IndexShardRoutingTable indexShardRoutingTable : indexShardRoutingTables) {
+                expected.remove(indexShardRoutingTable.shardId().id());
+            }
+            throw new IllegalStateException("Wrong number of shards in routing table, missing: " + expected);
+        }
+
+        // check the replicas
+        for (IndexShardRoutingTable indexShardRoutingTable : indexShardRoutingTables) {
+            int routingNumberOfReplicas = indexShardRoutingTable.size() - 1;
+            if (routingNumberOfReplicas != indexMetaData.getNumberOfReplicas()) {
+                throw new IllegalStateException("Shard [" + indexShardRoutingTable.shardId().id() +
+                                 "] routing table has wrong number of replicas, expected [" + indexMetaData.getNumberOfReplicas() +
+                                 "], got [" + routingNumberOfReplicas + "]");
+            }
+            for (ShardRouting shardRouting : indexShardRoutingTable) {
+                if (!shardRouting.index().equals(indexShardRoutingTables.getIndex())) {
+                    throw new IllegalStateException("shard routing has an index [" + shardRouting.index() + "] that is different " +
+                                                    "from the routing table");
+                }
+                final Set<String> inSyncAllocationIds = indexMetaData.inSyncAllocationIds(shardRouting.id());
+                if (shardRouting.active() &&
+                    inSyncAllocationIds.contains(shardRouting.allocationId().getId()) == false) {
+                    throw new IllegalStateException("active shard routing " + shardRouting + " has no corresponding entry in the in-sync " +
+                        "allocation set " + inSyncAllocationIds);
+                }
+
+                if (shardRouting.primary() && shardRouting.initializing() &&
+                    shardRouting.recoverySource().getType() == RecoverySource.Type.EXISTING_STORE) {
+                    if (inSyncAllocationIds.contains(RecoverySource.ExistingStoreRecoverySource.FORCED_ALLOCATION_ID)) {
+                        if (inSyncAllocationIds.size() != 1) {
+                            throw new IllegalStateException("a primary shard routing " + shardRouting
+                                                            + " is a primary that is recovering from a stale primary has unexpected allocation ids in in-sync " +
+                                                            "allocation set " + inSyncAllocationIds);
+                        }
+                    } else if (inSyncAllocationIds.contains(shardRouting.allocationId().getId()) == false) {
+                        throw new IllegalStateException("a primary shard routing " + shardRouting
+                                                        + " is a primary that is recovering from a known allocation id but has no corresponding entry in the in-sync " +
+                                                        "allocation set " + inSyncAllocationIds);
+                    }
+                }
+            }
+        }
+        return true;
+    }
+
     public enum XContentContext {
         /* Custom metadata should be returns as part of API call */
         API,
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java b/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java
index 89e8c95..4937e9c 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java
@@ -378,6 +378,17 @@ public class DiscoveryNode implements Writeable, ToXContentFragment {
     }
 
     /**
+     * Determine if a given node exists
+     *
+     *
+     * @param discoveryNodes@return <code>true</code> if the node exists. Otherwise <code>false</code>
+     */
+    public boolean nodeExists(DiscoveryNodes discoveryNodes) {
+        DiscoveryNode existing = discoveryNodes.getNodes().get(getId());
+        return existing != null && existing.equals(this);
+    }
+
+    /**
      * Enum that holds all the possible roles that that a node can fulfill in a cluster.
      * Each role has its name and a corresponding abbreviation used by cat apis.
      */
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java b/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
index a767ac3..968be62 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
@@ -186,17 +186,6 @@ public class DiscoveryNodes extends AbstractDiffable<DiscoveryNodes> implements
     }
 
     /**
-     * Determine if a given node exists
-     *
-     * @param node of the node which existence should be verified
-     * @return <code>true</code> if the node exists. Otherwise <code>false</code>
-     */
-    public boolean nodeExists(DiscoveryNode node) {
-        DiscoveryNode existing = nodes.get(node.getId());
-        return existing != null && existing.equals(node);
-    }
-
-    /**
      * Get the id of the master node
      *
      * @return id of the master
@@ -395,12 +384,12 @@ public class DiscoveryNodes extends AbstractDiffable<DiscoveryNodes> implements
         final List<DiscoveryNode> removed = new ArrayList<>();
         final List<DiscoveryNode> added = new ArrayList<>();
         for (DiscoveryNode node : other) {
-            if (this.nodeExists(node) == false) {
+            if (node.nodeExists(this) == false) {
                 removed.add(node);
             }
         }
         for (DiscoveryNode node : this) {
-            if (other.nodeExists(node) == false) {
+            if (node.nodeExists(other) == false) {
                 added.add(node);
             }
         }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
index 171aab4..ba17573 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
@@ -26,7 +26,6 @@ import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.Diff;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.routing.RecoverySource.EmptyStoreRecoverySource;
 import org.elasticsearch.cluster.routing.RecoverySource.ExistingStoreRecoverySource;
 import org.elasticsearch.cluster.routing.RecoverySource.LocalShardsRecoverySource;
@@ -97,67 +96,6 @@ public class IndexRoutingTable extends AbstractDiffable<IndexRoutingTable> imple
         return index;
     }
 
-    boolean validate(MetaData metaData) {
-        // check index exists
-        if (!metaData.hasIndex(index.getName())) {
-            throw new IllegalStateException(index + " exists in routing does not exists in metadata");
-        }
-        IndexMetaData indexMetaData = metaData.index(index.getName());
-        if (indexMetaData.getIndexUUID().equals(index.getUUID()) == false) {
-            throw new IllegalStateException(index.getName() + " exists in routing does not exists in metadata with the same uuid");
-        }
-
-        // check the number of shards
-        if (indexMetaData.getNumberOfShards() != shards().size()) {
-            Set<Integer> expected = new HashSet<>();
-            for (int i = 0; i < indexMetaData.getNumberOfShards(); i++) {
-                expected.add(i);
-            }
-            for (IndexShardRoutingTable indexShardRoutingTable : this) {
-                expected.remove(indexShardRoutingTable.shardId().id());
-            }
-            throw new IllegalStateException("Wrong number of shards in routing table, missing: " + expected);
-        }
-
-        // check the replicas
-        for (IndexShardRoutingTable indexShardRoutingTable : this) {
-            int routingNumberOfReplicas = indexShardRoutingTable.size() - 1;
-            if (routingNumberOfReplicas != indexMetaData.getNumberOfReplicas()) {
-                throw new IllegalStateException("Shard [" + indexShardRoutingTable.shardId().id() +
-                                 "] routing table has wrong number of replicas, expected [" + indexMetaData.getNumberOfReplicas() +
-                                 "], got [" + routingNumberOfReplicas + "]");
-            }
-            for (ShardRouting shardRouting : indexShardRoutingTable) {
-                if (!shardRouting.index().equals(index)) {
-                    throw new IllegalStateException("shard routing has an index [" + shardRouting.index() + "] that is different " +
-                                                    "from the routing table");
-                }
-                final Set<String> inSyncAllocationIds = indexMetaData.inSyncAllocationIds(shardRouting.id());
-                if (shardRouting.active() &&
-                    inSyncAllocationIds.contains(shardRouting.allocationId().getId()) == false) {
-                    throw new IllegalStateException("active shard routing " + shardRouting + " has no corresponding entry in the in-sync " +
-                        "allocation set " + inSyncAllocationIds);
-                }
-
-                if (shardRouting.primary() && shardRouting.initializing() &&
-                    shardRouting.recoverySource().getType() == RecoverySource.Type.EXISTING_STORE) {
-                    if (inSyncAllocationIds.contains(RecoverySource.ExistingStoreRecoverySource.FORCED_ALLOCATION_ID)) {
-                        if (inSyncAllocationIds.size() != 1) {
-                            throw new IllegalStateException("a primary shard routing " + shardRouting
-                                                            + " is a primary that is recovering from a stale primary has unexpected allocation ids in in-sync " +
-                                                            "allocation set " + inSyncAllocationIds);
-                        }
-                    } else if (inSyncAllocationIds.contains(shardRouting.allocationId().getId()) == false) {
-                        throw new IllegalStateException("a primary shard routing " + shardRouting
-                                                        + " is a primary that is recovering from a known allocation id but has no corresponding entry in the in-sync " +
-                                                        "allocation set " + inSyncAllocationIds);
-                    }
-                }
-            }
-        }
-        return true;
-    }
-
     @Override
     public Iterator<IndexShardRoutingTable> iterator() {
         return shards.valuesIt();
@@ -260,7 +198,7 @@ public class IndexRoutingTable extends AbstractDiffable<IndexRoutingTable> imple
     public List<ShardRouting> shardsWithState(ShardRoutingState state) {
         List<ShardRouting> shards = new ArrayList<>();
         for (IndexShardRoutingTable shardRoutingTable : this) {
-            shards.addAll(shardRoutingTable.shardsWithState(state));
+            shards.addAll(state.shardsWithState(shardRoutingTable));
         }
         return shards;
     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
index ca89182..539172f 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
@@ -540,19 +540,6 @@ public class IndexShardRoutingTable implements Iterable<ShardRouting> {
         return shards;
     }
 
-    public List<ShardRouting> shardsWithState(ShardRoutingState state) {
-        if (state == ShardRoutingState.INITIALIZING) {
-            return allInitializingShards;
-        }
-        List<ShardRouting> shards = new ArrayList<>();
-        for (ShardRouting shardEntry : this) {
-            if (shardEntry.state() == state) {
-                shards.add(shardEntry);
-            }
-        }
-        return shards;
-    }
-
     public static class Builder {
 
         private ShardId shardId;
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java
index 995be24..53db2b2 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java
@@ -19,8 +19,12 @@
 
 package org.elasticsearch.cluster.routing;
 
+import com.carrotsearch.hppc.cursors.ObjectCursor;
+import org.elasticsearch.cluster.DiskUsage;
 import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;
 import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.index.shard.ShardId;
 
 import java.util.ArrayList;
@@ -223,4 +227,24 @@ public class RoutingNode implements Iterable<ShardRouting> {
     public boolean isEmpty() {
         return shards.isEmpty();
     }
+
+    /**
+     * Returns a {@link DiskUsage} for the {@link RoutingNode} using the
+     * average usage of other nodes in the disk usage map.
+     * @param usages Map of nodeId to DiskUsage for all known nodes
+     * @param diskThresholdDecider
+     * @return DiskUsage representing given node using the average disk usage
+     */
+    public DiskUsage averageUsage(ImmutableOpenMap<String, DiskUsage> usages, DiskThresholdDecider diskThresholdDecider) {
+        if (usages.size() == 0) {
+            return new DiskUsage(nodeId(), node().getName(), "_na_", 0, 0);
+        }
+        long totalBytes = 0;
+        long freeBytes = 0;
+        for (ObjectCursor<DiskUsage> du : usages.values()) {
+            totalBytes += du.value.getTotalBytes();
+            freeBytes += du.value.getFreeBytes();
+        }
+        return new DiskUsage(nodeId(), node().getName(), "_na_", totalBytes / usages.size(), freeBytes / usages.size());
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
index 4371152..e4fb4f3 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
@@ -29,6 +29,9 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.UnassignedInfo.AllocationStatus;
+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
+import org.elasticsearch.cluster.routing.allocation.decider.Decision;
+import org.elasticsearch.cluster.routing.allocation.decider.NodeVersionAllocationDecider;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Randomness;
 import org.elasticsearch.common.collect.Tuple;
@@ -800,6 +803,20 @@ public class RoutingNodes implements Iterable<RoutingNode> {
         return nodesToShards.size();
     }
 
+    public Decision isVersionCompatibleRelocatePrimary(final String sourceNodeId,
+                                                       final RoutingNode target, final RoutingAllocation allocation, NodeVersionAllocationDecider nodeVersionAllocationDecider) {
+        final RoutingNode source = node(sourceNodeId);
+        if (target.node().getVersion().onOrAfter(source.node().getVersion())) {
+            return allocation.decision(Decision.YES, NodeVersionAllocationDecider.NAME,
+                "can relocate primary shard from a node with version [%s] to a node with equal-or-newer version [%s]",
+                source.node().getVersion(), target.node().getVersion());
+        } else {
+            return allocation.decision(Decision.NO, NodeVersionAllocationDecider.NAME,
+                "cannot relocate primary shard from a node with version [%s] to a node with older version [%s]",
+                source.node().getVersion(), target.node().getVersion());
+        }
+    }
+
     public static final class UnassignedShards implements Iterable<ShardRouting>  {
 
         private final RoutingNodes nodes;
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
index bab150f..1b7e1f0 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
@@ -86,11 +86,6 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
         return indicesRouting.containsKey(index);
     }
 
-    public boolean hasIndex(Index index) {
-        IndexRoutingTable indexRouting = index(index.getName());
-        return indexRouting != null && indexRouting.getIndex().equals(index);
-    }
-
     public IndexRoutingTable index(String index) {
         return indicesRouting.get(index);
     }
@@ -162,7 +157,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
 
     public boolean validate(MetaData metaData) {
         for (IndexRoutingTable indexRoutingTable : this) {
-            if (indexRoutingTable.validate(metaData) == false) {
+            if (metaData.validate(indexRoutingTable) == false) {
                 return false;
             }
         }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRouting.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRouting.java
index 5566321..0568217 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRouting.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRouting.java
@@ -21,7 +21,10 @@ package org.elasticsearch.cluster.routing;
 
 import org.elasticsearch.cluster.routing.RecoverySource.ExistingStoreRecoverySource;
 import org.elasticsearch.cluster.routing.RecoverySource.PeerRecoverySource;
+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.cluster.routing.allocation.allocator.BalancedShardsAllocator;
+import org.elasticsearch.cluster.routing.allocation.decider.Decision;
+import org.elasticsearch.cluster.routing.allocation.decider.SameShardAllocationDecider;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -653,4 +656,22 @@ public final class ShardRouting implements Writeable, ToXContentObject {
     public RecoverySource recoverySource() {
         return recoverySource;
     }
+
+    public Decision decideSameNode(RoutingNode node, RoutingAllocation allocation,
+                                   Iterable<ShardRouting> assignedShards, SameShardAllocationDecider sameShardAllocationDecider) {
+        for (ShardRouting assignedShard : assignedShards) {
+            if (node.nodeId().equals(assignedShard.currentNodeId())) {
+                if (assignedShard.isSameAllocation(this)) {
+                    return allocation.decision(Decision.NO, SameShardAllocationDecider.NAME,
+                        "the shard cannot be allocated to the node on which it already exists [%s]",
+                        toString());
+                } else {
+                    return allocation.decision(Decision.NO, SameShardAllocationDecider.NAME,
+                        "the shard cannot be allocated to the same node on which a copy of the shard already exists [%s]",
+                        assignedShard.toString());
+                }
+            }
+        }
+        return allocation.decision(Decision.YES, SameShardAllocationDecider.NAME, "the shard does not exist on the same node");
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java
index b36e1fc..f5b1fe2 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java
@@ -20,6 +20,9 @@
 package org.elasticsearch.cluster.routing;
 
 
+import java.util.ArrayList;
+import java.util.List;
+
 /**
  * Represents the current state of a {@link ShardRouting} as defined by the
  * cluster.
@@ -71,4 +74,17 @@ public enum ShardRoutingState {
                 throw new IllegalStateException("No routing state mapped for [" + value + "]");
         }
     }
+
+    public List<ShardRouting> shardsWithState(IndexShardRoutingTable shardRoutings) {
+        if (this == INITIALIZING) {
+            return shardRoutings.getAllInitializingShards();
+        }
+        List<ShardRouting> shards = new ArrayList<>();
+        for (ShardRouting shardEntry : shardRoutings) {
+            if (shardEntry.state() == this) {
+                shards.add(shardEntry);
+            }
+        }
+        return shards;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java
index 7610969..7873c0c 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java
@@ -73,4 +73,9 @@ public class RerouteExplanation implements ToXContentObject {
         builder.endObject();
         return builder;
     }
+
+    public RoutingExplanations add(RoutingExplanations routingExplanations) {
+        routingExplanations.explanations().add(this);
+        return routingExplanations;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java
index e0be712..f463933 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java
@@ -28,6 +28,7 @@ import org.elasticsearch.cluster.routing.RoutingChangesObserver;
 import org.elasticsearch.cluster.routing.RoutingNodes;
 import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.allocation.command.AbstractAllocateAllocationCommand;
 import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;
 import org.elasticsearch.cluster.routing.allocation.decider.Decision;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
@@ -290,6 +291,19 @@ public class RoutingAllocation {
         this.hasPendingAsyncFetch = true;
     }
 
+    /**
+     * Utility method for rejecting the current allocation command based on provided reason
+     * @param explain
+     * @param reason
+     * @param abstractAllocateAllocationCommand
+     */
+    public RerouteExplanation explainOrThrowRejectedCommand(boolean explain, String reason, AbstractAllocateAllocationCommand abstractAllocateAllocationCommand) {
+        if (explain) {
+            return new RerouteExplanation(abstractAllocateAllocationCommand, decision(Decision.NO, abstractAllocateAllocationCommand.name() + " (allocation command)", reason));
+        }
+        throw new IllegalArgumentException("[" + abstractAllocateAllocationCommand.name() + "] " + reason);
+    }
+
     public enum DebugMode {
         /**
          * debug mode is off
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
index fe97b52..6f7067f 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.routing.allocation;
 import org.elasticsearch.cluster.routing.allocation.decider.Decision;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.ToXContentFragment;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
@@ -43,11 +42,6 @@ public class RoutingExplanations implements ToXContentFragment {
         this.explanations = new ArrayList<>();
     }
 
-    public RoutingExplanations add(RerouteExplanation explanation) {
-        this.explanations.add(explanation);
-        return this;
-    }
-
     public List<RerouteExplanation> explanations() {
         return this.explanations;
     }
@@ -72,7 +66,7 @@ public class RoutingExplanations implements ToXContentFragment {
         RoutingExplanations exp = new RoutingExplanations();
         for (int i = 0; i < exCount; i++) {
             RerouteExplanation explanation = RerouteExplanation.readFrom(in);
-            exp.add(explanation);
+            explanation.add(exp);
         }
         return exp;
     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AbstractAllocateAllocationCommand.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AbstractAllocateAllocationCommand.java
index 4ffd70a..e460e44 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AbstractAllocateAllocationCommand.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AbstractAllocateAllocationCommand.java
@@ -152,23 +152,13 @@ public abstract class AbstractAllocateAllocationCommand implements AllocationCom
      */
     protected RerouteExplanation explainOrThrowMissingRoutingNode(RoutingAllocation allocation, boolean explain, DiscoveryNode discoNode) {
         if (!discoNode.isDataNode()) {
-            return explainOrThrowRejectedCommand(explain, allocation, "allocation can only be done on data nodes, not [" + node + "]");
+            return allocation.explainOrThrowRejectedCommand(explain, "allocation can only be done on data nodes, not [" + node + "]", this);
         } else {
-            return explainOrThrowRejectedCommand(explain, allocation, "could not find [" + node + "] among the routing nodes");
+            return allocation.explainOrThrowRejectedCommand(explain, "could not find [" + node + "] among the routing nodes", this);
         }
     }
 
     /**
-     * Utility method for rejecting the current allocation command based on provided reason
-     */
-    protected RerouteExplanation explainOrThrowRejectedCommand(boolean explain, RoutingAllocation allocation, String reason) {
-        if (explain) {
-            return new RerouteExplanation(this, allocation.decision(Decision.NO, name() + " (allocation command)", reason));
-        }
-        throw new IllegalArgumentException("[" + name() + "] " + reason);
-    }
-
-    /**
      * Utility method for rejecting the current allocation command based on provided exception
      */
     protected RerouteExplanation explainOrThrowRejectedCommand(boolean explain, RoutingAllocation allocation, RuntimeException rte) {
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateEmptyPrimaryAllocationCommand.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateEmptyPrimaryAllocationCommand.java
index a42fd27..a9297a9 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateEmptyPrimaryAllocationCommand.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateEmptyPrimaryAllocationCommand.java
@@ -117,13 +117,13 @@ public class AllocateEmptyPrimaryAllocationCommand extends BasePrimaryAllocation
             return explainOrThrowRejectedCommand(explain, allocation, e);
         }
         if (shardRouting.unassigned() == false) {
-            return explainOrThrowRejectedCommand(explain, allocation, "primary [" + index + "][" + shardId + "] is already assigned");
+            return allocation.explainOrThrowRejectedCommand(explain, "primary [" + index + "][" + shardId + "] is already assigned", this);
         }
 
         if (shardRouting.recoverySource().getType() != RecoverySource.Type.EMPTY_STORE && acceptDataLoss == false) {
             String dataLossWarning = "allocating an empty primary for [" + index + "][" + shardId + "] can result in data loss. Please confirm " +
                 "by setting the accept_data_loss parameter to true";
-            return explainOrThrowRejectedCommand(explain, allocation, dataLossWarning);
+            return allocation.explainOrThrowRejectedCommand(explain, dataLossWarning, this);
         }
 
         UnassignedInfo unassignedInfoToUpdate = null;
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateReplicaAllocationCommand.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateReplicaAllocationCommand.java
index 6ec09a9..1bb5d75 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateReplicaAllocationCommand.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateReplicaAllocationCommand.java
@@ -108,15 +108,15 @@ public class AllocateReplicaAllocationCommand extends AbstractAllocateAllocation
             return explainOrThrowRejectedCommand(explain, allocation, e);
         }
         if (primaryShardRouting.unassigned()) {
-            return explainOrThrowRejectedCommand(explain, allocation,
-                "trying to allocate a replica shard [" + index + "][" + shardId + "], while corresponding primary shard is still unassigned");
+            return allocation.explainOrThrowRejectedCommand(explain,
+                "trying to allocate a replica shard [" + index + "][" + shardId + "], while corresponding primary shard is still unassigned", AllocateReplicaAllocationCommand.this);
         }
 
         List<ShardRouting> replicaShardRoutings = allocation.routingTable().shardRoutingTable(index, shardId).replicaShardsWithState(ShardRoutingState.UNASSIGNED);
         ShardRouting shardRouting;
         if (replicaShardRoutings.isEmpty()) {
-            return explainOrThrowRejectedCommand(explain, allocation,
-                "all copies of [" + index + "][" + shardId + "] are already assigned. Use the move allocation command instead");
+            return allocation.explainOrThrowRejectedCommand(explain,
+                "all copies of [" + index + "][" + shardId + "] are already assigned. Use the move allocation command instead", AllocateReplicaAllocationCommand.this);
         } else {
             shardRouting = replicaShardRoutings.get(0);
         }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateStalePrimaryAllocationCommand.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateStalePrimaryAllocationCommand.java
index f4c9aba..d50521a 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateStalePrimaryAllocationCommand.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocateStalePrimaryAllocationCommand.java
@@ -115,18 +115,18 @@ public class AllocateStalePrimaryAllocationCommand extends BasePrimaryAllocation
             return explainOrThrowRejectedCommand(explain, allocation, e);
         }
         if (shardRouting.unassigned() == false) {
-            return explainOrThrowRejectedCommand(explain, allocation, "primary [" + index + "][" + shardId + "] is already assigned");
+            return allocation.explainOrThrowRejectedCommand(explain, "primary [" + index + "][" + shardId + "] is already assigned", this);
         }
 
         if (acceptDataLoss == false) {
             String dataLossWarning = "allocating an empty primary for [" + index + "][" + shardId + "] can result in data loss. Please " +
                 "confirm by setting the accept_data_loss parameter to true";
-            return explainOrThrowRejectedCommand(explain, allocation, dataLossWarning);
+            return allocation.explainOrThrowRejectedCommand(explain, dataLossWarning, this);
         }
 
         if (shardRouting.recoverySource().getType() != RecoverySource.Type.EXISTING_STORE) {
-            return explainOrThrowRejectedCommand(explain, allocation,
-                "trying to allocate an existing primary shard [" + index + "][" + shardId + "], while no such shard has ever been active");
+            return allocation.explainOrThrowRejectedCommand(explain,
+                "trying to allocate an existing primary shard [" + index + "][" + shardId + "], while no such shard has ever been active", this);
         }
 
         initializeUnassignedShard(allocation, routingNodes, routingNode, shardRouting, null,
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java
index ce017c2..934faa5 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java
@@ -68,7 +68,7 @@ public class AllocationCommands {
     public RoutingExplanations execute(RoutingAllocation allocation, boolean explain) {
         RoutingExplanations explanations = new RoutingExplanations();
         for (AllocationCommand command : commands) {
-            explanations.add(command.execute(allocation, explain));
+            command.execute(allocation, explain).add(explanations);
         }
         return explanations;
     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
index 5f1560a..d943aac 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.cluster.routing.allocation.decider;
 
-import com.carrotsearch.hppc.cursors.ObjectCursor;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.elasticsearch.cluster.ClusterInfo;
@@ -314,7 +313,7 @@ public class DiskThresholdDecider extends AllocationDecider {
         if (usage == null) {
             // If there is no usage, and we have other nodes in the cluster,
             // use the average usage for all nodes as the usage for this node
-            usage = averageUsage(node, usages);
+            usage = node.averageUsage(usages, this);
             if (logger.isDebugEnabled()) {
                 logger.debug("unable to determine disk usage for {}, defaulting to average across nodes [{} total] [{} free] [{}% free]",
                         node.nodeId(), usage.getTotalBytes(), usage.getFreeBytes(), usage.getFreeDiskAsPercentage());
@@ -335,26 +334,6 @@ public class DiskThresholdDecider extends AllocationDecider {
     }
 
     /**
-     * Returns a {@link DiskUsage} for the {@link RoutingNode} using the
-     * average usage of other nodes in the disk usage map.
-     * @param node Node to return an averaged DiskUsage object for
-     * @param usages Map of nodeId to DiskUsage for all known nodes
-     * @return DiskUsage representing given node using the average disk usage
-     */
-    DiskUsage averageUsage(RoutingNode node, ImmutableOpenMap<String, DiskUsage> usages) {
-        if (usages.size() == 0) {
-            return new DiskUsage(node.nodeId(), node.node().getName(), "_na_", 0, 0);
-        }
-        long totalBytes = 0;
-        long freeBytes = 0;
-        for (ObjectCursor<DiskUsage> du : usages.values()) {
-            totalBytes += du.value.getTotalBytes();
-            freeBytes += du.value.getFreeBytes();
-        }
-        return new DiskUsage(node.nodeId(), node.node().getName(), "_na_", totalBytes / usages.size(), freeBytes / usages.size());
-    }
-
-    /**
      * Given the DiskUsage for a node and the size of the shard, return the
      * percentage of free disk if the shard were to be allocated to the node.
      * @param usage A DiskUsage for the node to have space computed for
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/NodeVersionAllocationDecider.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/NodeVersionAllocationDecider.java
index e2817eb..3623ee1 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/NodeVersionAllocationDecider.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/NodeVersionAllocationDecider.java
@@ -50,7 +50,7 @@ public class NodeVersionAllocationDecider extends AllocationDecider {
                 }
             } else {
                 // relocating primary, only migrate to newer host
-                return isVersionCompatibleRelocatePrimary(allocation.routingNodes(), shardRouting.currentNodeId(), node, allocation);
+                return allocation.routingNodes().isVersionCompatibleRelocatePrimary(shardRouting.currentNodeId(), node, allocation, this);
             }
         } else {
             final ShardRouting primary = allocation.routingNodes().activePrimary(shardRouting.shardId());
@@ -64,20 +64,6 @@ public class NodeVersionAllocationDecider extends AllocationDecider {
         }
     }
 
-    private Decision isVersionCompatibleRelocatePrimary(final RoutingNodes routingNodes, final String sourceNodeId,
-                                                        final RoutingNode target, final RoutingAllocation allocation) {
-        final RoutingNode source = routingNodes.node(sourceNodeId);
-        if (target.node().getVersion().onOrAfter(source.node().getVersion())) {
-            return allocation.decision(Decision.YES, NAME,
-                "can relocate primary shard from a node with version [%s] to a node with equal-or-newer version [%s]",
-                source.node().getVersion(), target.node().getVersion());
-        } else {
-            return allocation.decision(Decision.NO, NAME,
-                "cannot relocate primary shard from a node with version [%s] to a node with older version [%s]",
-                source.node().getVersion(), target.node().getVersion());
-        }
-    }
-
     private Decision isVersionCompatibleAllocatingReplica(final RoutingNodes routingNodes, final String sourceNodeId,
                                                           final RoutingNode target, final RoutingAllocation allocation) {
         final RoutingNode source = routingNodes.node(sourceNodeId);
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java
index 2961b3f..6a5146b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java
@@ -69,7 +69,7 @@ public class SameShardAllocationDecider extends AllocationDecider {
     @Override
     public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {
         Iterable<ShardRouting> assignedShards = allocation.routingNodes().assignedShards(shardRouting.shardId());
-        Decision decision = decideSameNode(shardRouting, node, allocation, assignedShards);
+        Decision decision = shardRouting.decideSameNode(node, allocation, assignedShards, this);
         if (decision.type() == Decision.Type.NO || sameHost == false) {
             // if its already a NO decision looking at the node, or we aren't configured to look at the host, return the decision
             return decision;
@@ -113,24 +113,7 @@ public class SameShardAllocationDecider extends AllocationDecider {
     public Decision canForceAllocatePrimary(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {
         assert shardRouting.primary() : "must not call force allocate on a non-primary shard";
         Iterable<ShardRouting> assignedShards = allocation.routingNodes().assignedShards(shardRouting.shardId());
-        return decideSameNode(shardRouting, node, allocation, assignedShards);
+        return shardRouting.decideSameNode(node, allocation, assignedShards, this);
     }
 
-    private Decision decideSameNode(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation,
-                                    Iterable<ShardRouting> assignedShards) {
-        for (ShardRouting assignedShard : assignedShards) {
-            if (node.nodeId().equals(assignedShard.currentNodeId())) {
-                if (assignedShard.isSameAllocation(shardRouting)) {
-                    return allocation.decision(Decision.NO, NAME,
-                        "the shard cannot be allocated to the node on which it already exists [%s]",
-                        shardRouting.toString());
-                } else {
-                    return allocation.decision(Decision.NO, NAME,
-                        "the shard cannot be allocated to the same node on which a copy of the shard already exists [%s]",
-                        assignedShard.toString());
-                }
-            }
-        }
-        return allocation.decision(Decision.YES, NAME, "the shard does not exist on the same node");
-    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/cluster/service/ClusterApplierService.java b/es/es-server/src/main/java/org/elasticsearch/cluster/service/ClusterApplierService.java
index 2d9f89e..3bd7f7b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/cluster/service/ClusterApplierService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/cluster/service/ClusterApplierService.java
@@ -31,7 +31,10 @@ import org.elasticsearch.cluster.ClusterStateTaskConfig;
 import org.elasticsearch.cluster.LocalNodeMasterListener;
 import org.elasticsearch.cluster.NodeConnectionsService;
 import org.elasticsearch.cluster.TimeoutClusterStateListener;
+import org.elasticsearch.cluster.coordination.CoordinationState;
+import org.elasticsearch.cluster.coordination.InMemoryPersistedState;
 import org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException;
+import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Priority;
@@ -44,6 +47,7 @@ import org.elasticsearch.common.util.concurrent.EsExecutors;
 import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;
 import org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor;
 import org.elasticsearch.common.util.iterable.Iterables;
+import org.elasticsearch.gateway.GatewayMetaState;
 import org.elasticsearch.threadpool.Scheduler;
 import org.elasticsearch.threadpool.ThreadPool;
 
@@ -144,6 +148,17 @@ public class ClusterApplierService extends AbstractLifecycleComponent implements
             threadPool.scheduler());
     }
 
+    public CoordinationState.PersistedState getPersistedState(Settings settings, GatewayMetaState gatewayMetaState) {
+        gatewayMetaState.applyClusterStateUpdaters();
+        if (DiscoveryNode.isMasterNode(settings) == false) {
+            // use Zen1 way of writing cluster state for non-master-eligible nodes
+            // this avoids concurrent manipulating of IndexMetadata with IndicesStore
+            addLowPriorityApplier(gatewayMetaState);
+            return new InMemoryPersistedState(gatewayMetaState.getCurrentTerm(), gatewayMetaState.getLastAcceptedState());
+        }
+        return gatewayMetaState;
+    }
+
     class UpdateTask extends SourcePrioritizedRunnable implements Function<ClusterState, ClusterState> {
         final ClusterApplyListener listener;
         final Function<ClusterState, ClusterState> updateFunction;
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/blobstore/BlobPath.java b/es/es-server/src/main/java/org/elasticsearch/common/blobstore/BlobPath.java
index ea02aeb..a0b9c5f 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/blobstore/BlobPath.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/blobstore/BlobPath.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.common.blobstore;
 
+import org.elasticsearch.common.blobstore.fs.FsBlobStore;
+
+import java.nio.file.Path;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
@@ -76,4 +79,18 @@ public class BlobPath implements Iterable<String> {
         }
         return sb.toString();
     }
+
+    public Path buildPath(FsBlobStore fsBlobStore) {
+        String[] paths = toArray();
+        if (paths.length == 0) {
+            return fsBlobStore.path();
+        }
+        Path blobPath = fsBlobStore.path().resolve(paths[0]);
+        if (paths.length > 1) {
+            for (int i = 1; i < paths.length; i++) {
+                blobPath = blobPath.resolve(paths[i]);
+            }
+        }
+        return blobPath;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobStore.java b/es/es-server/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobStore.java
index f225b6e..e90a9ab 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobStore.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobStore.java
@@ -73,7 +73,7 @@ public class FsBlobStore implements BlobStore {
 
     @Override
     public void delete(BlobPath path) throws IOException {
-        IOUtils.rm(buildPath(path));
+        IOUtils.rm(path.buildPath(this));
     }
 
     @Override
@@ -82,24 +82,11 @@ public class FsBlobStore implements BlobStore {
     }
 
     private synchronized Path buildAndCreate(BlobPath path) throws IOException {
-        Path f = buildPath(path);
+        Path f = path.buildPath(this);
         if (!readOnly) {
             Files.createDirectories(f);
         }
         return f;
     }
 
-    private Path buildPath(BlobPath path) {
-        String[] paths = path.toArray();
-        if (paths.length == 0) {
-            return path();
-        }
-        Path blobPath = this.path.resolve(paths[0]);
-        if (paths.length > 1) {
-            for (int i = 1; i < paths.length; i++) {
-                blobPath = blobPath.resolve(paths[i]);
-            }
-        }
-        return blobPath;
-    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java b/es/es-server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
index 691325c..dcba09c 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
@@ -20,16 +20,16 @@ package org.elasticsearch.common.bytes;
 
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefIterator;
+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;
 import org.elasticsearch.common.io.stream.BytesStream;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.xcontent.ToXContentFragment;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentHelper;
+import org.elasticsearch.common.xcontent.XContentType;
 
-import java.io.ByteArrayOutputStream;
-import java.io.EOFException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
+import java.io.*;
+import java.util.Objects;
 import java.util.function.ToIntBiFunction;
 
 /**
@@ -249,6 +249,25 @@ public abstract class BytesReference implements Comparable<BytesReference>, ToXC
     }
 
     /**
+     * Adds mapping that will be added when the index gets created.
+     *  @param type   The mapping type
+     * @param xContentType the content type of the mapping source
+     * @param createIndexRequest
+     */
+    public CreateIndexRequest mapping(String type, XContentType xContentType, CreateIndexRequest createIndexRequest) {
+        if (createIndexRequest.mappings().containsKey(type)) {
+            throw new IllegalStateException("mappings for type \"" + type + "\" were already defined");
+        }
+        Objects.requireNonNull(xContentType);
+        try {
+            createIndexRequest.mappings().put(type, XContentHelper.convertToJson(this, false, false, xContentType));
+            return createIndexRequest;
+        } catch (IOException e) {
+            throw new UncheckedIOException("failed to convert to json", e);
+        }
+    }
+
+    /**
      * Instead of adding the complexity of {@link InputStream#reset()} etc to the actual impl
      * this wrapper builds it on top of the BytesReferenceStreamInput which is much simpler
      * that way.
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/inject/internal/Errors.java b/es/es-server/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
index 472eb42..58b2d97 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
@@ -377,16 +377,9 @@ public final class Errors {
         throw new ProvisionException(getMessages());
     }
 
-    private Message merge(Message message) {
-        List<Object> sources = new ArrayList<>();
-        sources.addAll(getSources());
-        sources.addAll(message.getSources());
-        return new Message(sources, message.getMessage(), message.getCause());
-    }
-
     public Errors merge(Collection<Message> messages) {
         for (Message message : messages) {
-            addMessage(merge(message));
+            addMessage(message.merge(this));
         }
         return this;
     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/inject/spi/Message.java b/es/es-server/src/main/java/org/elasticsearch/common/inject/spi/Message.java
index 619feca..994e29e 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/inject/spi/Message.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/inject/spi/Message.java
@@ -20,6 +20,7 @@ import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.SourceProvider;
 
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 import java.util.Objects;
@@ -128,4 +129,11 @@ public final class Message implements Element {
     public void applyTo(Binder binder) {
         binder.withSource(getSource()).addError(this);
     }
-}
\ No newline at end of file
+
+    public Message merge(Errors errors) {
+        List<Object> sources = new ArrayList<>();
+        sources.addAll(errors.getSources());
+        sources.addAll(getSources());
+        return new Message(sources, getMessage(), getCause());
+    }
+}
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
index 8523b73..06862d9 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
@@ -22,6 +22,7 @@ package org.elasticsearch.common.io.stream;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
+import org.apache.lucene.search.*;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.LockObtainFailedException;
 import org.apache.lucene.util.ArrayUtil;
@@ -38,6 +39,7 @@ import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.text.Text;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;
+import org.elasticsearch.index.engine.Segment;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 
@@ -1051,4 +1053,55 @@ public abstract class StreamInput extends InputStream {
             return null;
         }
     }
+
+    public Sort readSegmentSort(Segment segment) throws IOException {
+        int size = readVInt();
+        if (size == 0) {
+            return null;
+        }
+        SortField[] fields = new SortField[size];
+        for (int i = 0; i < size; i++) {
+            String field = readString();
+            byte type = readByte();
+            if (type == 0) {
+                Boolean missingFirst = readOptionalBoolean();
+                boolean max = readBoolean();
+                boolean reverse = readBoolean();
+                fields[i] = new SortedSetSortField(field, reverse,
+                    max ? SortedSetSelector.Type.MAX : SortedSetSelector.Type.MIN);
+                if (missingFirst != null) {
+                    fields[i].setMissingValue(missingFirst ?
+                        SortedSetSortField.STRING_FIRST : SortedSetSortField.STRING_LAST);
+                }
+            } else {
+                Object missing = readGenericValue();
+                boolean max = readBoolean();
+                boolean reverse = readBoolean();
+                final SortField.Type numericType;
+                switch (type) {
+                    case 1:
+                        numericType = SortField.Type.INT;
+                        break;
+                    case 2:
+                        numericType = SortField.Type.FLOAT;
+                        break;
+                    case 3:
+                        numericType = SortField.Type.DOUBLE;
+                        break;
+                    case 4:
+                        numericType = SortField.Type.LONG;
+                        break;
+                    default:
+                        throw new IOException("invalid index sort type:[" + type +
+                            "] for numeric field:[" + field + "]");
+                }
+                fields[i] = new SortedNumericSortField(field, numericType, reverse, max ?
+                    SortedNumericSelector.Type.MAX : SortedNumericSelector.Type.MIN);
+                if (missing != null) {
+                    fields[i].setMissingValue(missing);
+                }
+            }
+        }
+        return new Sort(fields);
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java b/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
index 857bf37..99ff8cf 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
@@ -353,14 +353,6 @@ public abstract class StreamOutput extends OutputStream {
         }
     }
 
-    public void writeOptionalText(@Nullable Text text) throws IOException {
-        if (text == null) {
-            writeInt(-1);
-        } else {
-            writeText(text);
-        }
-    }
-
     private final BytesRefBuilder spare = new BytesRefBuilder();
 
     public void writeText(Text text) throws IOException {
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/settings/Settings.java b/es/es-server/src/main/java/org/elasticsearch/common/settings/Settings.java
index 2de2dd5..7fe2bc4 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/settings/Settings.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/settings/Settings.java
@@ -511,21 +511,6 @@ public final class Settings implements ToXContentFragment {
     }
 
     /**
-     * Returns a parsed version.
-     */
-    public Version getAsVersion(String setting, Version defaultVersion) throws SettingsException {
-        String sValue = get(setting);
-        if (sValue == null) {
-            return defaultVersion;
-        }
-        try {
-            return Version.fromId(Integer.parseInt(sValue));
-        } catch (Exception e) {
-            throw new SettingsException("Failed to parse version setting [" + setting + "] with value [" + sValue + "]", e);
-        }
-    }
-
-    /**
      * @return  The direct keys of this settings
      */
     public Set<String> names() {
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/text/Text.java b/es/es-server/src/main/java/org/elasticsearch/common/text/Text.java
index df02cb6..5ffea85 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/text/Text.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/text/Text.java
@@ -21,6 +21,7 @@ package org.elasticsearch.common.text;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.ToXContentFragment;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
@@ -116,4 +117,12 @@ public final class Text implements Comparable<Text>, ToXContentFragment {
             return builder.utf8Value(br.bytes, br.offset, br.length);
         }
     }
+
+    public void writeOptionalText(StreamOutput streamOutput) throws IOException {
+        if (this == null) {
+            streamOutput.writeInt(-1);
+        } else {
+            streamOutput.writeText(this);
+        }
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/transport/BoundTransportAddress.java b/es/es-server/src/main/java/org/elasticsearch/common/transport/BoundTransportAddress.java
index 1c9e3d4..640d4de 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/transport/BoundTransportAddress.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/transport/BoundTransportAddress.java
@@ -19,6 +19,18 @@
 
 package org.elasticsearch.common.transport;
 
+import org.elasticsearch.common.network.NetworkAddress;
+import org.elasticsearch.node.Node;
+
+import java.io.BufferedWriter;
+import java.io.IOException;
+import java.net.InetAddress;
+import java.net.InetSocketAddress;
+import java.nio.charset.Charset;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
+
 /**
  * A bounded transport address is a tuple of {@link TransportAddress}, one array that represents
  * the addresses the transport is bound to, and the other is the published one that represents the address clients
@@ -65,4 +77,25 @@ public class BoundTransportAddress {
         }
         return builder.toString();
     }
+
+    /** Writes a file to the logs dir containing the ports for the given transport type
+     * @param type
+     * @param node*/
+    public void writePortsFile(String type, Node node) {
+        Path tmpPortsFile = node.getEnvironment().logsFile().resolve(type + ".ports.tmp");
+        try (BufferedWriter writer = Files.newBufferedWriter(tmpPortsFile, Charset.forName("UTF-8"))) {
+            for (TransportAddress address : boundAddresses()) {
+                InetAddress inetAddress = InetAddress.getByName(address.getAddress());
+                writer.write(NetworkAddress.format(new InetSocketAddress(inetAddress, address.getPort())) + "\n");
+            }
+        } catch (IOException e) {
+            throw new RuntimeException("Failed to write ports file", e);
+        }
+        Path portsFile = node.getEnvironment().logsFile().resolve(type + ".ports");
+        try {
+            Files.move(tmpPortsFile, portsFile, StandardCopyOption.ATOMIC_MOVE);
+        } catch (IOException e) {
+            throw new RuntimeException("Failed to rename ports file", e);
+        }
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java b/es/es-server/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java
index 3e5e21e..3cae9b4 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java
@@ -22,9 +22,12 @@ package org.elasticsearch.common.unit;
 import org.apache.logging.log4j.LogManager;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.breaker.CircuitBreaker;
 import org.elasticsearch.common.logging.DeprecationLogger;
 import org.elasticsearch.common.xcontent.ToXContentFragment;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.indices.breaker.BreakerSettings;
+import org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService;
 
 import java.io.IOException;
 import java.util.Locale;
@@ -253,4 +256,10 @@ public class ByteSizeValue implements Comparable<ByteSizeValue>, ToXContentFragm
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         return builder.value(toString());
     }
+
+    public boolean validateTotalCircuitBreakerLimit(HierarchyCircuitBreakerService hierarchyCircuitBreakerService) {
+        BreakerSettings newParentSettings = new BreakerSettings(CircuitBreaker.PARENT, getBytes(), 1.0, CircuitBreaker.Type.PARENT);
+        hierarchyCircuitBreakerService.validateSettings(new BreakerSettings[]{newParentSettings});
+        return true;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/common/util/concurrent/CountDown.java b/es/es-server/src/main/java/org/elasticsearch/common/util/concurrent/CountDown.java
index b2a80fc..3959609 100644
--- a/es/es-server/src/main/java/org/elasticsearch/common/util/concurrent/CountDown.java
+++ b/es/es-server/src/main/java/org/elasticsearch/common/util/concurrent/CountDown.java
@@ -20,6 +20,14 @@
 package org.elasticsearch.common.util.concurrent;
 
 
+import org.elasticsearch.action.ActionListener;
+import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.indices.flush.ShardsSyncedFlushResult;
+import org.elasticsearch.indices.flush.SyncedFlushService;
+
+import java.util.List;
+import java.util.Map;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.atomic.AtomicInteger;
 
@@ -77,4 +85,12 @@ public final class CountDown {
         assert countDown.get() >= 0;
         return countDown.get() == 0;
     }
+
+    public void countDownAndSendResponseIfDone(String syncId, List<ShardRouting> shards, ShardId shardId, int totalShards,
+                                               ActionListener<ShardsSyncedFlushResult> listener, Map<ShardRouting, SyncedFlushService.ShardSyncedFlushResponse> results, SyncedFlushService syncedFlushService) {
+        if (countDown()) {
+            assert results.size() == shards.size();
+            listener.onResponse(new ShardsSyncedFlushResult(shardId, syncId, totalShards, results));
+        }
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/discovery/DiscoveryModule.java b/es/es-server/src/main/java/org/elasticsearch/discovery/DiscoveryModule.java
index a14def8..7b9b4ca 100644
--- a/es/es-server/src/main/java/org/elasticsearch/discovery/DiscoveryModule.java
+++ b/es/es-server/src/main/java/org/elasticsearch/discovery/DiscoveryModule.java
@@ -128,7 +128,7 @@ public class DiscoveryModule {
             discovery = new Coordinator(NODE_NAME_SETTING.get(settings),
                 settings, clusterSettings,
                 transportService, namedWriteableRegistry, allocationService, masterService,
-                () -> gatewayMetaState.getPersistedState(settings, (ClusterApplierService) clusterApplier), seedHostsProvider,
+                () -> ((ClusterApplierService) clusterApplier).getPersistedState(settings, gatewayMetaState), seedHostsProvider,
                 clusterApplier, joinValidators, new Random(Randomness.get().nextLong()));
         } else {
             throw new IllegalArgumentException("Unknown discovery type [" + discoveryType + "]");
diff --git a/es/es-server/src/main/java/org/elasticsearch/env/Environment.java b/es/es-server/src/main/java/org/elasticsearch/env/Environment.java
index 1f49400..c3c9527 100644
--- a/es/es-server/src/main/java/org/elasticsearch/env/Environment.java
+++ b/es/es-server/src/main/java/org/elasticsearch/env/Environment.java
@@ -26,6 +26,7 @@ import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.common.settings.Setting;
 import org.elasticsearch.common.settings.Setting.Property;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.indices.analysis.HunspellService;
 
 import java.io.FileNotFoundException;
 import java.io.IOException;
@@ -344,4 +345,8 @@ public class Environment {
     private static void assertEquals(Object actual, Object expected, String name) {
         assert Objects.deepEquals(actual, expected) : "actual " + name + " [" + actual + "] is different than [ " + expected + "]";
     }
+
+    public Path resolveHunspellDirectory(HunspellService hunspellService) {
+        return configFile().resolve("hunspell");
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/es/es-server/src/main/java/org/elasticsearch/env/NodeEnvironment.java
index 8ef3ab0..43fa57a 100644
--- a/es/es-server/src/main/java/org/elasticsearch/env/NodeEnvironment.java
+++ b/es/es-server/src/main/java/org/elasticsearch/env/NodeEnvironment.java
@@ -492,7 +492,7 @@ public final class NodeEnvironment  implements Closeable {
      */
     public void deleteShardDirectoryUnderLock(ShardLock lock, IndexSettings indexSettings) throws IOException {
         final ShardId shardId = lock.getShardId();
-        assert isShardLocked(shardId) : "shard " + shardId + " is not locked";
+        assert shardId.isShardLocked(this) : "shard " + shardId + " is not locked";
         final Path[] paths = availableShardPaths(shardId);
         logger.trace("acquiring locks for {}, paths: [{}]", shardId, paths);
         acquireFSLockForPaths(indexSettings, paths);
@@ -534,15 +534,6 @@ public final class NodeEnvironment  implements Closeable {
         return existingPaths.size() == 0;
     }
 
-    private boolean isShardLocked(ShardId id) {
-        try {
-            shardLock(id, "checking if shard is locked").close();
-            return false;
-        } catch (ShardLockObtainFailedException ex) {
-            return true;
-        }
-    }
-
     /**
      * Deletes an indexes data directory recursively iff all of the indexes
      * shards locks were successfully acquired. If any of the indexes shard directories can't be locked
diff --git a/es/es-server/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java b/es/es-server/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
index 30361fa..2d74870 100644
--- a/es/es-server/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
+++ b/es/es-server/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
@@ -29,8 +29,6 @@ import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.ClusterStateApplier;
 import org.elasticsearch.cluster.coordination.CoordinationState;
-import org.elasticsearch.cluster.coordination.CoordinationState.PersistedState;
-import org.elasticsearch.cluster.coordination.InMemoryPersistedState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.Manifest;
 import org.elasticsearch.cluster.metadata.MetaData;
@@ -38,7 +36,6 @@ import org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.RoutingNode;
 import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.service.ClusterApplierService;
 import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.collect.Tuple;
@@ -104,17 +101,6 @@ public class GatewayMetaState implements ClusterStateApplier, CoordinationState.
         incrementalWrite = false;
     }
 
-    public PersistedState getPersistedState(Settings settings, ClusterApplierService clusterApplierService) {
-        applyClusterStateUpdaters();
-        if (DiscoveryNode.isMasterNode(settings) == false) {
-            // use Zen1 way of writing cluster state for non-master-eligible nodes
-            // this avoids concurrent manipulating of IndexMetadata with IndicesStore
-            clusterApplierService.addLowPriorityApplier(this);
-            return new InMemoryPersistedState(getCurrentTerm(), getLastAcceptedState());
-        }
-        return this;
-    }
-
     private void initializeClusterState(ClusterName clusterName) throws IOException {
         long startNS = System.nanoTime();
         Tuple<Manifest, MetaData> manifestAndMetaData = metaStateService.loadFullState();
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/Index.java b/es/es-server/src/main/java/org/elasticsearch/index/Index.java
index ac5a276..2f8b3e2 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/Index.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/Index.java
@@ -20,6 +20,8 @@
 package org.elasticsearch.index;
 
 import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.routing.IndexRoutingTable;
+import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -119,6 +121,11 @@ public class Index implements Writeable, ToXContentObject {
         return INDEX_PARSER.parse(parser, null).build();
     }
 
+    public boolean hasIndex(RoutingTable indexRoutingTables) {
+        IndexRoutingTable indexRouting = indexRoutingTables.index(getName());
+        return indexRouting != null && indexRouting.getIndex().equals(this);
+    }
+
     /**
      * Builder for Index objects.  Used by ObjectParser instances only.
      */
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/IndexModule.java b/es/es-server/src/main/java/org/elasticsearch/index/IndexModule.java
index fe02c1a..ac76e7b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/IndexModule.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/IndexModule.java
@@ -392,7 +392,7 @@ public final class IndexModule {
      */
     public MapperService newIndexMapperService(NamedXContentRegistry xContentRegistry, MapperRegistry mapperRegistry)
         throws IOException {
-        return new MapperService(indexSettings, analysisRegistry.build(indexSettings), xContentRegistry,
+        return new MapperService(indexSettings, indexSettings.build(analysisRegistry), xContentRegistry,
             mapperRegistry,
             () -> { throw new UnsupportedOperationException("no index query shard context available"); });
     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/IndexService.java b/es/es-server/src/main/java/org/elasticsearch/index/IndexService.java
index ec88d51..1db3cae 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/IndexService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/IndexService.java
@@ -143,7 +143,7 @@ public class IndexService extends AbstractIndexComponent implements IndicesClust
         this.xContentRegistry = xContentRegistry;
         this.namedWriteableRegistry = namedWriteableRegistry;
         this.circuitBreakerService = circuitBreakerService;
-        this.mapperService = new MapperService(indexSettings, registry.build(indexSettings), xContentRegistry,
+        this.mapperService = new MapperService(indexSettings, indexSettings.build(registry), xContentRegistry,
             mapperRegistry,
             // we parse all percolator queries as they would be parsed on shard 0
             () -> newQueryShardContext(System::currentTimeMillis));
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/IndexSettings.java b/es/es-server/src/main/java/org/elasticsearch/index/IndexSettings.java
index 2e61a59..f47cd9e 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/IndexSettings.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/IndexSettings.java
@@ -30,12 +30,15 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeUnit;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.index.analysis.*;
 import org.elasticsearch.index.translog.Translog;
 import org.elasticsearch.node.Node;
 
+import java.io.IOException;
 import java.util.Collections;
 import java.util.List;
 import java.util.Locale;
+import java.util.Map;
 import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
 import java.util.function.Function;
@@ -591,4 +594,18 @@ public final class IndexSettings {
     public long getSoftDeleteRetentionOperations() {
         return this.softDeleteRetentionOperations;
     }
+
+    /**
+     * Creates an index-level {@link IndexAnalyzers} from this registry using the given index settings
+     * @param analysisRegistry
+     */
+    public IndexAnalyzers build(AnalysisRegistry analysisRegistry) throws IOException {
+
+        final Map<String, CharFilterFactory> charFilterFactories = analysisRegistry.buildCharFilterFactories(this);
+        final Map<String, TokenizerFactory> tokenizerFactories = analysisRegistry.buildTokenizerFactories(this);
+        final Map<String, TokenFilterFactory> tokenFilterFactories = analysisRegistry.buildTokenFilterFactories(this);
+        final Map<String, AnalyzerProvider<?>> analyzierFactories = analysisRegistry.buildAnalyzerFactories(this);
+        final Map<String, AnalyzerProvider<?>> normalizerFactories = analysisRegistry.buildNormalizerFactories(this);
+        return analysisRegistry.build(this, analyzierFactories, normalizerFactories, tokenizerFactories, charFilterFactories, tokenFilterFactories);
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java b/es/es-server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java
index 57498a3..d2016de 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java
@@ -45,7 +45,7 @@ import static java.util.Collections.unmodifiableMap;
 
 /**
  * An internal registry for tokenizer, token filter, char filter and analyzer.
- * This class exists per node and allows to create per-index {@link IndexAnalyzers} via {@link #build(IndexSettings)}
+ * This class exists per node and allows to create per-index {@link IndexAnalyzers} via {@link IndexSettings#build(AnalysisRegistry)}
  */
 public final class AnalysisRegistry implements Closeable {
     public static final String INDEX_ANALYSIS_CHAR_FILTER = "index.analysis.char_filter";
@@ -143,19 +143,6 @@ public final class AnalysisRegistry implements Closeable {
         }
     }
 
-    /**
-     * Creates an index-level {@link IndexAnalyzers} from this registry using the given index settings
-     */
-    public IndexAnalyzers build(IndexSettings indexSettings) throws IOException {
-
-        final Map<String, CharFilterFactory> charFilterFactories = buildCharFilterFactories(indexSettings);
-        final Map<String, TokenizerFactory> tokenizerFactories = buildTokenizerFactories(indexSettings);
-        final Map<String, TokenFilterFactory> tokenFilterFactories = buildTokenFilterFactories(indexSettings);
-        final Map<String, AnalyzerProvider<?>> analyzierFactories = buildAnalyzerFactories(indexSettings);
-        final Map<String, AnalyzerProvider<?>> normalizerFactories = buildNormalizerFactories(indexSettings);
-        return build(indexSettings, analyzierFactories, normalizerFactories, tokenizerFactories, charFilterFactories, tokenFilterFactories);
-    }
-
     public Map<String, TokenFilterFactory> buildTokenFilterFactories(IndexSettings indexSettings) throws IOException {
         final Map<String, Settings> tokenFiltersSettings = indexSettings.getSettings().getGroups(INDEX_ANALYSIS_FILTER);
         Map<String, AnalysisModule.AnalysisProvider<TokenFilterFactory>> tokenFilters = new HashMap<>(this.tokenFilters);
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/engine/Segment.java b/es/es-server/src/main/java/org/elasticsearch/index/engine/Segment.java
index 945359e..959790d 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/engine/Segment.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/engine/Segment.java
@@ -177,7 +177,7 @@ public class Segment implements Streamable {
             // verbose mode
             ramTree = readRamTree(in);
         }
-        segmentSort = readSegmentSort(in);
+        segmentSort = in.readSegmentSort(this);
         if (in.readBoolean()) {
             attributes = in.readMap(StreamInput::readString, StreamInput::readString);
         } else {
@@ -211,57 +211,6 @@ public class Segment implements Streamable {
         }
     }
 
-    Sort readSegmentSort(StreamInput in) throws IOException {
-        int size = in.readVInt();
-        if (size == 0) {
-            return null;
-        }
-        SortField[] fields = new SortField[size];
-        for (int i = 0; i < size; i++) {
-            String field = in.readString();
-            byte type = in.readByte();
-            if (type == 0) {
-                Boolean missingFirst = in.readOptionalBoolean();
-                boolean max = in.readBoolean();
-                boolean reverse = in.readBoolean();
-                fields[i] = new SortedSetSortField(field, reverse,
-                    max ? SortedSetSelector.Type.MAX : SortedSetSelector.Type.MIN);
-                if (missingFirst != null) {
-                    fields[i].setMissingValue(missingFirst ?
-                        SortedSetSortField.STRING_FIRST : SortedSetSortField.STRING_LAST);
-                }
-            } else {
-                Object missing = in.readGenericValue();
-                boolean max = in.readBoolean();
-                boolean reverse = in.readBoolean();
-                final SortField.Type numericType;
-                switch (type) {
-                    case 1:
-                        numericType = SortField.Type.INT;
-                        break;
-                    case 2:
-                        numericType = SortField.Type.FLOAT;
-                        break;
-                    case 3:
-                        numericType = SortField.Type.DOUBLE;
-                        break;
-                    case 4:
-                        numericType = SortField.Type.LONG;
-                        break;
-                    default:
-                        throw new IOException("invalid index sort type:[" + type +
-                            "] for numeric field:[" + field + "]");
-                }
-                fields[i] = new SortedNumericSortField(field, numericType, reverse, max ?
-                    SortedNumericSelector.Type.MAX : SortedNumericSelector.Type.MIN);
-                if (missing != null) {
-                    fields[i].setMissingValue(missing);
-                }
-            }
-        }
-        return new Sort(fields);
-    }
-
     void writeSegmentSort(StreamOutput out, Sort sort) throws IOException {
         if (sort == null) {
             out.writeVInt(0);
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java b/es/es-server/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java
index 71c8bc5..09b9696 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java
@@ -36,7 +36,6 @@ import org.elasticsearch.index.mapper.array.DynamicArrayFieldMapperBuilderFactor
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.Comparator;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
@@ -569,32 +568,32 @@ final class DocumentParser {
     private static Mapper.Builder<?,?> createBuilderFromFieldType(final ParseContext context, MappedFieldType fieldType, String currentFieldName) {
         Mapper.Builder builder = null;
         if (fieldType instanceof TextFieldType) {
-            builder = context.root().findTemplateBuilder(context, currentFieldName, "text", XContentFieldType.STRING);
+            builder = context.findTemplateBuilder(currentFieldName, "text", XContentFieldType.STRING, context.root());
             if (builder == null) {
                 builder = new TextFieldMapper.Builder(currentFieldName)
                         .addMultiField(new KeywordFieldMapper.Builder("keyword").ignoreAbove(256));
             }
         } else if (fieldType instanceof KeywordFieldType) {
-            builder = context.root().findTemplateBuilder(context, currentFieldName, "keyword", XContentFieldType.STRING);
+            builder = context.findTemplateBuilder(currentFieldName, "keyword", XContentFieldType.STRING, context.root());
         } else {
             switch (fieldType.typeName()) {
             case DateFieldMapper.CONTENT_TYPE:
                 builder = context.root().findTemplateBuilder(context, currentFieldName, XContentFieldType.DATE);
                 break;
             case "long":
-                builder = context.root().findTemplateBuilder(context, currentFieldName, "long", XContentFieldType.LONG);
+                builder = context.findTemplateBuilder(currentFieldName, "long", XContentFieldType.LONG, context.root());
                 break;
             case "double":
-                builder = context.root().findTemplateBuilder(context, currentFieldName, "double", XContentFieldType.DOUBLE);
+                builder = context.findTemplateBuilder(currentFieldName, "double", XContentFieldType.DOUBLE, context.root());
                 break;
             case "integer":
-                builder = context.root().findTemplateBuilder(context, currentFieldName, "integer", XContentFieldType.LONG);
+                builder = context.findTemplateBuilder(currentFieldName, "integer", XContentFieldType.LONG, context.root());
                 break;
             case "float":
-                builder = context.root().findTemplateBuilder(context, currentFieldName, "float", XContentFieldType.DOUBLE);
+                builder = context.findTemplateBuilder(currentFieldName, "float", XContentFieldType.DOUBLE, context.root());
                 break;
             case BooleanFieldMapper.CONTENT_TYPE:
-                builder = context.root().findTemplateBuilder(context, currentFieldName, "boolean", XContentFieldType.BOOLEAN);
+                builder = context.findTemplateBuilder(currentFieldName, "boolean", XContentFieldType.BOOLEAN, context.root());
                 break;
             default:
                 break;
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java b/es/es-server/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
index 35f33a6..b6202ab 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.mapper;
 
+import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.index.IndexOptions;
@@ -384,4 +385,16 @@ public abstract class MappedFieldType extends FieldType {
         checkIfFrozen();
         this.eagerGlobalOrdinals = eagerGlobalOrdinals;
     }
+
+    /**
+     * Gets the search analyzer for the given field, or the default if there is none present for the field
+     * TODO: remove this by moving defaults into mappers themselves
+     * @param queryShardContext
+     */
+    public Analyzer getSearchAnalyzer(QueryShardContext queryShardContext) {
+        if (searchAnalyzer() != null) {
+            return searchAnalyzer();
+        }
+        return queryShardContext.getMapperService().searchAnalyzer();
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/es/es-server/src/main/java/org/elasticsearch/index/mapper/MapperService.java
index 35877ea..cb3965b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/mapper/MapperService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/mapper/MapperService.java
@@ -26,9 +26,7 @@ import org.apache.logging.log4j.message.ParameterizedMessage;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.DelegatingAnalyzerWrapper;
 import org.apache.lucene.index.Term;
-import org.elasticsearch.Assertions;
 import org.elasticsearch.ElasticsearchGenerationException;
-import org.elasticsearch.Version;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MappingMetaData;
 import org.elasticsearch.common.Nullable;
@@ -207,7 +205,7 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
 
         boolean requireRefresh = false;
 
-        assertMappingVersion(currentIndexMetaData, newIndexMetaData, updatedEntries);
+        currentIndexMetaData.assertMappingVersion(newIndexMetaData, updatedEntries, this);
 
         for (DocumentMapper documentMapper : updatedEntries.values()) {
             String mappingType = documentMapper.type();
@@ -236,45 +234,6 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
         return requireRefresh;
     }
 
-    private void assertMappingVersion(
-            final IndexMetaData currentIndexMetaData,
-            final IndexMetaData newIndexMetaData,
-            final Map<String, DocumentMapper> updatedEntries) {
-        if (Assertions.ENABLED
-                && currentIndexMetaData != null
-                && currentIndexMetaData.getCreationVersion().onOrAfter(Version.ES_V_6_5_1)) {
-            if (currentIndexMetaData.getMappingVersion() == newIndexMetaData.getMappingVersion()) {
-                // if the mapping version is unchanged, then there should not be any updates and all mappings should be the same
-                assert updatedEntries.isEmpty() : updatedEntries;
-                for (final ObjectCursor<MappingMetaData> mapping : newIndexMetaData.getMappings().values()) {
-                    final CompressedXContent currentSource = currentIndexMetaData.mapping(mapping.value.type()).source();
-                    final CompressedXContent newSource = mapping.value.source();
-                    assert currentSource.equals(newSource) :
-                            "expected current mapping [" + currentSource + "] for type [" + mapping.value.type() + "] "
-                                    + "to be the same as new mapping [" + newSource + "]";
-                }
-            } else {
-                // if the mapping version is changed, it should increase, there should be updates, and the mapping should be different
-                final long currentMappingVersion = currentIndexMetaData.getMappingVersion();
-                final long newMappingVersion = newIndexMetaData.getMappingVersion();
-                assert currentMappingVersion < newMappingVersion :
-                        "expected current mapping version [" + currentMappingVersion + "] "
-                                + "to be less than new mapping version [" + newMappingVersion + "]";
-                assert updatedEntries.isEmpty() == false;
-                for (final DocumentMapper documentMapper : updatedEntries.values()) {
-                    final MappingMetaData currentMapping = currentIndexMetaData.mapping(documentMapper.type());
-                    if (currentMapping != null) {
-                        final CompressedXContent currentSource = currentMapping.source();
-                        final CompressedXContent newSource = documentMapper.mappingSource();
-                        assert currentSource.equals(newSource) == false :
-                                "expected current mapping [" + currentSource + "] for type [" + documentMapper.type() + "] " +
-                                        "to be different than new mapping";
-                    }
-                }
-            }
-        }
-    }
-
     public void merge(Map<String, Map<String, Object>> mappings, MergeReason reason, boolean updateAllTypes) {
         Map<String, CompressedXContent> mappingSourcesCompressed = new LinkedHashMap<>(mappings.size());
         for (Map.Entry<String, Map<String, Object>> entry : mappings.entrySet()) {
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/mapper/ParseContext.java b/es/es-server/src/main/java/org/elasticsearch/index/mapper/ParseContext.java
index d3f42cb..d03af53 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/mapper/ParseContext.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/mapper/ParseContext.java
@@ -36,6 +36,28 @@ import java.util.Set;
 
 public abstract class ParseContext implements Iterable<ParseContext.Document>{
 
+    /**
+     * Find a template. Returns {@code null} if no template could be found.
+     * @param name        the field name
+     * @param dynamicType the field type to give the field if the template does not define one
+     * @param matchType   the type of the field in the json document or null if unknown
+     * @param mappers
+     * @return a mapper builder, or null if there is no template for such a field
+     */
+    public Mapper.Builder findTemplateBuilder(String name, String dynamicType, DynamicTemplate.XContentFieldType matchType, RootObjectMapper mappers) {
+        DynamicTemplate dynamicTemplate = mappers.findTemplate(path(), name, matchType);
+        if (dynamicTemplate == null) {
+            return null;
+        }
+        Mapper.TypeParser.ParserContext parserContext = docMapperParser().parserContext(name);
+        String mappingType = dynamicTemplate.mappingType(dynamicType);
+        Mapper.TypeParser typeParser = parserContext.typeParser(mappingType);
+        if (typeParser == null) {
+            throw new MapperParsingException("failed to find type parsed [" + mappingType + "] for [" + name + "]");
+        }
+        return typeParser.parse(name, dynamicTemplate.mappingForName(name, dynamicType), parserContext);
+    }
+
     /** Fork of {@link org.apache.lucene.document.Document} with additional functionality. */
     public static class Document implements Iterable<IndexableField> {
 
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/mapper/RootObjectMapper.java b/es/es-server/src/main/java/org/elasticsearch/index/mapper/RootObjectMapper.java
index 86e8164..ef0b731 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/mapper/RootObjectMapper.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/mapper/RootObjectMapper.java
@@ -205,28 +205,7 @@ public class RootObjectMapper extends ObjectMapper {
     }
 
     public Mapper.Builder findTemplateBuilder(ParseContext context, String name, XContentFieldType matchType) {
-        return findTemplateBuilder(context, name, matchType.defaultMappingType(), matchType);
-    }
-
-    /**
-     * Find a template. Returns {@code null} if no template could be found.
-     * @param name        the field name
-     * @param dynamicType the field type to give the field if the template does not define one
-     * @param matchType   the type of the field in the json document or null if unknown
-     * @return a mapper builder, or null if there is no template for such a field
-     */
-    public Mapper.Builder findTemplateBuilder(ParseContext context, String name, String dynamicType, XContentFieldType matchType) {
-        DynamicTemplate dynamicTemplate = findTemplate(context.path(), name, matchType);
-        if (dynamicTemplate == null) {
-            return null;
-        }
-        Mapper.TypeParser.ParserContext parserContext = context.docMapperParser().parserContext(name);
-        String mappingType = dynamicTemplate.mappingType(dynamicType);
-        Mapper.TypeParser typeParser = parserContext.typeParser(mappingType);
-        if (typeParser == null) {
-            throw new MapperParsingException("failed to find type parsed [" + mappingType + "] for [" + name + "]");
-        }
-        return typeParser.parse(name, dynamicTemplate.mappingForName(name, dynamicType), parserContext);
+        return context.findTemplateBuilder(name, matchType.defaultMappingType(), matchType, this);
     }
 
     public DynamicTemplate findTemplate(ContentPath path, String name, XContentFieldType matchType) {
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/query/QueryShardContext.java b/es/es-server/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
index 6980d8d..9a370a8 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
@@ -88,17 +88,6 @@ public class QueryShardContext extends QueryRewriteContext {
     }
 
     /**
-     * Gets the search analyzer for the given field, or the default if there is none present for the field
-     * TODO: remove this by moving defaults into mappers themselves
-     */
-    public Analyzer getSearchAnalyzer(MappedFieldType fieldType) {
-        if (fieldType.searchAnalyzer() != null) {
-            return fieldType.searchAnalyzer();
-        }
-        return getMapperService().searchAnalyzer();
-    }
-
-    /**
      * Gets the search quote analyzer for the given field, or the default if there is none present for the field
      * TODO: remove this by moving defaults into mappers themselves
      */
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/search/MatchQuery.java b/es/es-server/src/main/java/org/elasticsearch/index/search/MatchQuery.java
index 290bf33..47cc407 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/search/MatchQuery.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/search/MatchQuery.java
@@ -207,7 +207,7 @@ public class MatchQuery {
 
     protected Analyzer getAnalyzer(MappedFieldType fieldType, boolean quoted) {
         if (analyzer == null) {
-            return quoted ? context.getSearchQuoteAnalyzer(fieldType) : context.getSearchAnalyzer(fieldType);
+            return quoted ? context.getSearchQuoteAnalyzer(fieldType) : fieldType.getSearchAnalyzer(context);
         } else {
             return analyzer;
         }
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java b/es/es-server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java
index 855dc07..608a60a 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java
@@ -37,13 +37,10 @@ import org.elasticsearch.common.util.concurrent.ThreadContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.IndexShardClosedException;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.translog.Translog;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
-import java.io.IOException;
-
 /**
  * Background global checkpoint sync action initiated when a shard goes inactive. This is needed because while we send the global checkpoint
  * on every replication operation, after the last operation completes the global checkpoint could advance but without a follow-up operation
@@ -110,23 +107,16 @@ public class GlobalCheckpointSyncAction extends TransportReplicationAction<
     @Override
     protected PrimaryResult<Request, ReplicationResponse> shardOperationOnPrimary(
             final Request request, final IndexShard indexShard) throws Exception {
-        maybeSyncTranslog(indexShard);
+        indexShard.maybeSyncTranslog(this);
         return new PrimaryResult<>(request, new ReplicationResponse());
     }
 
     @Override
     protected ReplicaResult shardOperationOnReplica(final Request request, final IndexShard indexShard) throws Exception {
-        maybeSyncTranslog(indexShard);
+        indexShard.maybeSyncTranslog(this);
         return new ReplicaResult();
     }
 
-    private void maybeSyncTranslog(final IndexShard indexShard) throws IOException {
-        if (indexShard.getTranslogDurability() == Translog.Durability.REQUEST &&
-            indexShard.getLastSyncedGlobalCheckpoint() < indexShard.getGlobalCheckpoint()) {
-            indexShard.sync();
-        }
-    }
-
     public static final class Request extends ReplicationRequest<Request> {
 
         private Request() {
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/es/es-server/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index 529e718..f7b1405 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -91,6 +91,7 @@ import org.elasticsearch.index.mapper.RootObjectMapper;
 import org.elasticsearch.index.mapper.SourceToParse;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.recovery.RecoveryStats;
+import org.elasticsearch.index.seqno.GlobalCheckpointSyncAction;
 import org.elasticsearch.index.seqno.ReplicationTracker;
 import org.elasticsearch.index.seqno.SeqNoStats;
 import org.elasticsearch.index.seqno.SequenceNumbers;
@@ -2108,6 +2109,13 @@ public class IndexShard extends AbstractIndexShardComponent implements IndicesCl
         return replicationTracker.isRelocated();
     }
 
+    public void maybeSyncTranslog(GlobalCheckpointSyncAction globalCheckpointSyncAction) throws IOException {
+        if (getTranslogDurability() == Translog.Durability.REQUEST &&
+            getLastSyncedGlobalCheckpoint() < getGlobalCheckpoint()) {
+            sync();
+        }
+    }
+
     class ShardEventListener implements Engine.EventListener {
         private final CopyOnWriteArrayList<Consumer<ShardFailure>> delegates = new CopyOnWriteArrayList<>();
 
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/shard/ShardId.java b/es/es-server/src/main/java/org/elasticsearch/index/shard/ShardId.java
index 06f5747..b54219c 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/shard/ShardId.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/shard/ShardId.java
@@ -23,6 +23,8 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Writeable;
+import org.elasticsearch.env.NodeEnvironment;
+import org.elasticsearch.env.ShardLockObtainFailedException;
 import org.elasticsearch.index.Index;
 
 import java.io.IOException;
@@ -125,4 +127,13 @@ public class ShardId implements Writeable, Comparable<ShardId> {
         }
         return Integer.compare(shardId, o.getId());
     }
+
+    public boolean isShardLocked(NodeEnvironment nodeEnvironment) {
+        try {
+            nodeEnvironment.shardLock(this, "checking if shard is locked").close();
+            return false;
+        } catch (ShardLockObtainFailedException ex) {
+            return true;
+        }
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/store/Store.java b/es/es-server/src/main/java/org/elasticsearch/index/store/Store.java
index 43cbeb1..b9e248f 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/store/Store.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/store/Store.java
@@ -483,27 +483,6 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
         }
     }
 
-    /**
-     * The returned IndexOutput validates the files checksum.
-     * <p>
-     * Note: Checksums are calculated by default since version 4.8.0. This method only adds the
-     * verification against the checksum in the given metadata and does not add any significant overhead.
-     */
-    public IndexOutput createVerifyingOutput(String fileName, final StoreFileMetaData metadata, final IOContext context) throws IOException {
-        IndexOutput output = directory().createOutput(fileName, context);
-        boolean success = false;
-        try {
-            assert metadata.writtenBy() != null;
-            output = new LuceneVerifyingIndexOutput(metadata, output);
-            success = true;
-        } finally {
-            if (success == false) {
-                IOUtils.closeWhileHandlingException(output);
-            }
-        }
-        return output;
-    }
-
     public static void verify(IndexOutput output) throws IOException {
         if (output instanceof VerifyingIndexOutput) {
             ((VerifyingIndexOutput) output).verify();
diff --git a/es/es-server/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java b/es/es-server/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java
index 59ad749..fb2d154 100644
--- a/es/es-server/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java
+++ b/es/es-server/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java
@@ -19,11 +19,14 @@
 
 package org.elasticsearch.index.store;
 
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Version;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Writeable;
+import org.elasticsearch.core.internal.io.IOUtils;
 
 import java.io.IOException;
 import java.text.ParseException;
@@ -130,4 +133,28 @@ public class StoreFileMetaData implements Writeable {
     public BytesRef hash() {
         return hash;
     }
+
+    /**
+     * The returned IndexOutput validates the files checksum.
+     * <p>
+     * Note: Checksums are calculated by default since version 4.8.0. This method only adds the
+     * verification against the checksum in the given metadata and does not add any significant overhead.
+     * @param fileName
+     * @param context
+     * @param store
+     */
+    public IndexOutput createVerifyingOutput(String fileName, final IOContext context, Store store) throws IOException {
+        IndexOutput output = store.directory().createOutput(fileName, context);
+        boolean success = false;
+        try {
+            assert writtenBy() != null;
+            output = new Store.LuceneVerifyingIndexOutput(this, output);
+            success = true;
+        } finally {
+            if (success == false) {
+                IOUtils.closeWhileHandlingException(output);
+            }
+        }
+        return output;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java b/es/es-server/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java
index 1b71fcf..805557e 100644
--- a/es/es-server/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java
@@ -94,7 +94,7 @@ public class HunspellService {
     public HunspellService(final Settings settings, final Environment env, final Map<String, Dictionary> knownDictionaries)
             throws IOException {
         this.knownDictionaries = Collections.unmodifiableMap(knownDictionaries);
-        this.hunspellDir = resolveHunspellDirectory(env);
+        this.hunspellDir = env.resolveHunspellDirectory(this);
         this.defaultIgnoreCase = HUNSPELL_IGNORE_CASE.get(settings);
         this.loadingFunction = (locale) -> {
             try {
@@ -122,10 +122,6 @@ public class HunspellService {
         return dictionary;
     }
 
-    private Path resolveHunspellDirectory(Environment env) {
-        return env.configFile().resolve("hunspell");
-    }
-
     /**
      * Scans the hunspell directory and loads all found dictionaries
      */
diff --git a/es/es-server/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java b/es/es-server/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java
index abd3bb6..e2c72eb 100644
--- a/es/es-server/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java
@@ -132,7 +132,7 @@ public class HierarchyCircuitBreakerService extends CircuitBreakerService {
         registerBreaker(this.inFlightRequestsSettings);
         registerBreaker(this.accountingSettings);
 
-        clusterSettings.addSettingsUpdateConsumer(TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING, this::setTotalCircuitBreakerLimit, this::validateTotalCircuitBreakerLimit);
+        clusterSettings.addSettingsUpdateConsumer(TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING, this::setTotalCircuitBreakerLimit, ByteSizeValue::validateTotalCircuitBreakerLimit);
         clusterSettings.addSettingsUpdateConsumer(FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, this::setFieldDataBreakerLimit);
         clusterSettings.addSettingsUpdateConsumer(IN_FLIGHT_REQUESTS_CIRCUIT_BREAKER_LIMIT_SETTING, IN_FLIGHT_REQUESTS_CIRCUIT_BREAKER_OVERHEAD_SETTING, this::setInFlightRequestsBreakerLimit);
         clusterSettings.addSettingsUpdateConsumer(REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING, REQUEST_CIRCUIT_BREAKER_OVERHEAD_SETTING, this::setRequestBreakerLimit);
@@ -173,12 +173,6 @@ public class HierarchyCircuitBreakerService extends CircuitBreakerService {
         logger.info("Updated breaker settings for accounting requests: {}", newAccountingSettings);
     }
 
-    private boolean validateTotalCircuitBreakerLimit(ByteSizeValue byteSizeValue) {
-        BreakerSettings newParentSettings = new BreakerSettings(CircuitBreaker.PARENT, byteSizeValue.getBytes(), 1.0, CircuitBreaker.Type.PARENT);
-        validateSettings(new BreakerSettings[]{newParentSettings});
-        return true;
-    }
-
     private void setTotalCircuitBreakerLimit(ByteSizeValue byteSizeValue) {
         BreakerSettings newParentSettings = new BreakerSettings(CircuitBreaker.PARENT, byteSizeValue.getBytes(), 1.0, CircuitBreaker.Type.PARENT);
         this.parentSettings = newParentSettings;
diff --git a/es/es-server/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java b/es/es-server/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
index a2e4b94..3149820 100644
--- a/es/es-server/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
@@ -360,14 +360,14 @@ public class SyncedFlushService implements IndexEventListener {
             if (node == null) {
                 logger.trace("{} is assigned to an unknown node. skipping for sync id [{}]. shard routing {}", shardId, syncId, shard);
                 results.put(shard, new ShardSyncedFlushResponse("unknown node"));
-                countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, countDown, results);
+                countDown.countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, results, this);
                 continue;
             }
             final PreSyncedFlushResponse preSyncedResponse = preSyncResponses.get(shard.currentNodeId());
             if (preSyncedResponse == null) {
                 logger.trace("{} can't resolve expected commit id for current node, skipping for sync id [{}]. shard routing {}", shardId, syncId, shard);
                 results.put(shard, new ShardSyncedFlushResponse("no commit id from pre-sync flush"));
-                countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, countDown, results);
+                countDown.countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, results, this);
                 continue;
             }
             if (preSyncedResponse.numDocs != numDocsOnPrimary
@@ -376,7 +376,7 @@ public class SyncedFlushService implements IndexEventListener {
                     shardId, syncId, shard, preSyncedResponse.numDocs, numDocsOnPrimary);
                 results.put(shard, new ShardSyncedFlushResponse("out of sync replica; " +
                     "num docs on replica [" + preSyncedResponse.numDocs + "]; num docs on primary [" + numDocsOnPrimary + "]"));
-                countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, countDown, results);
+                countDown.countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, results, this);
                 continue;
             }
             logger.trace("{} sending synced flush request to {}. sync id [{}].", shardId, shard, syncId);
@@ -392,14 +392,14 @@ public class SyncedFlushService implements IndexEventListener {
                             ShardSyncedFlushResponse existing = results.put(shard, response);
                             assert existing == null : "got two answers for node [" + node + "]";
                             // count after the assert so we won't decrement twice in handleException
-                            countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, countDown, results);
+                            countDown.countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, results, this);
                         }
 
                         @Override
                         public void handleException(TransportException exp) {
                             logger.trace(() -> new ParameterizedMessage("{} error while performing synced flush on [{}], skipping", shardId, shard), exp);
                             results.put(shard, new ShardSyncedFlushResponse(exp.getMessage()));
-                            countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, countDown, results);
+                            countDown.countDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, results, this);
                         }
 
                         @Override
@@ -411,14 +411,6 @@ public class SyncedFlushService implements IndexEventListener {
 
     }
 
-    private void countDownAndSendResponseIfDone(String syncId, List<ShardRouting> shards, ShardId shardId, int totalShards,
-                                                ActionListener<ShardsSyncedFlushResult> listener, CountDown countDown, Map<ShardRouting, ShardSyncedFlushResponse> results) {
-        if (countDown.countDown()) {
-            assert results.size() == shards.size();
-            listener.onResponse(new ShardsSyncedFlushResult(shardId, syncId, totalShards, results));
-        }
-    }
-
     /**
      * send presync requests to all started copies of the given shard
      */
diff --git a/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java b/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java
index 96c85b1..a415783 100644
--- a/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java
+++ b/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java
@@ -30,7 +30,6 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefIterator;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ExceptionsHelper;
-import org.elasticsearch.Version;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.UUIDs;
 import org.elasticsearch.common.bytes.BytesReference;
@@ -313,7 +312,7 @@ public class RecoveryTarget extends AbstractRefCounted implements RecoveryTarget
         }
         // add first, before it's created
         tempFileNames.put(tempFileName, fileName);
-        IndexOutput indexOutput = store.createVerifyingOutput(tempFileName, metaData, IOContext.DEFAULT);
+        IndexOutput indexOutput = metaData.createVerifyingOutput(tempFileName, IOContext.DEFAULT, store);
         openIndexOutputs.put(fileName, indexOutput);
         return indexOutput;
     }
diff --git a/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java b/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java
index b37fefe..be64f4b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java
+++ b/es/es-server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java
@@ -77,36 +77,32 @@ public class RemoteRecoveryTargetHandler implements RecoveryTargetHandler {
 
     @Override
     public void prepareForTranslogOperations(boolean fileBasedRecovery, int totalTranslogOps) throws IOException {
-        transportService.submitRequest(targetNode, PeerRecoveryTargetService.Actions.PREPARE_TRANSLOG,
+        TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build().submitRequest(targetNode, PeerRecoveryTargetService.Actions.PREPARE_TRANSLOG,
                 new RecoveryPrepareForTranslogOperationsRequest(recoveryId, shardId, totalTranslogOps, fileBasedRecovery),
-                TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build(),
-                EmptyTransportResponseHandler.INSTANCE_SAME).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME, transportService).txGet();
     }
 
     @Override
     public void finalizeRecovery(final long globalCheckpoint) {
-        transportService.submitRequest(targetNode, PeerRecoveryTargetService.Actions.FINALIZE,
+        TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionLongTimeout()).build().submitRequest(targetNode, PeerRecoveryTargetService.Actions.FINALIZE,
             new RecoveryFinalizeRecoveryRequest(recoveryId, shardId, globalCheckpoint),
-            TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionLongTimeout()).build(),
-            EmptyTransportResponseHandler.INSTANCE_SAME).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME, transportService).txGet();
     }
 
     @Override
     public void ensureClusterStateVersion(long clusterStateVersion) {
-        transportService.submitRequest(targetNode, PeerRecoveryTargetService.Actions.WAIT_CLUSTERSTATE,
+        TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionLongTimeout()).build().submitRequest(targetNode, PeerRecoveryTargetService.Actions.WAIT_CLUSTERSTATE,
             new RecoveryWaitForClusterStateRequest(recoveryId, shardId, clusterStateVersion),
-            TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionLongTimeout()).build(),
-                EmptyTransportResponseHandler.INSTANCE_SAME).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME, transportService).txGet();
     }
 
     @Override
     public void handoffPrimaryContext(final ReplicationTracker.PrimaryContext primaryContext) {
-        transportService.submitRequest(
+        TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build().submitRequest(
                 targetNode,
                 PeerRecoveryTargetService.Actions.HANDOFF_PRIMARY_CONTEXT,
                 new RecoveryHandoffPrimaryContextRequest(recoveryId, shardId, primaryContext),
-                TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build(),
-                EmptyTransportResponseHandler.INSTANCE_SAME).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME, transportService).txGet();
     }
 
     @Override
@@ -114,12 +110,11 @@ public class RemoteRecoveryTargetHandler implements RecoveryTargetHandler {
                                         long maxSeenAutoIdTimestampOnPrimary, long maxSeqNoOfDeletesOrUpdatesOnPrimary) {
         final RecoveryTranslogOperationsRequest translogOperationsRequest = new RecoveryTranslogOperationsRequest(
             recoveryId, shardId, operations, totalTranslogOps, maxSeenAutoIdTimestampOnPrimary, maxSeqNoOfDeletesOrUpdatesOnPrimary);
-        final TransportFuture<RecoveryTranslogOperationsResponse> future = transportService.submitRequest(
+        final TransportFuture<RecoveryTranslogOperationsResponse> future = translogOpsRequestOptions.submitRequest(
                 targetNode,
                 PeerRecoveryTargetService.Actions.TRANSLOG_OPS,
                 translogOperationsRequest,
-                translogOpsRequestOptions,
-                RecoveryTranslogOperationsResponse.HANDLER);
+            RecoveryTranslogOperationsResponse.HANDLER, transportService);
         return future.txGet().localCheckpoint;
     }
 
@@ -129,18 +124,16 @@ public class RemoteRecoveryTargetHandler implements RecoveryTargetHandler {
 
         RecoveryFilesInfoRequest recoveryInfoFilesRequest = new RecoveryFilesInfoRequest(recoveryId, shardId,
                 phase1FileNames, phase1FileSizes, phase1ExistingFileNames, phase1ExistingFileSizes, totalTranslogOps);
-        transportService.submitRequest(targetNode, PeerRecoveryTargetService.Actions.FILES_INFO, recoveryInfoFilesRequest,
-                TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build(),
-                EmptyTransportResponseHandler.INSTANCE_SAME).txGet();
+        TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build().submitRequest(targetNode, PeerRecoveryTargetService.Actions.FILES_INFO, recoveryInfoFilesRequest,
+            EmptyTransportResponseHandler.INSTANCE_SAME, transportService).txGet();
 
     }
 
     @Override
     public void cleanFiles(int totalTranslogOps, Store.MetadataSnapshot sourceMetaData) throws IOException {
-        transportService.submitRequest(targetNode, PeerRecoveryTargetService.Actions.CLEAN_FILES,
+        TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build().submitRequest(targetNode, PeerRecoveryTargetService.Actions.CLEAN_FILES,
                 new RecoveryCleanFilesRequest(recoveryId, shardId, sourceMetaData, totalTranslogOps),
-                TransportRequestOptions.builder().withTimeout(recoverySettings.internalActionTimeout()).build(),
-                EmptyTransportResponseHandler.INSTANCE_SAME).txGet();
+            EmptyTransportResponseHandler.INSTANCE_SAME, transportService).txGet();
     }
 
     @Override
@@ -168,14 +161,14 @@ public class RemoteRecoveryTargetHandler implements RecoveryTargetHandler {
             throttleTimeInNanos = 0;
         }
 
-        transportService.submitRequest(targetNode, PeerRecoveryTargetService.Actions.FILE_CHUNK,
+        fileChunkRequestOptions.submitRequest(targetNode, PeerRecoveryTargetService.Actions.FILE_CHUNK,
             new RecoveryFileChunkRequest(recoveryId, shardId, fileMetaData, position, content, lastChunk,
                 totalTranslogOps,
                 /* we send estimateTotalOperations with every request since we collect stats on the target and that way we can
                  * see how many translog ops we accumulate while copying files across the network. A future optimization
                  * would be in to restart file copy again (new deltas) if we have too many translog ops are piling up.
                  */
-                throttleTimeInNanos), fileChunkRequestOptions, EmptyTransportResponseHandler.INSTANCE_SAME).txGet();
+                throttleTimeInNanos), EmptyTransportResponseHandler.INSTANCE_SAME, transportService).txGet();
     }
 
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/indices/store/IndicesStore.java b/es/es-server/src/main/java/org/elasticsearch/indices/store/IndicesStore.java
index c6b5270..2b1b3ce 100644
--- a/es/es-server/src/main/java/org/elasticsearch/indices/store/IndicesStore.java
+++ b/es/es-server/src/main/java/org/elasticsearch/indices/store/IndicesStore.java
@@ -135,7 +135,7 @@ public class IndicesStore implements ClusterStateListener, Closeable {
         // - closed indices don't need to be removed from the cache but we do it anyway for code simplicity
         for (Iterator<ShardId> it = folderNotFoundCache.iterator(); it.hasNext(); ) {
             ShardId shardId = it.next();
-            if (routingTable.hasIndex(shardId.getIndex()) == false) {
+            if (shardId.getIndex().hasIndex(routingTable) == false) {
                 it.remove();
             }
         }
diff --git a/es/es-server/src/main/java/org/elasticsearch/node/Node.java b/es/es-server/src/main/java/org/elasticsearch/node/Node.java
index 61e83c4..e85719f 100644
--- a/es/es-server/src/main/java/org/elasticsearch/node/Node.java
+++ b/es/es-server/src/main/java/org/elasticsearch/node/Node.java
@@ -66,7 +66,6 @@ import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.logging.DeprecationLogger;
 import org.elasticsearch.common.logging.NodeAndClusterIdStateListener;
-import org.elasticsearch.common.network.NetworkAddress;
 import org.elasticsearch.common.network.NetworkModule;
 import org.elasticsearch.common.network.NetworkService;
 import org.elasticsearch.common.settings.ClusterSettings;
@@ -133,15 +132,8 @@ import org.elasticsearch.transport.TransportInterceptor;
 import org.elasticsearch.transport.TransportService;
 
 import javax.net.ssl.SNIHostName;
-import java.io.BufferedWriter;
 import java.io.Closeable;
 import java.io.IOException;
-import java.net.InetAddress;
-import java.net.InetSocketAddress;
-import java.nio.charset.Charset;
-import java.nio.file.Files;
-import java.nio.file.Path;
-import java.nio.file.StandardCopyOption;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -731,9 +723,9 @@ public class Node implements Closeable {
 
         if (WRITE_PORTS_FILE_SETTING.get(settings)) {
             TransportService transport = injector.getInstance(TransportService.class);
-            writePortsFile("transport", transport.boundAddress());
+            transport.boundAddress().writePortsFile("transport", this);
             HttpServerTransport http = injector.getInstance(HttpServerTransport.class);
-            writePortsFile("http", http.boundAddress());
+            http.boundAddress().writePortsFile("http", this);
         }
 
         logger.info("started");
@@ -884,25 +876,6 @@ public class Node implements Closeable {
                                                        List<BootstrapCheck> bootstrapChecks) throws NodeValidationException {
     }
 
-    /** Writes a file to the logs dir containing the ports for the given transport type */
-    private void writePortsFile(String type, BoundTransportAddress boundAddress) {
-        Path tmpPortsFile = environment.logsFile().resolve(type + ".ports.tmp");
-        try (BufferedWriter writer = Files.newBufferedWriter(tmpPortsFile, Charset.forName("UTF-8"))) {
-            for (TransportAddress address : boundAddress.boundAddresses()) {
-                InetAddress inetAddress = InetAddress.getByName(address.getAddress());
-                writer.write(NetworkAddress.format(new InetSocketAddress(inetAddress, address.getPort())) + "\n");
-            }
-        } catch (IOException e) {
-            throw new RuntimeException("Failed to write ports file", e);
-        }
-        Path portsFile = environment.logsFile().resolve(type + ".ports");
-        try {
-            Files.move(tmpPortsFile, portsFile, StandardCopyOption.ATOMIC_MOVE);
-        } catch (IOException e) {
-            throw new RuntimeException("Failed to rename ports file", e);
-        }
-    }
-
     /**
      * The {@link PluginsService} used to build this node's components.
      */
diff --git a/es/es-server/src/main/java/org/elasticsearch/repositories/RepositoryData.java b/es/es-server/src/main/java/org/elasticsearch/repositories/RepositoryData.java
index 7a8d832..7d3742d 100644
--- a/es/es-server/src/main/java/org/elasticsearch/repositories/RepositoryData.java
+++ b/es/es-server/src/main/java/org/elasticsearch/repositories/RepositoryData.java
@@ -19,14 +19,17 @@
 
 package org.elasticsearch.repositories;
 
+import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.ResourceNotFoundException;
+import org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.UUIDs;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.snapshots.SnapshotId;
+import org.elasticsearch.snapshots.SnapshotInfo;
 import org.elasticsearch.snapshots.SnapshotState;
 
 import java.io.IOException;
@@ -494,4 +497,30 @@ public final class RepositoryData {
         return new RepositoryData(this.genId, this.snapshotIds, this.snapshotStates, this.indexSnapshots, incompatibleSnapshotIds);
     }
 
+    public List<SnapshotInfo> buildSimpleSnapshotInfos(final Set<SnapshotId> toResolve,
+                                                       final List<SnapshotInfo> currentSnapshots, TransportGetSnapshotsAction transportGetSnapshotsAction) {
+        List<SnapshotInfo> snapshotInfos = new ArrayList<>();
+        for (SnapshotInfo snapshotInfo : currentSnapshots) {
+            if (toResolve.remove(snapshotInfo.snapshotId())) {
+                snapshotInfos.add(snapshotInfo.basic());
+            }
+        }
+        Map<SnapshotId, List<String>> snapshotsToIndices = new HashMap<>();
+        for (IndexId indexId : getIndices().values()) {
+            for (SnapshotId snapshotId : getSnapshots(indexId)) {
+                if (toResolve.contains(snapshotId)) {
+                    snapshotsToIndices.computeIfAbsent(snapshotId, (k) -> new ArrayList<>())
+                                      .add(indexId.getName());
+                }
+            }
+        }
+        for (Map.Entry<SnapshotId, List<String>> entry : snapshotsToIndices.entrySet()) {
+            final List<String> indices = entry.getValue();
+            CollectionUtil.timSort(indices);
+            final SnapshotId snapshotId = entry.getKey();
+            snapshotInfos.add(new SnapshotInfo(snapshotId, indices, getSnapshotState(snapshotId)));
+        }
+        CollectionUtil.timSort(snapshotInfos);
+        return Collections.unmodifiableList(snapshotInfos);
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java b/es/es-server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
index bebd28f..51a6002 100644
--- a/es/es-server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
+++ b/es/es-server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
@@ -1653,7 +1653,7 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent imp
                     stream = new RateLimitingInputStream(partSliceStream, restoreRateLimiter, restoreRateLimitingTimeInNanos::inc);
                 }
 
-                try (IndexOutput indexOutput = store.createVerifyingOutput(fileInfo.physicalName(), fileInfo.metadata(), IOContext.DEFAULT)) {
+                try (IndexOutput indexOutput = fileInfo.metadata().createVerifyingOutput(fileInfo.physicalName(), IOContext.DEFAULT, store)) {
                     final byte[] buffer = new byte[BUFFER_SIZE];
                     int length;
                     while ((length = stream.read(buffer)) > 0) {
diff --git a/es/es-server/src/main/java/org/elasticsearch/rest/RestStatus.java b/es/es-server/src/main/java/org/elasticsearch/rest/RestStatus.java
index e7c07f2..10d5d88 100644
--- a/es/es-server/src/main/java/org/elasticsearch/rest/RestStatus.java
+++ b/es/es-server/src/main/java/org/elasticsearch/rest/RestStatus.java
@@ -20,6 +20,8 @@
 package org.elasticsearch.rest;
 
 import org.elasticsearch.action.ShardOperationFailedException;
+import org.elasticsearch.cluster.block.ClusterBlock;
+import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 
@@ -535,4 +537,17 @@ public enum RestStatus {
     public static RestStatus fromCode(int code) {
         return CODE_TO_STATUS.get(code);
     }
+
+    /**
+     * Is there a global block with the provided status?
+     * @param clusterBlocks
+     */
+    public boolean hasGlobalBlockWithStatus(ClusterBlocks clusterBlocks) {
+        for (ClusterBlock clusterBlock : clusterBlocks.global()) {
+            if (clusterBlock.status().equals(this)) {
+                return true;
+            }
+        }
+        return false;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/snapshots/RestoreService.java b/es/es-server/src/main/java/org/elasticsearch/snapshots/RestoreService.java
index 5cb927b..897b428 100644
--- a/es/es-server/src/main/java/org/elasticsearch/snapshots/RestoreService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/snapshots/RestoreService.java
@@ -195,7 +195,7 @@ public class RestoreService implements ClusterStateApplier {
             final Snapshot snapshot = new Snapshot(request.repositoryName, snapshotId);
 
             // Make sure that we can restore from this snapshot
-            validateSnapshotRestorable(request.repositoryName, snapshotInfo);
+            snapshotInfo.validateSnapshotRestorable(request.repositoryName, this);
 
             // Resolve the indices from the snapshot that need to be restored
             final List<String> indicesInSnapshot = filterIndices(snapshotInfo.indices(), request.indices(), request.indicesOptions());
@@ -809,24 +809,6 @@ public class RestoreService implements ClusterStateApplier {
         return Collections.unmodifiableMap(renamedIndices);
     }
 
-    /**
-     * Checks that snapshots can be restored and have compatible version
-     *
-     * @param repository      repository name
-     * @param snapshotInfo    snapshot metadata
-     */
-    private void validateSnapshotRestorable(final String repository, final SnapshotInfo snapshotInfo) {
-        if (!snapshotInfo.state().restorable()) {
-            throw new SnapshotRestoreException(new Snapshot(repository, snapshotInfo.snapshotId()),
-                                               "unsupported snapshot state [" + snapshotInfo.state() + "]");
-        }
-        if (Version.CURRENT.before(snapshotInfo.version())) {
-            throw new SnapshotRestoreException(new Snapshot(repository, snapshotInfo.snapshotId()),
-                                               "the snapshot was created with CrateDB version [" + snapshotInfo.version() +
-                                                   "] which is higher than the version of this node [" + Version.CURRENT + "]");
-        }
-    }
-
     private boolean failed(SnapshotInfo snapshot, String index) {
         for (SnapshotShardFailure failure : snapshot.shardFailures()) {
             if (index.equals(failure.index())) {
diff --git a/es/es-server/src/main/java/org/elasticsearch/snapshots/Snapshot.java b/es/es-server/src/main/java/org/elasticsearch/snapshots/Snapshot.java
index 314cd40..bee55a4 100644
--- a/es/es-server/src/main/java/org/elasticsearch/snapshots/Snapshot.java
+++ b/es/es-server/src/main/java/org/elasticsearch/snapshots/Snapshot.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.snapshots;
 
+import org.elasticsearch.cluster.SnapshotsInProgress;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Writeable;
@@ -99,4 +100,13 @@ public final class Snapshot implements Writeable {
         snapshotId.writeTo(out);
     }
 
+    public SnapshotsInProgress.Entry snapshot(SnapshotsInProgress snapshotsInProgress) {
+        for (SnapshotsInProgress.Entry entry : snapshotsInProgress.entries()) {
+            final Snapshot curr = entry.snapshot();
+            if (curr.equals(this)) {
+                return entry;
+            }
+        }
+        return null;
+    }
 }
diff --git a/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java b/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java
index c514e8f..e94569a 100644
--- a/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java
+++ b/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java
@@ -79,6 +79,23 @@ public final class SnapshotInfo implements Comparable<SnapshotInfo>, ToXContent,
     private static final Comparator<SnapshotInfo> COMPARATOR =
         Comparator.comparing(SnapshotInfo::startTime).thenComparing(SnapshotInfo::snapshotId);
 
+    /**
+     * Checks that snapshots can be restored and have compatible version
+     *  @param repository      repository name
+     * @param restoreService
+     */
+    public void validateSnapshotRestorable(final String repository, RestoreService restoreService) {
+        if (!state().restorable()) {
+            throw new SnapshotRestoreException(new Snapshot(repository, snapshotId()),
+                                               "unsupported snapshot state [" + state() + "]");
+        }
+        if (Version.CURRENT.before(version())) {
+            throw new SnapshotRestoreException(new Snapshot(repository, snapshotId()),
+                                               "the snapshot was created with CrateDB version [" + version() +
+                                                   "] which is higher than the version of this node [" + Version.CURRENT + "]");
+        }
+    }
+
     public static final class SnapshotInfoBuilder {
         private String snapshotName = null;
         private String snapshotUUID = null;
diff --git a/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java b/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
index 9bd42f1..bd9cd7e 100644
--- a/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
@@ -219,7 +219,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent implements
         while (it.hasNext()) {
             final Map.Entry<Snapshot, Map<ShardId, IndexShardSnapshotStatus>> entry = it.next();
             final Snapshot snapshot = entry.getKey();
-            if (snapshotsInProgress == null || snapshotsInProgress.snapshot(snapshot) == null) {
+            if (snapshotsInProgress == null || snapshot.snapshot(snapshotsInProgress) == null) {
                 // abort any running snapshots of shards for the removed entry;
                 // this could happen if for some reason the cluster state update for aborting
                 // running shards is missed, then the snapshot is removed is a subsequent cluster
diff --git a/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java b/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
index 6526f57..d70324b 100644
--- a/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
@@ -498,7 +498,7 @@ public class SnapshotsService extends AbstractLifecycleComponent implements Clus
                         if (hadAbortedInitializations) {
                             final SnapshotsInProgress snapshotsInProgress = newState.custom(SnapshotsInProgress.TYPE);
                             assert snapshotsInProgress != null;
-                            final SnapshotsInProgress.Entry entry = snapshotsInProgress.snapshot(snapshot.snapshot());
+                            final SnapshotsInProgress.Entry entry = snapshot.snapshot().snapshot(snapshotsInProgress);
                             assert entry != null;
                             endSnapshot(entry);
                         }
@@ -1155,7 +1155,7 @@ public class SnapshotsService extends AbstractLifecycleComponent implements Clus
                 }
                 ClusterState.Builder clusterStateBuilder = ClusterState.builder(currentState);
                 SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);
-                SnapshotsInProgress.Entry snapshotEntry = snapshots != null ? snapshots.snapshot(snapshot) : null;
+                SnapshotsInProgress.Entry snapshotEntry = snapshots != null ? snapshot.snapshot(snapshots) : null;
                 if (snapshotEntry == null) {
                     // This snapshot is not running - delete
                     if (snapshots != null && !snapshots.entries().isEmpty()) {
diff --git a/es/es-server/src/main/java/org/elasticsearch/transport/TransportRequestOptions.java b/es/es-server/src/main/java/org/elasticsearch/transport/TransportRequestOptions.java
index 879d6ae..a8d916e 100644
--- a/es/es-server/src/main/java/org/elasticsearch/transport/TransportRequestOptions.java
+++ b/es/es-server/src/main/java/org/elasticsearch/transport/TransportRequestOptions.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.transport;
 
+import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.unit.TimeValue;
 
 public class TransportRequestOptions {
@@ -47,6 +48,19 @@ public class TransportRequestOptions {
 
     public static final TransportRequestOptions EMPTY = new TransportRequestOptions.Builder().build();
 
+    public <T extends TransportResponse> TransportFuture<T> submitRequest(DiscoveryNode node, String action, TransportRequest request,
+                                                                          TransportResponseHandler<T> handler, TransportService transportService) throws TransportException {
+        PlainTransportFuture<T> futureHandler = new PlainTransportFuture<>(handler);
+        try {
+            Transport.Connection connection = transportService.getConnection(node);
+            transportService.sendRequest(connection, action, request, this, futureHandler);
+        } catch (NodeNotConnectedException ex) {
+            // the caller might not handle this so we invoke the handler
+            futureHandler.handleException(ex);
+        }
+        return futureHandler;
+    }
+
     public enum Type {
         RECOVERY,
         BULK,
diff --git a/es/es-server/src/main/java/org/elasticsearch/transport/TransportService.java b/es/es-server/src/main/java/org/elasticsearch/transport/TransportService.java
index b429edc..aa008be 100644
--- a/es/es-server/src/main/java/org/elasticsearch/transport/TransportService.java
+++ b/es/es-server/src/main/java/org/elasticsearch/transport/TransportService.java
@@ -479,21 +479,7 @@ public class TransportService extends AbstractLifecycleComponent implements Tran
 
     public <T extends TransportResponse> TransportFuture<T> submitRequest(DiscoveryNode node, String action, TransportRequest request,
                                                                           TransportResponseHandler<T> handler) throws TransportException {
-        return submitRequest(node, action, request, TransportRequestOptions.EMPTY, handler);
-    }
-
-    public <T extends TransportResponse> TransportFuture<T> submitRequest(DiscoveryNode node, String action, TransportRequest request,
-                                                                          TransportRequestOptions options,
-                                                                          TransportResponseHandler<T> handler) throws TransportException {
-        PlainTransportFuture<T> futureHandler = new PlainTransportFuture<>(handler);
-        try {
-            Transport.Connection connection = getConnection(node);
-            sendRequest(connection, action, request, options, futureHandler);
-        } catch (NodeNotConnectedException ex) {
-            // the caller might not handle this so we invoke the handler
-            futureHandler.handleException(ex);
-        }
-        return futureHandler;
+        return TransportRequestOptions.EMPTY.submitRequest(node, action, request, handler, this);
     }
 
     public <T extends TransportResponse> void sendRequest(final DiscoveryNode node, final String action,
diff --git a/es/es-server/src/test/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequestTests.java b/es/es-server/src/test/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequestTests.java
index 52a5e7d..5eeec76 100644
--- a/es/es-server/src/test/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequestTests.java
+++ b/es/es-server/src/test/java/org/elasticsearch/action/admin/cluster/configuration/AddVotingConfigExclusionsRequestTests.java
@@ -70,17 +70,17 @@ public class AddVotingConfigExclusionsRequestTests extends ESTestCase {
         final ClusterState clusterState = ClusterState.builder(new ClusterName("cluster")).nodes(new Builder()
             .add(localNode).add(otherNode1).add(otherNode2).add(otherDataNode).localNodeId(localNode.getId())).build();
 
-        assertThat(makeRequest().resolveVotingConfigExclusions(clusterState),
+        assertThat(clusterState.resolveVotingConfigExclusions(makeRequest()),
                 containsInAnyOrder(localNodeExclusion, otherNode1Exclusion, otherNode2Exclusion));
-        assertThat(makeRequest("_all").resolveVotingConfigExclusions(clusterState),
+        assertThat(clusterState.resolveVotingConfigExclusions(makeRequest("_all")),
                 containsInAnyOrder(localNodeExclusion, otherNode1Exclusion, otherNode2Exclusion));
-        assertThat(makeRequest("_local").resolveVotingConfigExclusions(clusterState),
+        assertThat(clusterState.resolveVotingConfigExclusions(makeRequest("_local")),
                 contains(localNodeExclusion));
-        assertThat(makeRequest("other*").resolveVotingConfigExclusions(clusterState),
+        assertThat(clusterState.resolveVotingConfigExclusions(makeRequest("other*")),
                 containsInAnyOrder(otherNode1Exclusion, otherNode2Exclusion));
 
         assertThat(expectThrows(IllegalArgumentException.class,
-                () -> makeRequest("not-a-node").resolveVotingConfigExclusions(clusterState)).getMessage(),
+                () -> clusterState.resolveVotingConfigExclusions(makeRequest("not-a-node"))).getMessage(),
                     equalTo("add voting config exclusions request for [not-a-node] matched no master-eligible nodes"));
     }
 
diff --git a/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/CoordinatorTests.java b/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/CoordinatorTests.java
index 04e7a42..7c4c368 100644
--- a/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/CoordinatorTests.java
+++ b/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/CoordinatorTests.java
@@ -70,13 +70,11 @@ import org.elasticsearch.discovery.DiscoveryModule;
 import org.elasticsearch.discovery.SeedHostsProvider.HostsResolver;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.gateway.MetaStateService;
-import org.elasticsearch.gateway.MockGatewayMetaState;
 import org.elasticsearch.indices.cluster.FakeThreadPoolMasterService;
 import org.elasticsearch.test.ESTestCase;
 import org.elasticsearch.test.MockLogAppender;
 import org.elasticsearch.test.disruption.DisruptableMockTransport;
 import org.elasticsearch.test.disruption.DisruptableMockTransport.ConnectionStatus;
-import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.elasticsearch.transport.TransportService;
 import org.hamcrest.Matcher;
 import org.hamcrest.core.IsCollectionContaining;
@@ -1715,8 +1713,7 @@ public class CoordinatorTests extends ESTestCase {
                     if (rarely()) {
                         nodeEnvironment = newNodeEnvironment();
                         nodeEnvironments.add(nodeEnvironment);
-                        delegate = new MockGatewayMetaState(Settings.EMPTY, nodeEnvironment, xContentRegistry(), localNode)
-                                .getPersistedState(Settings.EMPTY, null);
+                        delegate = null.getPersistedState(Settings.EMPTY);
                     } else {
                         nodeEnvironment = null;
                         delegate = new InMemoryPersistedState(0L,
@@ -1744,8 +1741,7 @@ public class CoordinatorTests extends ESTestCase {
                                 new Manifest(updatedTerm, manifest.getClusterStateVersion(), manifest.getGlobalGeneration(),
                                     manifest.getIndexGenerations()));
                         }
-                        delegate = new MockGatewayMetaState(Settings.EMPTY, nodeEnvironment, xContentRegistry(), newLocalNode)
-                                .getPersistedState(Settings.EMPTY, null);
+                        delegate = null.getPersistedState(Settings.EMPTY);
                     } else {
                         nodeEnvironment = null;
                         BytesStreamOutput outStream = new BytesStreamOutput();
diff --git a/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java b/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java
index a57810b..28a1f5f 100644
--- a/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java
+++ b/es/es-server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java
@@ -92,7 +92,7 @@ public class FollowersCheckerTests extends ESTestCase {
             protected void onSendRequest(long requestId, String action, TransportRequest request, DiscoveryNode node) {
                 assertThat(action, equalTo(FOLLOWER_CHECK_ACTION_NAME));
                 assertThat(request, instanceOf(FollowerCheckRequest.class));
-                assertTrue(discoveryNodesHolder[0].nodeExists(node));
+                assertTrue(node.nodeExists(discoveryNodesHolder[0]));
                 assertThat(node, not(equalTo(localNode)));
                 checkedNodes.add(node);
                 checkCount.incrementAndGet();
diff --git a/es/es-testing/src/main/java/org/elasticsearch/index/analysis/AnalysisTestsHelper.java b/es/es-testing/src/main/java/org/elasticsearch/index/analysis/AnalysisTestsHelper.java
index a7153f9..018e43c 100644
--- a/es/es-testing/src/main/java/org/elasticsearch/index/analysis/AnalysisTestsHelper.java
+++ b/es/es-testing/src/main/java/org/elasticsearch/index/analysis/AnalysisTestsHelper.java
@@ -64,7 +64,7 @@ public class AnalysisTestsHelper {
         final IndexSettings indexSettings = IndexSettingsModule.newIndexSettings("test", actualSettings);
         final AnalysisRegistry analysisRegistry =
                 new AnalysisModule(new Environment(actualSettings, configPath), Arrays.asList(plugins)).getAnalysisRegistry();
-        return new ESTestCase.TestAnalysis(analysisRegistry.build(indexSettings),
+        return new ESTestCase.TestAnalysis(indexSettings.build(analysisRegistry),
                 analysisRegistry.buildTokenFilterFactories(indexSettings),
                 analysisRegistry.buildTokenizerFactories(indexSettings),
                 analysisRegistry.buildCharFilterFactories(indexSettings));
diff --git a/es/es-testing/src/main/java/org/elasticsearch/test/ESTestCase.java b/es/es-testing/src/main/java/org/elasticsearch/test/ESTestCase.java
index 53ee907..0e54791 100644
--- a/es/es-testing/src/main/java/org/elasticsearch/test/ESTestCase.java
+++ b/es/es-testing/src/main/java/org/elasticsearch/test/ESTestCase.java
@@ -1332,7 +1332,7 @@ public abstract class ESTestCase extends LuceneTestCase {
         Environment env = TestEnvironment.newEnvironment(nodeSettings);
         AnalysisModule analysisModule = new AnalysisModule(env, Arrays.asList(analysisPlugins));
         AnalysisRegistry analysisRegistry = analysisModule.getAnalysisRegistry();
-        return new TestAnalysis(analysisRegistry.build(indexSettings),
+        return new TestAnalysis(indexSettings.build(analysisRegistry),
             analysisRegistry.buildTokenFilterFactories(indexSettings),
             analysisRegistry.buildTokenizerFactories(indexSettings),
             analysisRegistry.buildCharFilterFactories(indexSettings));
diff --git a/es/es-testing/src/main/java/org/elasticsearch/test/InternalTestCluster.java b/es/es-testing/src/main/java/org/elasticsearch/test/InternalTestCluster.java
index 00735b0..a256c8c 100644
--- a/es/es-testing/src/main/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/es/es-testing/src/main/java/org/elasticsearch/test/InternalTestCluster.java
@@ -1072,7 +1072,7 @@ public final class InternalTestCluster extends TestCluster {
                     return false;
                 }
                 for (DiscoveryNode expectedNode : expectedNodes) {
-                    if (discoveryNodes.nodeExists(expectedNode) == false) {
+                    if (expectedNode.nodeExists(discoveryNodes) == false) {
                         return false;
                     }
                 }
diff --git a/http/src/main/java/io/crate/protocols/http/MainAndStaticFileHandler.java b/http/src/main/java/io/crate/protocols/http/MainAndStaticFileHandler.java
index bf6236d..c99c023 100644
--- a/http/src/main/java/io/crate/protocols/http/MainAndStaticFileHandler.java
+++ b/http/src/main/java/io/crate/protocols/http/MainAndStaticFileHandler.java
@@ -141,7 +141,7 @@ public class MainAndStaticFileHandler extends SimpleChannelInboundHandler<FullHt
                                                                    ClusterStateResponse response,
                                                                    ByteBufAllocator alloc,
                                                                    @Nullable String nodeName) {
-        var httpStatus = response.getState().blocks().hasGlobalBlockWithStatus(RestStatus.SERVICE_UNAVAILABLE)
+        var httpStatus = RestStatus.SERVICE_UNAVAILABLE.hasGlobalBlockWithStatus(response.getState().blocks())
             ? HttpResponseStatus.SERVICE_UNAVAILABLE
             : HttpResponseStatus.OK;
         try {
diff --git a/sql/src/main/java/io/crate/analyze/AbstractInsertAnalyzedStatement.java b/sql/src/main/java/io/crate/analyze/AbstractInsertAnalyzedStatement.java
index dde3856..96e2e29 100644
--- a/sql/src/main/java/io/crate/analyze/AbstractInsertAnalyzedStatement.java
+++ b/sql/src/main/java/io/crate/analyze/AbstractInsertAnalyzedStatement.java
@@ -93,7 +93,7 @@ public abstract class AbstractInsertAnalyzedStatement implements AnalyzedStateme
         if (ref == null) {
             ref = tableInfo.indexColumn(column);
             if (ref == null) {
-                DynamicReference reference = tableInfo.getDynamic(column, true);
+                DynamicReference reference = column.getDynamic(true, tableInfo);
                 if (reference == null) {
                     throw new ColumnUnknownException(column.sqlFqn(), tableInfo.ident());
                 }
diff --git a/sql/src/main/java/io/crate/analyze/AlterTableAnalyzer.java b/sql/src/main/java/io/crate/analyze/AlterTableAnalyzer.java
index 9b8a18f..c722948 100644
--- a/sql/src/main/java/io/crate/analyze/AlterTableAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/AlterTableAnalyzer.java
@@ -78,7 +78,7 @@ public class AlterTableAnalyzer {
             relationName = schemas.resolveRelation(node.table().getName(), sessionContext.searchPath());
         }
 
-        DocTableInfo tableInfo = schemas.getTableInfo(relationName, Operation.ALTER_TABLE_RENAME);
+        DocTableInfo tableInfo = relationName.getTableInfo(Operation.ALTER_TABLE_RENAME, schemas);
         RelationName newRelationName = new RelationName(relationName.schema(), newIdentParts.get(0));
         newRelationName.ensureValidForRelationCreation();
         return new AlterTableRenameAnalyzedStatement(tableInfo, newRelationName);
diff --git a/sql/src/main/java/io/crate/analyze/AlterTableOpenCloseAnalyzer.java b/sql/src/main/java/io/crate/analyze/AlterTableOpenCloseAnalyzer.java
index 814319b..00a41e1 100644
--- a/sql/src/main/java/io/crate/analyze/AlterTableOpenCloseAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/AlterTableOpenCloseAnalyzer.java
@@ -51,7 +51,7 @@ class AlterTableOpenCloseAnalyzer {
             relationName = schemas.resolveRelation(table.getName(), sessionContext.searchPath());
         }
 
-        DocTableInfo tableInfo = schemas.getTableInfo(relationName, Operation.ALTER_OPEN_CLOSE);
+        DocTableInfo tableInfo = relationName.getTableInfo(Operation.ALTER_OPEN_CLOSE, schemas);
         PartitionName partitionName = null;
         if (tableInfo.isPartitioned()) {
             partitionName = AlterTableAnalyzer.createPartitionName(table.partitionProperties(), tableInfo, null);
diff --git a/sql/src/main/java/io/crate/analyze/AlterTableRerouteAnalyzer.java b/sql/src/main/java/io/crate/analyze/AlterTableRerouteAnalyzer.java
index 6764165..0f6bb82 100644
--- a/sql/src/main/java/io/crate/analyze/AlterTableRerouteAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/AlterTableRerouteAnalyzer.java
@@ -55,7 +55,7 @@ public class AlterTableRerouteAnalyzer {
         } else {
             relationName = schemas.resolveRelation(node.table().getName(), context.sessionContext().searchPath());
         }
-        tableInfo = schemas.getTableInfo(relationName, Operation.ALTER_REROUTE);
+        tableInfo = relationName.getTableInfo(Operation.ALTER_REROUTE, schemas);
         return REROUTE_OPTION_VISITOR.process(node.rerouteOption(), new Context(tableInfo, node.table().partitionProperties()));
     }
 
diff --git a/sql/src/main/java/io/crate/analyze/CreateTableAnalyzedStatement.java b/sql/src/main/java/io/crate/analyze/CreateTableAnalyzedStatement.java
index 8b9b41c..de92519 100644
--- a/sql/src/main/java/io/crate/analyze/CreateTableAnalyzedStatement.java
+++ b/sql/src/main/java/io/crate/analyze/CreateTableAnalyzedStatement.java
@@ -22,10 +22,12 @@
 package io.crate.analyze;
 
 import io.crate.exceptions.RelationAlreadyExists;
+import io.crate.execution.ddl.tables.TableCreator;
 import io.crate.metadata.ColumnIdent;
 import io.crate.metadata.PartitionName;
 import io.crate.metadata.RelationName;
 import io.crate.metadata.Schemas;
+import org.elasticsearch.common.settings.Settings;
 
 import javax.annotation.Nullable;
 import java.util.Collection;
@@ -158,4 +160,7 @@ public class CreateTableAnalyzedStatement extends AbstractDDLAnalyzedStatement {
         return analyzedTableElements;
     }
 
+    public Settings settings(TableCreator tableCreator) {
+        return tableParameter().settings();
+    }
 }
diff --git a/sql/src/main/java/io/crate/analyze/InsertFromSubQueryAnalyzer.java b/sql/src/main/java/io/crate/analyze/InsertFromSubQueryAnalyzer.java
index fd77fbb..8f7097c 100644
--- a/sql/src/main/java/io/crate/analyze/InsertFromSubQueryAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/InsertFromSubQueryAnalyzer.java
@@ -176,7 +176,7 @@ class InsertFromSubQueryAnalyzer {
             Reference reference = targetTable.getReference(columnIdent);
             Reference targetReference;
             if (reference == null) {
-                DynamicReference dynamicReference = targetTable.getDynamic(columnIdent, true);
+                DynamicReference dynamicReference = columnIdent.getDynamic(true, targetTable);
                 if (dynamicReference == null) {
                     throw new ColumnUnknownException(targetColumnName, targetTable.ident());
                 }
diff --git a/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzedStatement.java b/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzedStatement.java
index 359a81f..0a486c3 100644
--- a/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzedStatement.java
+++ b/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzedStatement.java
@@ -158,11 +158,6 @@ public class InsertFromValuesAnalyzedStatement extends AbstractInsertAnalyzedSta
         return numBulkResponses;
     }
 
-    public void addGeneratedColumn(Reference reference) {
-        columns().add(reference);
-        numAddedGeneratedColumns++;
-    }
-
     public int numAddedGeneratedColumns() {
         return numAddedGeneratedColumns;
     }
diff --git a/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzer.java b/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzer.java
index 486323c..e47e85e 100644
--- a/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/InsertFromValuesAnalyzer.java
@@ -579,7 +579,7 @@ class InsertFromValuesAnalyzer extends AbstractInsertAnalyzer {
         int idx = context.columns().indexOf(reference);
         if (idx == -1) {
             // add column & value
-            context.addGeneratedColumn(reference);
+            reference.addGeneratedColumn(context);
             int valuesIdx = insertValues.length;
             insertValues = Arrays.copyOf(insertValues, insertValues.length + 1);
             insertValues[valuesIdx] = value;
diff --git a/sql/src/main/java/io/crate/analyze/RestoreSnapshotAnalyzer.java b/sql/src/main/java/io/crate/analyze/RestoreSnapshotAnalyzer.java
index 732b1cb..1b6267f 100644
--- a/sql/src/main/java/io/crate/analyze/RestoreSnapshotAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/RestoreSnapshotAnalyzer.java
@@ -77,7 +77,7 @@ class RestoreSnapshotAnalyzer {
                         throw new RelationAlreadyExists(relationName);
                     }
 
-                    DocTableInfo docTableInfo = schemas.getTableInfo(relationName, Operation.RESTORE_SNAPSHOT);
+                    DocTableInfo docTableInfo = relationName.getTableInfo(Operation.RESTORE_SNAPSHOT, schemas);
                     PartitionName partitionName = PartitionPropertiesAnalyzer.toPartitionName(
                         relationName,
                         docTableInfo,
diff --git a/sql/src/main/java/io/crate/analyze/expressions/ExpressionAnalyzer.java b/sql/src/main/java/io/crate/analyze/expressions/ExpressionAnalyzer.java
index da2886b..3443a2e 100644
--- a/sql/src/main/java/io/crate/analyze/expressions/ExpressionAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/expressions/ExpressionAnalyzer.java
@@ -28,17 +28,12 @@ import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Multimap;
 import io.crate.action.sql.Option;
-import io.crate.analyze.DataTypeAnalyzer;
-import io.crate.analyze.FrameBoundDefinition;
-import io.crate.analyze.NegateLiterals;
-import io.crate.analyze.OrderBy;
-import io.crate.analyze.SubscriptContext;
-import io.crate.analyze.SubscriptValidator;
-import io.crate.analyze.WindowDefinition;
-import io.crate.analyze.WindowFrameDefinition;
+import io.crate.analyze.*;
 import io.crate.analyze.relations.AnalyzedRelation;
 import io.crate.analyze.relations.FieldProvider;
 import io.crate.analyze.relations.OrderyByAnalyzer;
+import io.crate.analyze.relations.RelationAnalyzer;
+import io.crate.analyze.validator.HavingSymbolValidator;
 import io.crate.analyze.validator.SemanticSortValidator;
 import io.crate.exceptions.ColumnUnknownException;
 import io.crate.exceptions.ConversionException;
@@ -391,6 +386,20 @@ public class ExpressionAnalyzer {
         }
     }
 
+    public HavingClause analyzeHaving(Optional<Expression> having,
+                                      @Nullable List<Symbol> groupBy,
+                                      ExpressionAnalysisContext expressionAnalysisContext, RelationAnalyzer relationAnalyzer) {
+        if (having.isPresent()) {
+            if (!expressionAnalysisContext.hasAggregates() && (groupBy == null || groupBy.isEmpty())) {
+                throw new IllegalArgumentException("HAVING clause can only be used in GROUP BY or global aggregate queries");
+            }
+            Symbol symbol = convert(having.get(), expressionAnalysisContext);
+            HavingSymbolValidator.validate(symbol, groupBy);
+            return new HavingClause(symbol);
+        }
+        return null;
+    }
+
     private class InnerExpressionAnalyzer extends AstVisitor<Symbol, ExpressionAnalysisContext> {
 
         @Override
diff --git a/sql/src/main/java/io/crate/analyze/expressions/ValueNormalizer.java b/sql/src/main/java/io/crate/analyze/expressions/ValueNormalizer.java
index e0abbf5..0bc1645 100644
--- a/sql/src/main/java/io/crate/analyze/expressions/ValueNormalizer.java
+++ b/sql/src/main/java/io/crate/analyze/expressions/ValueNormalizer.java
@@ -122,7 +122,7 @@ public final class ValueNormalizer {
                 }
                 DynamicReference dynamicReference = null;
                 if (tableInfo instanceof DocTableInfo) {
-                    dynamicReference = ((DocTableInfo) tableInfo).getDynamic(nestedIdent, true);
+                    dynamicReference = nestedIdent.getDynamic(true, ((DocTableInfo) tableInfo));
                 }
                 if (dynamicReference == null) {
                     throw new ColumnUnknownException(nestedIdent.sqlFqn(), tableInfo.ident());
diff --git a/sql/src/main/java/io/crate/analyze/relations/DocTableRelation.java b/sql/src/main/java/io/crate/analyze/relations/DocTableRelation.java
index 7c9b1e9..8042914 100644
--- a/sql/src/main/java/io/crate/analyze/relations/DocTableRelation.java
+++ b/sql/src/main/java/io/crate/analyze/relations/DocTableRelation.java
@@ -61,8 +61,8 @@ public class DocTableRelation extends AbstractTableRelation<DocTableInfo> {
         if (reference == null) {
             reference = tableInfo.indexColumn(path);
             if (reference == null) {
-                DynamicReference dynamic = tableInfo.getDynamic(path,
-                    operation == Operation.INSERT || operation == Operation.UPDATE);
+                DynamicReference dynamic = path.getDynamic(
+                    operation == Operation.INSERT || operation == Operation.UPDATE, tableInfo);
                 if (dynamic == null) {
                     return null;
                 } else {
diff --git a/sql/src/main/java/io/crate/analyze/relations/RelationAnalyzer.java b/sql/src/main/java/io/crate/analyze/relations/RelationAnalyzer.java
index 6b580a9..cf96646 100644
--- a/sql/src/main/java/io/crate/analyze/relations/RelationAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/relations/RelationAnalyzer.java
@@ -24,7 +24,6 @@ package io.crate.analyze.relations;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Multimap;
-import io.crate.analyze.HavingClause;
 import io.crate.analyze.MultiSourceSelect;
 import io.crate.analyze.OrderBy;
 import io.crate.analyze.ParamTypeHints;
@@ -39,7 +38,6 @@ import io.crate.analyze.expressions.SubqueryAnalyzer;
 import io.crate.analyze.relations.select.SelectAnalysis;
 import io.crate.analyze.relations.select.SelectAnalyzer;
 import io.crate.analyze.validator.GroupBySymbolValidator;
-import io.crate.analyze.validator.HavingSymbolValidator;
 import io.crate.analyze.validator.SemanticSortValidator;
 import io.crate.exceptions.AmbiguousColumnAliasException;
 import io.crate.exceptions.ColumnUnknownException;
@@ -170,7 +168,7 @@ public class RelationAnalyzer extends DefaultTraversalVisitor<AnalyzedRelation,
                 expressionAnalyzer,
                 expressionAnalysisContext);
             for (Field field : childRelationFields) {
-                selectAnalysis.add(field.path(), field);
+                field.add(field.path(), selectAnalysis);
             }
 
             return new OrderedLimitedRelation(
@@ -322,12 +320,11 @@ public class RelationAnalyzer extends DefaultTraversalVisitor<AnalyzedRelation,
             selectAnalysis.outputSymbols(),
             whereClause,
             groupBy,
-            analyzeHaving(
+            expressionAnalyzer.analyzeHaving(
                 node.getHaving(),
                 groupBy,
-                expressionAnalyzer,
-                context.expressionAnalysisContext()
-            ),
+                context.expressionAnalysisContext(),
+                this),
             analyzeOrderBy(
                 selectAnalysis,
                 node.getOrderBy(),
@@ -451,21 +448,6 @@ public class RelationAnalyzer extends DefaultTraversalVisitor<AnalyzedRelation,
         return groupBySymbols;
     }
 
-    private HavingClause analyzeHaving(Optional<Expression> having,
-                                       @Nullable List<Symbol> groupBy,
-                                       ExpressionAnalyzer expressionAnalyzer,
-                                       ExpressionAnalysisContext expressionAnalysisContext) {
-        if (having.isPresent()) {
-            if (!expressionAnalysisContext.hasAggregates() && (groupBy == null || groupBy.isEmpty())) {
-                throw new IllegalArgumentException("HAVING clause can only be used in GROUP BY or global aggregate queries");
-            }
-            Symbol symbol = expressionAnalyzer.convert(having.get(), expressionAnalysisContext);
-            HavingSymbolValidator.validate(symbol, groupBy);
-            return new HavingClause(symbol);
-        }
-        return null;
-    }
-
     /**
      * <h2>resolve expression by also taking alias and ordinal-reference into account</h2>
      * <p>
diff --git a/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalysis.java b/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalysis.java
index 5f58d13..440ba99 100644
--- a/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalysis.java
+++ b/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalysis.java
@@ -82,9 +82,4 @@ public class SelectAnalysis {
         return outputMultiMap;
     }
 
-    public void add(ColumnIdent path, Symbol symbol) {
-        outputNames.add(path);
-        outputSymbols.add(symbol);
-        outputMultiMap.put(path.sqlFqn(), symbol);
-    }
 }
diff --git a/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalyzer.java b/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalyzer.java
index 5da6da7..28c65ff 100644
--- a/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalyzer.java
+++ b/sql/src/main/java/io/crate/analyze/relations/select/SelectAnalyzer.java
@@ -60,9 +60,9 @@ public class SelectAnalyzer {
         protected Void visitSingleColumn(SingleColumn node, SelectAnalysis context) {
             Symbol symbol = context.toSymbol(node.getExpression());
             if (node.getAlias() != null) {
-                context.add(new ColumnIdent(node.getAlias()), symbol);
+                symbol.add(new ColumnIdent(node.getAlias()), context);
             } else {
-                context.add(new ColumnIdent(OutputNameFormatter.format(node.getExpression())), symbol);
+                symbol.add(new ColumnIdent(OutputNameFormatter.format(node.getExpression())), context);
             }
             return null;
         }
@@ -112,7 +112,7 @@ public class SelectAnalyzer {
 
         private static void addAllFieldsFromRelation(SelectAnalysis context, AnalyzedRelation relation) {
             for (Field field : relation.fields()) {
-                context.add(field.path(), field);
+                field.add(field.path(), context);
             }
         }
     }
diff --git a/sql/src/main/java/io/crate/execution/ddl/tables/AlterTableOperation.java b/sql/src/main/java/io/crate/execution/ddl/tables/AlterTableOperation.java
index 7a01a5e..17d5fe3 100644
--- a/sql/src/main/java/io/crate/execution/ddl/tables/AlterTableOperation.java
+++ b/sql/src/main/java/io/crate/execution/ddl/tables/AlterTableOperation.java
@@ -359,7 +359,7 @@ public class AlterTableOperation {
         }
         request.setResizeType(targetNumberOfShards > currentNumShards ? ResizeType.SPLIT : ResizeType.SHRINK);
         request.setCopySettings(Boolean.TRUE);
-        request.setWaitForActiveShards(ActiveShardCount.ONE);
+        ActiveShardCount.ONE.setWaitForActiveShards(request);
         FutureActionListener<ResizeResponse, Long> listener =
             new FutureActionListener<>(resp -> resp.isAcknowledged() ? 1L : 0L);
 
@@ -457,16 +457,15 @@ public class AlterTableOperation {
         Settings settings = settingsBuilder.build()
             .filter(k -> indexScopedSettings.isPrivateSetting(k) == false);
 
-        PutIndexTemplateRequest request = new PutIndexTemplateRequest(templateName)
+        PutIndexTemplateRequest request = new Alias(relationName.indexNameOrAlias()).alias(new PutIndexTemplateRequest(templateName)
             .create(false)
             .mapping(Constants.DEFAULT_MAPPING_TYPE, mapping)
             .order(indexTemplateMetaData.order())
             .settings(settings)
-            .patterns(indexTemplateMetaData.getPatterns())
-            .alias(new Alias(relationName.indexNameOrAlias()));
+            .patterns(indexTemplateMetaData.getPatterns()));
         for (ObjectObjectCursor<String, AliasMetaData> container : indexTemplateMetaData.aliases()) {
             Alias alias = new Alias(container.key);
-            request.alias(alias);
+            alias.alias(request);
         }
         return request;
     }
diff --git a/sql/src/main/java/io/crate/execution/ddl/tables/TableCreator.java b/sql/src/main/java/io/crate/execution/ddl/tables/TableCreator.java
index 9e06f4d..8b7da7e 100644
--- a/sql/src/main/java/io/crate/execution/ddl/tables/TableCreator.java
+++ b/sql/src/main/java/io/crate/execution/ddl/tables/TableCreator.java
@@ -46,7 +46,6 @@ import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Singleton;
-import org.elasticsearch.common.settings.Settings;
 
 import java.util.Collections;
 import java.util.Locale;
@@ -86,22 +85,17 @@ public class TableCreator {
     }
 
     private CreateIndexRequest createIndexRequest(CreateTableAnalyzedStatement statement) {
-        return new CreateIndexRequest(statement.tableIdent().indexNameOrAlias(), settings(statement))
+        return new CreateIndexRequest(statement.tableIdent().indexNameOrAlias(), statement.settings(this))
             .mapping(Constants.DEFAULT_MAPPING_TYPE, statement.mapping());
     }
 
-    private Settings settings(CreateTableAnalyzedStatement statement) {
-        return statement.tableParameter().settings();
-    }
-
     private PutIndexTemplateRequest createTemplateRequest(CreateTableAnalyzedStatement statement) {
-        return new PutIndexTemplateRequest(statement.templateName())
+        return new Alias(statement.tableIdent().indexNameOrAlias()).alias(new PutIndexTemplateRequest(statement.templateName())
             .mapping(Constants.DEFAULT_MAPPING_TYPE, statement.mapping())
             .create(true)
-            .settings(settings(statement))
+            .settings(statement.settings(this))
             .patterns(Collections.singletonList(statement.templatePrefix()))
-            .order(100)
-            .alias(new Alias(statement.tableIdent().indexNameOrAlias()));
+            .order(100));
     }
 
     private void createTable(final CompletableFuture<Long> result, final CreateTableAnalyzedStatement statement) {
diff --git a/sql/src/main/java/io/crate/execution/dml/upsert/TransportShardUpsertAction.java b/sql/src/main/java/io/crate/execution/dml/upsert/TransportShardUpsertAction.java
index be30169..3312bb7 100644
--- a/sql/src/main/java/io/crate/execution/dml/upsert/TransportShardUpsertAction.java
+++ b/sql/src/main/java/io/crate/execution/dml/upsert/TransportShardUpsertAction.java
@@ -113,7 +113,7 @@ public class TransportShardUpsertAction extends TransportShardAction<ShardUpsert
                                                                                         AtomicBoolean killed) {
         ShardResponse shardResponse = new ShardResponse();
         String indexName = request.index();
-        DocTableInfo tableInfo = schemas.getTableInfo(RelationName.fromIndexName(indexName), Operation.INSERT);
+        DocTableInfo tableInfo = RelationName.fromIndexName(indexName).getTableInfo(Operation.INSERT, schemas);
         Reference[] insertColumns = request.insertColumns();
         GeneratedColumns.Validation valueValidation = request.validateConstraints()
             ? GeneratedColumns.Validation.VALUE_MATCH
diff --git a/sql/src/main/java/io/crate/execution/dml/upsert/UpdateSourceGen.java b/sql/src/main/java/io/crate/execution/dml/upsert/UpdateSourceGen.java
index 6aaa546..9a2eb8c 100644
--- a/sql/src/main/java/io/crate/execution/dml/upsert/UpdateSourceGen.java
+++ b/sql/src/main/java/io/crate/execution/dml/upsert/UpdateSourceGen.java
@@ -92,7 +92,7 @@ final class UpdateSourceGen {
         for (String updateColumn : updateColumns) {
             ColumnIdent column = ColumnIdent.fromPath(updateColumn);
             Reference ref = table.getReference(column);
-            this.updateColumns.add(ref == null ? table.getDynamic(column, true) : ref);
+            this.updateColumns.add(ref == null ? column.getDynamic(true, table) : ref);
         }
         if (table.generatedColumns().isEmpty()) {
             generatedColumns = GeneratedColumns.empty();
diff --git a/sql/src/main/java/io/crate/execution/dsl/projection/WriterProjection.java b/sql/src/main/java/io/crate/execution/dsl/projection/WriterProjection.java
index 44325ac..5f989ef 100644
--- a/sql/src/main/java/io/crate/execution/dsl/projection/WriterProjection.java
+++ b/sql/src/main/java/io/crate/execution/dsl/projection/WriterProjection.java
@@ -22,7 +22,6 @@
 package io.crate.execution.dsl.projection;
 
 import com.google.common.collect.ImmutableList;
-import io.crate.expression.eval.EvaluatingNormalizer;
 import io.crate.expression.scalar.FormatFunction;
 import io.crate.expression.symbol.Function;
 import io.crate.expression.symbol.InputColumn;
@@ -35,7 +34,6 @@ import io.crate.metadata.FunctionInfo;
 import io.crate.metadata.Reference;
 import io.crate.metadata.ReferenceIdent;
 import io.crate.metadata.RowGranularity;
-import io.crate.metadata.TransactionContext;
 import io.crate.metadata.sys.SysShardsTableInfo;
 import io.crate.types.DataType;
 import io.crate.types.DataTypes;
@@ -252,18 +250,4 @@ public class WriterProjection extends Projection {
                '}';
     }
 
-    public WriterProjection normalize(EvaluatingNormalizer normalizer, TransactionContext txnCtx) {
-        Symbol nUri = normalizer.normalize(uri, txnCtx);
-        if (uri != nUri) {
-            return new WriterProjection(
-                inputs,
-                uri,
-                compressionType,
-                overwrites,
-                outputNames,
-                outputFormat
-            );
-        }
-        return this;
-    }
 }
diff --git a/sql/src/main/java/io/crate/execution/engine/JobLauncher.java b/sql/src/main/java/io/crate/execution/engine/JobLauncher.java
index 5f0aae6..f0bafb8 100644
--- a/sql/src/main/java/io/crate/execution/engine/JobLauncher.java
+++ b/sql/src/main/java/io/crate/execution/engine/JobLauncher.java
@@ -31,13 +31,11 @@ import io.crate.execution.dsl.phases.NodeOperation;
 import io.crate.execution.dsl.phases.NodeOperationGrouper;
 import io.crate.execution.dsl.phases.NodeOperationTree;
 import io.crate.execution.engine.distribution.StreamBucket;
-import io.crate.execution.jobs.DownstreamRXTask;
 import io.crate.execution.jobs.InstrumentedIndexSearcher;
 import io.crate.execution.jobs.JobSetup;
 import io.crate.execution.jobs.PageBucketReceiver;
 import io.crate.execution.jobs.RootTask;
 import io.crate.execution.jobs.SharedShardContexts;
-import io.crate.execution.jobs.Task;
 import io.crate.execution.jobs.TasksService;
 import io.crate.execution.jobs.kill.TransportKillJobsNodeAction;
 import io.crate.execution.jobs.transport.JobRequest;
@@ -208,7 +206,7 @@ public final class JobLauncher {
             sharedShardContexts);
         RootTask localTask = tasksService.createTask(builder);
 
-        List<PageBucketReceiver> pageBucketReceivers = getHandlerBucketReceivers(localTask, handlerPhaseAndReceiver);
+        List<PageBucketReceiver> pageBucketReceivers = localTask.getHandlerBucketReceivers(handlerPhaseAndReceiver, this);
         int bucketIdx = 0;
 
         /*
@@ -322,16 +320,4 @@ public final class JobLauncher {
         }
     }
 
-    private List<PageBucketReceiver> getHandlerBucketReceivers(RootTask rootTask,
-                                                               List<Tuple<ExecutionPhase, RowConsumer>> handlerPhases) {
-        final List<PageBucketReceiver> pageBucketReceivers = new ArrayList<>(handlerPhases.size());
-        for (Tuple<ExecutionPhase, ?> handlerPhase : handlerPhases) {
-            Task ctx = rootTask.getTaskOrNull(handlerPhase.v1().phaseId());
-            if (ctx instanceof DownstreamRXTask) {
-                PageBucketReceiver pageBucketReceiver = ((DownstreamRXTask) ctx).getBucketReceiver((byte) 0);
-                pageBucketReceivers.add(pageBucketReceiver);
-            }
-        }
-        return pageBucketReceivers;
-    }
 }
diff --git a/sql/src/main/java/io/crate/execution/engine/collect/CollectTask.java b/sql/src/main/java/io/crate/execution/engine/collect/CollectTask.java
index edbaf30..e848a8c 100644
--- a/sql/src/main/java/io/crate/execution/engine/collect/CollectTask.java
+++ b/sql/src/main/java/io/crate/execution/engine/collect/CollectTask.java
@@ -29,17 +29,21 @@ import io.crate.data.BatchIterator;
 import io.crate.data.ListenableRowConsumer;
 import io.crate.data.Row;
 import io.crate.data.RowConsumer;
+import io.crate.exceptions.Exceptions;
 import io.crate.execution.dsl.phases.CollectPhase;
 import io.crate.execution.dsl.phases.RoutedCollectPhase;
+import io.crate.execution.engine.collect.sources.ShardCollectorProviderFactory;
 import io.crate.execution.jobs.AbstractTask;
 import io.crate.execution.jobs.SharedShardContexts;
 import io.crate.metadata.TransactionContext;
 import io.crate.metadata.RowGranularity;
 import org.elasticsearch.index.engine.Engine;
+import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.threadpool.ThreadPool;
 
 import javax.annotation.Nonnull;
 import java.util.Locale;
+import java.util.function.Function;
 
 public class CollectTask extends AbstractTask {
 
@@ -168,4 +172,19 @@ public class CollectTask extends AbstractTask {
         // Anything else like doc tables, INFORMATION_SCHEMA tables or sys.cluster table collector, partition collector
         return ThreadPool.Names.SEARCH;
     }
+
+    public Function<IndexShard, BatchIterator<Row>> getLocalCollectorProvider(ShardCollectorProviderFactory shardCollectorProviderFactory,
+                                                                              RoutedCollectPhase collectPhase,
+                                                                              RowConsumer consumer, RemoteCollectorFactory remoteCollectorFactory) {
+        return indexShard -> {
+            try {
+                return shardCollectorProviderFactory
+                    .create(indexShard)
+                    .getIterator(collectPhase, consumer.requiresScroll(), this);
+            } catch (Exception e) {
+                Exceptions.rethrowUnchecked(e);
+                return null;
+            }
+        };
+    }
 }
diff --git a/sql/src/main/java/io/crate/execution/engine/collect/RemoteCollectorFactory.java b/sql/src/main/java/io/crate/execution/engine/collect/RemoteCollectorFactory.java
index 6312355..efbe12e 100644
--- a/sql/src/main/java/io/crate/execution/engine/collect/RemoteCollectorFactory.java
+++ b/sql/src/main/java/io/crate/execution/engine/collect/RemoteCollectorFactory.java
@@ -31,7 +31,6 @@ import io.crate.data.CollectingBatchIterator;
 import io.crate.data.CollectingRowConsumer;
 import io.crate.data.Row;
 import io.crate.data.RowConsumer;
-import io.crate.exceptions.Exceptions;
 import io.crate.execution.TransportActionProvider;
 import io.crate.execution.dsl.phases.RoutedCollectPhase;
 import io.crate.execution.dsl.projection.Projections;
@@ -44,7 +43,6 @@ import io.crate.planner.distribution.DistributionInfo;
 import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Singleton;
-import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
@@ -108,7 +106,7 @@ public class RemoteCollectorFactory {
             consumer,
             clusterService,
             indicesService,
-            getLocalCollectorProvider(shardCollectorProviderFactory, collectPhase, collectTask, consumer),
+            collectTask.getLocalCollectorProvider(shardCollectorProviderFactory, collectPhase, consumer, this),
             getRemoteCollectorProvider(childJobId, shardId, collectPhase, collectTask, consumer),
             searchTp,
             threadPool.getThreadContext());
@@ -124,22 +122,6 @@ public class RemoteCollectorFactory {
         );
     }
 
-    private Function<IndexShard, BatchIterator<Row>> getLocalCollectorProvider(ShardCollectorProviderFactory shardCollectorProviderFactory,
-                                                                               RoutedCollectPhase collectPhase,
-                                                                               CollectTask collectTask,
-                                                                               RowConsumer consumer) {
-        return indexShard -> {
-            try {
-                return shardCollectorProviderFactory
-                    .create(indexShard)
-                    .getIterator(collectPhase, consumer.requiresScroll(), collectTask);
-            } catch (Exception e) {
-                Exceptions.rethrowUnchecked(e);
-                return null;
-            }
-        };
-    }
-
     private Function<String, RemoteCollector> getRemoteCollectorProvider(UUID jobId,
                                                                          ShardId shardId,
                                                                          RoutedCollectPhase collectPhase,
diff --git a/sql/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java b/sql/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java
index 9ab444c..feab73c 100644
--- a/sql/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java
+++ b/sql/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java
@@ -325,7 +325,7 @@ public class ProjectionToProjectorVisitor
             inputs = ctx.topLevelInputs();
         }
 
-        projection = projection.normalize(normalizer, context.txnCtx);
+        projection = normalizer.normalizeOther(context.txnCtx, projection);
         String uri = DataTypes.STRING.value(
             SymbolEvaluator.evaluate(context.txnCtx, functions, projection.uri(), Row.EMPTY, SubQueryResults.EMPTY));
         assert uri != null : "URI must not be null";
diff --git a/sql/src/main/java/io/crate/execution/jobs/RootTask.java b/sql/src/main/java/io/crate/execution/jobs/RootTask.java
index f6bc2ce..ee2d714 100644
--- a/sql/src/main/java/io/crate/execution/jobs/RootTask.java
+++ b/sql/src/main/java/io/crate/execution/jobs/RootTask.java
@@ -26,13 +26,17 @@ import com.carrotsearch.hppc.cursors.IntCursor;
 import com.google.common.annotations.VisibleForTesting;
 import io.crate.concurrent.CompletableFutures;
 import io.crate.concurrent.CompletionListenable;
+import io.crate.data.RowConsumer;
 import io.crate.exceptions.JobKilledException;
 import io.crate.exceptions.SQLExceptions;
 import io.crate.exceptions.TaskMissing;
+import io.crate.execution.dsl.phases.ExecutionPhase;
+import io.crate.execution.engine.JobLauncher;
 import io.crate.execution.engine.collect.stats.JobsLogs;
 import io.crate.profile.ProfilingContext;
 import io.crate.profile.Timer;
 import org.apache.logging.log4j.Logger;
+import org.elasticsearch.common.collect.Tuple;
 
 import javax.annotation.Nonnull;
 import javax.annotation.Nullable;
@@ -74,6 +78,18 @@ public class RootTask implements CompletionListenable<Void> {
     @Nullable
     private final CompletableFuture<Map<String, Object>> profilingFuture;
 
+    public List<PageBucketReceiver> getHandlerBucketReceivers(List<Tuple<ExecutionPhase, RowConsumer>> handlerPhases, JobLauncher jobLauncher) {
+        final List<PageBucketReceiver> pageBucketReceivers = new ArrayList<>(handlerPhases.size());
+        for (Tuple<ExecutionPhase, ?> handlerPhase : handlerPhases) {
+            Task ctx = getTaskOrNull(handlerPhase.v1().phaseId());
+            if (ctx instanceof DownstreamRXTask) {
+                PageBucketReceiver pageBucketReceiver = ((DownstreamRXTask) ctx).getBucketReceiver((byte) 0);
+                pageBucketReceivers.add(pageBucketReceiver);
+            }
+        }
+        return pageBucketReceivers;
+    }
+
     public static class Builder {
 
         private final Logger logger;
diff --git a/sql/src/main/java/io/crate/execution/jobs/kill/TransportKillJobsNodeAction.java b/sql/src/main/java/io/crate/execution/jobs/kill/TransportKillJobsNodeAction.java
index efe47ee..d358bb8 100644
--- a/sql/src/main/java/io/crate/execution/jobs/kill/TransportKillJobsNodeAction.java
+++ b/sql/src/main/java/io/crate/execution/jobs/kill/TransportKillJobsNodeAction.java
@@ -21,12 +21,19 @@
 
 package io.crate.execution.jobs.kill;
 
+import com.google.common.annotations.VisibleForTesting;
+import io.crate.data.Row1;
+import io.crate.data.RowConsumer;
 import io.crate.execution.jobs.TasksService;
+import io.crate.execution.support.OneRowActionListener;
+import io.crate.planner.node.management.KillPlan;
 import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Singleton;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.Collections;
+import java.util.UUID;
 import java.util.concurrent.CompletableFuture;
 
 @Singleton
@@ -48,4 +55,18 @@ public class TransportKillJobsNodeAction extends TransportKillNodeAction<KillJob
     public KillJobsRequest call() throws Exception {
         return new KillJobsRequest();
     }
+
+    @VisibleForTesting
+    public void execute(TransportKillAllNodeAction killAllNodeAction,
+                        RowConsumer consumer, KillPlan killPlan) {
+        if (killPlan.jobToKill().isPresent()) {
+            UUID jobId = killPlan.jobToKill().get();
+            broadcast(
+                new KillJobsRequest(Collections.singletonList(jobId)),
+                new OneRowActionListener<>(consumer, Row1::new)
+            );
+        } else {
+            killAllNodeAction.broadcast(new KillAllRequest(), new OneRowActionListener<>(consumer, Row1::new));
+        }
+    }
 }
diff --git a/sql/src/main/java/io/crate/expression/eval/EvaluatingNormalizer.java b/sql/src/main/java/io/crate/expression/eval/EvaluatingNormalizer.java
index b3af7c8..02a72d3 100644
--- a/sql/src/main/java/io/crate/expression/eval/EvaluatingNormalizer.java
+++ b/sql/src/main/java/io/crate/expression/eval/EvaluatingNormalizer.java
@@ -24,6 +24,7 @@ package io.crate.expression.eval;
 
 import io.crate.analyze.relations.FieldResolver;
 import io.crate.data.Input;
+import io.crate.execution.dsl.projection.WriterProjection;
 import io.crate.expression.NestableInput;
 import io.crate.expression.reference.ReferenceResolver;
 import io.crate.expression.scalar.arithmetic.MapFunction;
@@ -90,6 +91,21 @@ public class EvaluatingNormalizer {
         this.visitor = new BaseVisitor();
     }
 
+    public WriterProjection normalizeOther(TransactionContext txnCtx, WriterProjection writerProjection) {
+        Symbol nUri = normalize(writerProjection.uri(), txnCtx);
+        if (writerProjection.uri() != nUri) {
+            return new WriterProjection(
+                writerProjection.inputs(),
+                writerProjection.uri(),
+                writerProjection.compressionType(),
+                writerProjection.overwrites(),
+                writerProjection.outputNames(),
+                writerProjection.outputFormat()
+            );
+        }
+        return writerProjection;
+    }
+
     private class BaseVisitor extends FunctionCopyVisitor<TransactionContext> {
         @Override
         public Symbol visitField(Field field, TransactionContext context) {
diff --git a/sql/src/main/java/io/crate/expression/symbol/Symbol.java b/sql/src/main/java/io/crate/expression/symbol/Symbol.java
index 7161d0c..d063a33 100644
--- a/sql/src/main/java/io/crate/expression/symbol/Symbol.java
+++ b/sql/src/main/java/io/crate/expression/symbol/Symbol.java
@@ -21,7 +21,9 @@
 
 package io.crate.expression.symbol;
 
+import io.crate.analyze.relations.select.SelectAnalysis;
 import io.crate.expression.scalar.cast.CastFunctionResolver;
+import io.crate.metadata.ColumnIdent;
 import io.crate.planner.ExplainLeaf;
 import io.crate.types.DataType;
 import io.crate.types.UndefinedType;
@@ -81,4 +83,10 @@ public abstract class Symbol implements FuncArg, Writeable, ExplainLeaf {
     public boolean canBeCasted() {
         return valueType().id() == UndefinedType.INSTANCE.id();
     }
+
+    public void add(ColumnIdent path, SelectAnalysis selectAnalysis) {
+        selectAnalysis.outputNames().add(path);
+        selectAnalysis.outputSymbols().add(this);
+        selectAnalysis.outputMultiMap().put(path.sqlFqn(), this);
+    }
 }
diff --git a/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionService.java b/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionService.java
index af429d3..95eaf42 100644
--- a/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionService.java
+++ b/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionService.java
@@ -22,7 +22,6 @@
 package io.crate.expression.udf;
 
 import com.google.common.annotations.VisibleForTesting;
-import io.crate.exceptions.UserDefinedFunctionAlreadyExistsException;
 import io.crate.exceptions.UserDefinedFunctionUnknownException;
 import io.crate.metadata.FunctionIdent;
 import io.crate.metadata.FunctionImplementation;
@@ -87,11 +86,10 @@ public class UserDefinedFunctionService {
                 public ClusterState execute(ClusterState currentState) throws Exception {
                     MetaData currentMetaData = currentState.metaData();
                     MetaData.Builder mdBuilder = MetaData.builder(currentMetaData);
-                    UserDefinedFunctionsMetaData functions = putFunction(
-                        currentMetaData.custom(UserDefinedFunctionsMetaData.TYPE),
+                    UserDefinedFunctionsMetaData functions = currentMetaData.custom(UserDefinedFunctionsMetaData.TYPE).putFunction(
                         metaData,
-                        replace
-                    );
+                        replace,
+                        this);
                     mdBuilder.putCustom(UserDefinedFunctionsMetaData.TYPE, functions);
                     return ClusterState.builder(currentState).metaData(mdBuilder).build();
                 }
@@ -154,29 +152,6 @@ public class UserDefinedFunctionService {
     }
 
     @VisibleForTesting
-    UserDefinedFunctionsMetaData putFunction(@Nullable UserDefinedFunctionsMetaData oldMetaData,
-                                             UserDefinedFunctionMetaData functionMetaData,
-                                             boolean replace) {
-        if (oldMetaData == null) {
-            return UserDefinedFunctionsMetaData.of(functionMetaData);
-        }
-
-        // create a new instance of the metadata, to guarantee the cluster changed action.
-        UserDefinedFunctionsMetaData newMetaData = UserDefinedFunctionsMetaData.newInstance(oldMetaData);
-        if (oldMetaData.contains(functionMetaData.schema(), functionMetaData.name(), functionMetaData.argumentTypes())) {
-            if (!replace) {
-                throw new UserDefinedFunctionAlreadyExistsException(functionMetaData);
-            }
-            newMetaData.replace(functionMetaData);
-        } else {
-            newMetaData.add(functionMetaData);
-        }
-
-        assert !newMetaData.equals(oldMetaData) : "must not be equal to guarantee the cluster change action";
-        return newMetaData;
-    }
-
-    @VisibleForTesting
     UserDefinedFunctionsMetaData removeFunction(@Nullable UserDefinedFunctionsMetaData functions,
                                                 String schema,
                                                 String name,
diff --git a/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionsMetaData.java b/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionsMetaData.java
index d2e790d..0b269f7 100644
--- a/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionsMetaData.java
+++ b/sql/src/main/java/io/crate/expression/udf/UserDefinedFunctionsMetaData.java
@@ -27,6 +27,7 @@
 package io.crate.expression.udf;
 
 import com.google.common.annotations.VisibleForTesting;
+import io.crate.exceptions.UserDefinedFunctionAlreadyExistsException;
 import io.crate.types.DataType;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.AbstractNamedDiffable;
@@ -165,4 +166,26 @@ public class UserDefinedFunctionsMetaData extends AbstractNamedDiffable<MetaData
     public Version getMinimalSupportedVersion() {
         return Version.ES_V_6_1_4;
     }
+
+    @VisibleForTesting
+    public UserDefinedFunctionsMetaData putFunction(UserDefinedFunctionMetaData functionMetaData,
+                                                    boolean replace, UserDefinedFunctionService userDefinedFunctionService) {
+        if (this == null) {
+            return of(functionMetaData);
+        }
+
+        // create a new instance of the metadata, to guarantee the cluster changed action.
+        UserDefinedFunctionsMetaData newMetaData = newInstance(this);
+        if (contains(functionMetaData.schema(), functionMetaData.name(), functionMetaData.argumentTypes())) {
+            if (!replace) {
+                throw new UserDefinedFunctionAlreadyExistsException(functionMetaData);
+            }
+            newMetaData.replace(functionMetaData);
+        } else {
+            newMetaData.add(functionMetaData);
+        }
+
+        assert !newMetaData.equals(this) : "must not be equal to guarantee the cluster change action";
+        return newMetaData;
+    }
 }
diff --git a/sql/src/main/java/io/crate/metadata/ColumnIdent.java b/sql/src/main/java/io/crate/metadata/ColumnIdent.java
index 8188a3a..c41a7aa 100644
--- a/sql/src/main/java/io/crate/metadata/ColumnIdent.java
+++ b/sql/src/main/java/io/crate/metadata/ColumnIdent.java
@@ -26,8 +26,12 @@ import com.google.common.collect.ComparisonChain;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Ordering;
 import io.crate.common.StringUtils;
+import io.crate.exceptions.ColumnUnknownException;
 import io.crate.exceptions.InvalidColumnNameException;
+import io.crate.expression.symbol.DynamicReference;
+import io.crate.metadata.doc.DocTableInfo;
 import io.crate.sql.Identifiers;
+import io.crate.sql.tree.ColumnPolicy;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 
@@ -404,4 +408,45 @@ public class ColumnIdent implements Comparable<ColumnIdent> {
         newPath.add(0, this.name);
         return new ColumnIdent(name, newPath);
     }
+
+    @Nullable
+    public DynamicReference getDynamic(boolean forWrite, DocTableInfo references) {
+        boolean parentIsIgnored = false;
+        ColumnPolicy parentPolicy = references.columnPolicy();
+        if (!isTopLevel()) {
+            // see if parent is strict object
+            ColumnIdent parentIdent = getParent();
+            Reference parentInfo = null;
+
+            while (parentIdent != null) {
+                parentInfo = references.getReference(parentIdent);
+                if (parentInfo != null) {
+                    break;
+                }
+                parentIdent = parentIdent.getParent();
+            }
+
+            if (parentInfo != null) {
+                parentPolicy = parentInfo.columnPolicy();
+            }
+        }
+
+        switch (parentPolicy) {
+            case DYNAMIC:
+                if (!forWrite) return null;
+                break;
+            case STRICT:
+                if (forWrite) throw new ColumnUnknownException(sqlFqn(), references.ident());
+                return null;
+            case IGNORED:
+                parentIsIgnored = true;
+                break;
+            default:
+                break;
+        }
+        if (parentIsIgnored) {
+            return new DynamicReference(new ReferenceIdent(references.ident(), this), references.rowGranularity(), ColumnPolicy.IGNORED);
+        }
+        return new DynamicReference(new ReferenceIdent(references.ident(), this), references.rowGranularity());
+    }
 }
diff --git a/sql/src/main/java/io/crate/metadata/PartitionInfos.java b/sql/src/main/java/io/crate/metadata/PartitionInfos.java
index 1fcb6f9..f51eac7 100644
--- a/sql/src/main/java/io/crate/metadata/PartitionInfos.java
+++ b/sql/src/main/java/io/crate/metadata/PartitionInfos.java
@@ -76,7 +76,7 @@ public class PartitionInfos implements Iterable<PartitionInfo> {
                 indexMetaData.getNumberOfShards(),
                 numberOfReplicas,
                 IndexMetaData.SETTING_INDEX_VERSION_CREATED.get(settings),
-                settings.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, null),
+                null.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, settings),
                 DocIndexMetaData.isClosed(indexMetaData, mappingMap, false),
                 valuesMap,
                 TableParameterInfo.tableParametersFromIndexMetaData(indexMetaData));
diff --git a/sql/src/main/java/io/crate/metadata/Reference.java b/sql/src/main/java/io/crate/metadata/Reference.java
index 6217966..62a20b7 100644
--- a/sql/src/main/java/io/crate/metadata/Reference.java
+++ b/sql/src/main/java/io/crate/metadata/Reference.java
@@ -22,6 +22,7 @@
 package io.crate.metadata;
 
 import com.google.common.base.MoreObjects;
+import io.crate.analyze.InsertFromValuesAnalyzedStatement;
 import io.crate.expression.symbol.Symbol;
 import io.crate.expression.symbol.SymbolType;
 import io.crate.expression.symbol.SymbolVisitor;
@@ -41,6 +42,11 @@ public class Reference extends Symbol {
 
     public static final Comparator<Reference> COMPARE_BY_COLUMN_IDENT = Comparator.comparing(Reference::column);
 
+    public void addGeneratedColumn(InsertFromValuesAnalyzedStatement insertFromValuesAnalyzedStatement) {
+        insertFromValuesAnalyzedStatement.columns().add(this);
+        insertFromValuesAnalyzedStatement.numAddedGeneratedColumns()++;
+    }
+
     public enum IndexType {
         ANALYZED,
         NOT_ANALYZED,
diff --git a/sql/src/main/java/io/crate/metadata/RelationName.java b/sql/src/main/java/io/crate/metadata/RelationName.java
index 56ae137..6334a66 100644
--- a/sql/src/main/java/io/crate/metadata/RelationName.java
+++ b/sql/src/main/java/io/crate/metadata/RelationName.java
@@ -27,7 +27,10 @@ import com.google.common.collect.ImmutableSet;
 import io.crate.blob.v2.BlobIndex;
 import io.crate.exceptions.InvalidRelationName;
 import io.crate.exceptions.InvalidSchemaNameException;
+import io.crate.exceptions.RelationUnknown;
 import io.crate.metadata.blob.BlobSchemaInfo;
+import io.crate.metadata.table.Operation;
+import io.crate.metadata.table.TableInfo;
 import io.crate.sql.Identifiers;
 import io.crate.sql.tree.QualifiedName;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -157,4 +160,20 @@ public final class RelationName implements Writeable {
         out.writeString(schema);
         out.writeString(name);
     }
+
+    /**
+     * @param operation The opreation planned to be performed on the table
+     * @param schemaInfos
+     * @return an instance of TableInfo for the given ident, guaranteed to be not null and to support the operation
+     * required on it.
+     * @throws io.crate.exceptions.SchemaUnknownException if schema given in <code>ident</code>
+     *                                                    does not exist
+     * @throws RelationUnknown  if table given in <code>ident</code> does
+     *                                                    not exist in the given schema
+     */
+    public <T extends TableInfo> T getTableInfo(Operation operation, Schemas schemaInfos) {
+        TableInfo tableInfo = schemaInfos.getTableInfo(this);
+        Operation.blockedRaiseException(tableInfo, operation);
+        return (T) tableInfo;
+    }
 }
diff --git a/sql/src/main/java/io/crate/metadata/Schemas.java b/sql/src/main/java/io/crate/metadata/Schemas.java
index f1588bb..e2a3c5f 100644
--- a/sql/src/main/java/io/crate/metadata/Schemas.java
+++ b/sql/src/main/java/io/crate/metadata/Schemas.java
@@ -222,22 +222,6 @@ public class Schemas extends AbstractLifecycleComponent implements Iterable<Sche
         return (T) info;
     }
 
-    /**
-     * @param ident the table ident to get a TableInfo for
-     * @param operation The opreation planned to be performed on the table
-     * @return an instance of TableInfo for the given ident, guaranteed to be not null and to support the operation
-     * required on it.
-     * @throws io.crate.exceptions.SchemaUnknownException if schema given in <code>ident</code>
-     *                                                    does not exist
-     * @throws RelationUnknown  if table given in <code>ident</code> does
-     *                                                    not exist in the given schema
-     */
-    public <T extends TableInfo> T getTableInfo(RelationName ident, Operation operation) {
-        TableInfo tableInfo = getTableInfo(ident);
-        Operation.blockedRaiseException(tableInfo, operation);
-        return (T) tableInfo;
-    }
-
     private SchemaInfo getSchemaInfo(RelationName ident) {
         String schemaName = ident.schema();
         SchemaInfo schemaInfo = schemas.get(schemaName);
diff --git a/sql/src/main/java/io/crate/metadata/blob/InternalBlobTableInfoFactory.java b/sql/src/main/java/io/crate/metadata/blob/InternalBlobTableInfoFactory.java
index 3b0a457..8c0c35b 100644
--- a/sql/src/main/java/io/crate/metadata/blob/InternalBlobTableInfoFactory.java
+++ b/sql/src/main/java/io/crate/metadata/blob/InternalBlobTableInfoFactory.java
@@ -87,7 +87,7 @@ public class InternalBlobTableInfoFactory implements BlobTableInfoFactory {
             TableParameterInfo.tableParametersFromIndexMetaData(indexMetaData),
             blobsPath(settings),
             IndexMetaData.SETTING_INDEX_VERSION_CREATED.get(settings),
-            settings.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, null),
+            null.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, settings),
             indexMetaData.getState() == IndexMetaData.State.CLOSE);
     }
 
diff --git a/sql/src/main/java/io/crate/metadata/doc/DocIndexMetaData.java b/sql/src/main/java/io/crate/metadata/doc/DocIndexMetaData.java
index f228175..59f7ae4 100644
--- a/sql/src/main/java/io/crate/metadata/doc/DocIndexMetaData.java
+++ b/sql/src/main/java/io/crate/metadata/doc/DocIndexMetaData.java
@@ -138,7 +138,7 @@ public class DocIndexMetaData {
             IndexMetaData.State.CLOSE : IndexMetaData.State.OPEN;
         supportedOperations = Operation.buildFromIndexSettingsAndState(metaData.getSettings(), state);
         versionCreated = IndexMetaData.SETTING_INDEX_VERSION_CREATED.get(settings);
-        versionUpgraded = settings.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, null);
+        versionUpgraded = null.getAsVersion(IndexMetaData.SETTING_VERSION_UPGRADED, settings);
         closed = state == IndexMetaData.State.CLOSE;
     }
 
diff --git a/sql/src/main/java/io/crate/metadata/doc/DocTableInfo.java b/sql/src/main/java/io/crate/metadata/doc/DocTableInfo.java
index a65031a..60734fd 100644
--- a/sql/src/main/java/io/crate/metadata/doc/DocTableInfo.java
+++ b/sql/src/main/java/io/crate/metadata/doc/DocTableInfo.java
@@ -23,14 +23,11 @@ package io.crate.metadata.doc;
 
 import io.crate.action.sql.SessionContext;
 import io.crate.analyze.WhereClause;
-import io.crate.exceptions.ColumnUnknownException;
-import io.crate.expression.symbol.DynamicReference;
 import io.crate.metadata.ColumnIdent;
 import io.crate.metadata.GeneratedReference;
 import io.crate.metadata.IndexReference;
 import io.crate.metadata.PartitionName;
 import io.crate.metadata.Reference;
-import io.crate.metadata.ReferenceIdent;
 import io.crate.metadata.RelationName;
 import io.crate.metadata.Routing;
 import io.crate.metadata.RoutingProvider;
@@ -381,47 +378,6 @@ public class DocTableInfo implements TableInfo, ShardedTable, StoredTable {
         return analyzers.get(ident);
     }
 
-    @Nullable
-    public DynamicReference getDynamic(ColumnIdent ident, boolean forWrite) {
-        boolean parentIsIgnored = false;
-        ColumnPolicy parentPolicy = columnPolicy();
-        if (!ident.isTopLevel()) {
-            // see if parent is strict object
-            ColumnIdent parentIdent = ident.getParent();
-            Reference parentInfo = null;
-
-            while (parentIdent != null) {
-                parentInfo = getReference(parentIdent);
-                if (parentInfo != null) {
-                    break;
-                }
-                parentIdent = parentIdent.getParent();
-            }
-
-            if (parentInfo != null) {
-                parentPolicy = parentInfo.columnPolicy();
-            }
-        }
-
-        switch (parentPolicy) {
-            case DYNAMIC:
-                if (!forWrite) return null;
-                break;
-            case STRICT:
-                if (forWrite) throw new ColumnUnknownException(ident.sqlFqn(), ident());
-                return null;
-            case IGNORED:
-                parentIsIgnored = true;
-                break;
-            default:
-                break;
-        }
-        if (parentIsIgnored) {
-            return new DynamicReference(new ReferenceIdent(ident(), ident), rowGranularity(), ColumnPolicy.IGNORED);
-        }
-        return new DynamicReference(new ReferenceIdent(ident(), ident), rowGranularity());
-    }
-
     @Override
     public String toString() {
         return ident.fqn();
diff --git a/sql/src/main/java/io/crate/metadata/sys/TableHealthService.java b/sql/src/main/java/io/crate/metadata/sys/TableHealthService.java
index bdbdaa5..9e70fea 100644
--- a/sql/src/main/java/io/crate/metadata/sys/TableHealthService.java
+++ b/sql/src/main/java/io/crate/metadata/sys/TableHealthService.java
@@ -88,7 +88,7 @@ public class TableHealthService {
             logger.debug("Could not retrieve tables health information. localNode is not fully available yet.");
             return completedFuture(Collections.emptyList());
         }
-        if (clusterService.state().getBlocks().hasGlobalBlockWithStatus(RestStatus.SERVICE_UNAVAILABLE)) {
+        if (RestStatus.SERVICE_UNAVAILABLE.hasGlobalBlockWithStatus(clusterService.state().getBlocks())) {
             return completedFuture(allAsUnavailable());
         }
         try {
diff --git a/sql/src/main/java/io/crate/planner/DependencyCarrier.java b/sql/src/main/java/io/crate/planner/DependencyCarrier.java
index 076d6a1..294c1da 100644
--- a/sql/src/main/java/io/crate/planner/DependencyCarrier.java
+++ b/sql/src/main/java/io/crate/planner/DependencyCarrier.java
@@ -29,15 +29,20 @@ import io.crate.execution.ddl.TransportSwapRelationsAction;
 import io.crate.execution.ddl.tables.TransportDropTableAction;
 import io.crate.execution.ddl.views.TransportCreateViewAction;
 import io.crate.execution.ddl.views.TransportDropViewAction;
+import io.crate.execution.dml.ShardRequestExecutor;
+import io.crate.execution.dml.delete.ShardDeleteRequest;
 import io.crate.execution.dsl.projection.builder.ProjectionBuilder;
 import io.crate.execution.engine.PhasesTaskFactory;
+import io.crate.execution.engine.indexing.ShardingUpsertExecutor;
 import io.crate.license.LicenseService;
 import io.crate.metadata.Functions;
 import io.crate.metadata.Schemas;
+import io.crate.planner.node.dml.DeleteById;
 import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Singleton;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.threadpool.ThreadPool;
 
 import java.util.concurrent.ScheduledExecutorService;
@@ -163,4 +168,19 @@ public class DependencyCarrier {
     public TransportDropViewAction dropViewAction() {
         return dropViewAction;
     }
+
+    public ShardRequestExecutor<ShardDeleteRequest> createExecutor(PlannerContext plannerContext, DeleteById deleteById) {
+        ClusterService clusterService = clusterService();
+        TimeValue requestTimeout = ShardingUpsertExecutor.BULK_REQUEST_TIMEOUT_SETTING
+            .setting().get(clusterService.state().metaData().settings());
+        return new ShardRequestExecutor<>(
+            clusterService,
+            plannerContext.transactionContext(),
+            functions(),
+            deleteById.table(),
+            new DeleteById.DeleteRequests(plannerContext.jobId(), requestTimeout),
+            transportActionProvider().transportShardDeleteAction()::execute,
+            deleteById.docKeys()
+        );
+    }
 }
diff --git a/sql/src/main/java/io/crate/planner/PlannerContext.java b/sql/src/main/java/io/crate/planner/PlannerContext.java
index ab11999..deec746 100644
--- a/sql/src/main/java/io/crate/planner/PlannerContext.java
+++ b/sql/src/main/java/io/crate/planner/PlannerContext.java
@@ -24,15 +24,24 @@ package io.crate.planner;
 
 import io.crate.action.sql.SessionContext;
 import io.crate.analyze.WhereClause;
+import io.crate.collections.Lists2;
+import io.crate.data.Row;
+import io.crate.execution.dsl.projection.EvalProjection;
+import io.crate.execution.dsl.projection.builder.InputColumns;
+import io.crate.expression.symbol.Symbol;
 import io.crate.metadata.CoordinatorTxnCtx;
 import io.crate.metadata.Functions;
 import io.crate.metadata.Routing;
 import io.crate.metadata.RoutingProvider;
 import io.crate.metadata.table.TableInfo;
+import io.crate.planner.operators.FetchOrEval;
+import io.crate.planner.operators.SubQueryAndParamBinder;
+import io.crate.planner.operators.SubQueryResults;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.routing.ShardRouting;
 
 import javax.annotation.Nullable;
+import java.util.List;
 import java.util.UUID;
 
 public class PlannerContext {
@@ -116,4 +125,35 @@ public class PlannerContext {
     public Functions functions() {
         return functions;
     }
+
+    public ExecutionPlan planWithEvalProjection(ExecutionPlan executionPlan,
+                                                List<Symbol> sourceOutputs,
+                                                Row params,
+                                                SubQueryResults subQueryResults, FetchOrEval fetchOrEval) {
+        SubQueryAndParamBinder binder = new SubQueryAndParamBinder(params, subQueryResults);
+        List<Symbol> boundOutputs = Lists2.map(fetchOrEval.outputs(), binder);
+        PositionalOrderBy orderBy = executionPlan.resultDescription().orderBy();
+        PositionalOrderBy newOrderBy;
+        if (orderBy == null) {
+            newOrderBy = null;
+        } else {
+            newOrderBy = orderBy.tryMapToNewOutputs(sourceOutputs, boundOutputs);
+            if (newOrderBy == null) {
+                // We've a query like `SELECT x, y FROM t ORDER BY z`
+                //
+                // The previous operator added `z` to the outputs to be able to do a sorted merge;
+                // We couldn't map the PositionalOrderBy to the new outputs (=[x,y]) since they don't contain `z` anymore.
+                // We need to merge to handler *before* we remove `z` from the outputs (which is what the eval here would do)
+                executionPlan = Merge.ensureOnHandler(executionPlan, this);
+            }
+        }
+        InputColumns.SourceSymbols ctx = new InputColumns.SourceSymbols(Lists2.map(sourceOutputs, binder));
+        executionPlan.addProjection(
+            new EvalProjection(InputColumns.create(boundOutputs, ctx)),
+            executionPlan.resultDescription().limit(),
+            executionPlan.resultDescription().offset(),
+            newOrderBy
+        );
+        return executionPlan;
+    }
 }
diff --git a/sql/src/main/java/io/crate/planner/node/dml/DeleteById.java b/sql/src/main/java/io/crate/planner/node/dml/DeleteById.java
index cbe7792..7f914ce 100644
--- a/sql/src/main/java/io/crate/planner/node/dml/DeleteById.java
+++ b/sql/src/main/java/io/crate/planner/node/dml/DeleteById.java
@@ -26,13 +26,11 @@ import io.crate.data.Row;
 import io.crate.data.RowConsumer;
 import io.crate.execution.dml.ShardRequestExecutor;
 import io.crate.execution.dml.delete.ShardDeleteRequest;
-import io.crate.execution.engine.indexing.ShardingUpsertExecutor;
 import io.crate.metadata.doc.DocTableInfo;
 import io.crate.planner.DependencyCarrier;
 import io.crate.planner.Plan;
 import io.crate.planner.PlannerContext;
 import io.crate.planner.operators.SubQueryResults;
-import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.shard.ShardId;
 
@@ -69,7 +67,7 @@ public class DeleteById implements Plan {
                               RowConsumer consumer,
                               Row params,
                               SubQueryResults subQueryResults) {
-        createExecutor(dependencies, plannerContext)
+        dependencies.createExecutor(plannerContext, this)
             .execute(consumer, params, subQueryResults);
     }
 
@@ -78,26 +76,10 @@ public class DeleteById implements Plan {
                                                      PlannerContext plannerContext,
                                                      List<Row> bulkParams,
                                                      SubQueryResults subQueryResults) {
-        return createExecutor(dependencies, plannerContext)
+        return dependencies.createExecutor(plannerContext, this)
             .executeBulk(bulkParams, subQueryResults);
     }
 
-    private ShardRequestExecutor<ShardDeleteRequest> createExecutor(DependencyCarrier dependencies,
-                                                                    PlannerContext plannerContext) {
-        ClusterService clusterService = dependencies.clusterService();
-        TimeValue requestTimeout = ShardingUpsertExecutor.BULK_REQUEST_TIMEOUT_SETTING
-            .setting().get(clusterService.state().metaData().settings());
-        return new ShardRequestExecutor<>(
-            clusterService,
-            plannerContext.transactionContext(),
-            dependencies.functions(),
-            table,
-            new DeleteRequests(plannerContext.jobId(), requestTimeout),
-            dependencies.transportActionProvider().transportShardDeleteAction()::execute,
-            docKeys
-        );
-    }
-
     static class DeleteRequests implements ShardRequestExecutor.RequestGrouper<ShardDeleteRequest> {
 
         private final UUID jobId;
diff --git a/sql/src/main/java/io/crate/planner/node/management/KillPlan.java b/sql/src/main/java/io/crate/planner/node/management/KillPlan.java
index 6e315b1..fdb383b 100644
--- a/sql/src/main/java/io/crate/planner/node/management/KillPlan.java
+++ b/sql/src/main/java/io/crate/planner/node/management/KillPlan.java
@@ -21,21 +21,13 @@
 
 package io.crate.planner.node.management;
 
-import com.google.common.annotations.VisibleForTesting;
 import io.crate.data.Row;
-import io.crate.data.Row1;
 import io.crate.data.RowConsumer;
-import io.crate.execution.jobs.kill.KillAllRequest;
-import io.crate.execution.jobs.kill.KillJobsRequest;
-import io.crate.execution.jobs.kill.TransportKillAllNodeAction;
-import io.crate.execution.jobs.kill.TransportKillJobsNodeAction;
-import io.crate.execution.support.OneRowActionListener;
 import io.crate.planner.DependencyCarrier;
 import io.crate.planner.Plan;
 import io.crate.planner.PlannerContext;
 import io.crate.planner.operators.SubQueryResults;
 
-import java.util.Collections;
 import java.util.Optional;
 import java.util.UUID;
 
@@ -55,21 +47,6 @@ public class KillPlan implements Plan {
         return jobToKill;
     }
 
-    @VisibleForTesting
-    void execute(TransportKillAllNodeAction killAllNodeAction,
-                 TransportKillJobsNodeAction killjobsNodeAction,
-                 RowConsumer consumer) {
-        if (jobToKill.isPresent()) {
-            UUID jobId = jobToKill.get();
-            killjobsNodeAction.broadcast(
-                new KillJobsRequest(Collections.singletonList(jobId)),
-                new OneRowActionListener<>(consumer, Row1::new)
-            );
-        } else {
-            killAllNodeAction.broadcast(new KillAllRequest(), new OneRowActionListener<>(consumer, Row1::new));
-        }
-    }
-
     @Override
     public StatementType type() {
         return StatementType.MANAGEMENT;
@@ -82,10 +59,9 @@ public class KillPlan implements Plan {
                               RowConsumer consumer,
                               Row params,
                               SubQueryResults subQueryResults) {
-        execute(
+        dependencies.transportActionProvider().transportKillJobsNodeAction().execute(
             dependencies.transportActionProvider().transportKillAllNodeAction(),
-            dependencies.transportActionProvider().transportKillJobsNodeAction(),
-            consumer
-        );
+            consumer,
+            this);
     }
 }
diff --git a/sql/src/main/java/io/crate/planner/operators/FetchOrEval.java b/sql/src/main/java/io/crate/planner/operators/FetchOrEval.java
index c0033f2..5b0d804 100644
--- a/sql/src/main/java/io/crate/planner/operators/FetchOrEval.java
+++ b/sql/src/main/java/io/crate/planner/operators/FetchOrEval.java
@@ -34,7 +34,6 @@ import io.crate.data.Row;
 import io.crate.execution.dsl.phases.FetchPhase;
 import io.crate.execution.dsl.projection.EvalProjection;
 import io.crate.execution.dsl.projection.FetchProjection;
-import io.crate.execution.dsl.projection.builder.InputColumns;
 import io.crate.execution.dsl.projection.builder.ProjectionBuilder;
 import io.crate.expression.symbol.FetchReference;
 import io.crate.expression.symbol.Field;
@@ -52,7 +51,6 @@ import io.crate.metadata.doc.DocSysColumns;
 import io.crate.planner.ExecutionPlan;
 import io.crate.planner.Merge;
 import io.crate.planner.PlannerContext;
-import io.crate.planner.PositionalOrderBy;
 import io.crate.planner.ReaderAllocations;
 import io.crate.planner.consumer.FetchMode;
 import io.crate.planner.node.dql.QueryThenFetch;
@@ -243,7 +241,7 @@ public class FetchOrEval extends ForwardingLogicalPlan {
         if (doFetch && Symbols.containsColumn(sourceOutputs, DocSysColumns.FETCHID)) {
             return planWithFetch(plannerContext, executionPlan, sourceOutputs, params, subQueryResults);
         }
-        return planWithEvalProjection(plannerContext, executionPlan, sourceOutputs, params, subQueryResults);
+        return plannerContext.planWithEvalProjection(executionPlan, sourceOutputs, params, subQueryResults, this);
     }
 
     @Override
@@ -307,7 +305,7 @@ public class FetchOrEval extends ForwardingLogicalPlan {
             // that all required columns are already provided.
             // This should be improved so that this case no longer occurs
             // `testNestedSimpleSelectWithJoin` is an example case
-            return planWithEvalProjection(plannerContext, executionPlan, sourceOutputs, params, subQueryResults);
+            return plannerContext.planWithEvalProjection(executionPlan, sourceOutputs, params, subQueryResults, this);
         }
 
         ReaderAllocations readerAllocations = plannerContext.buildReaderAllocations();
@@ -447,38 +445,6 @@ public class FetchOrEval extends ForwardingLogicalPlan {
         });
     }
 
-    private ExecutionPlan planWithEvalProjection(PlannerContext plannerContext,
-                                                 ExecutionPlan executionPlan,
-                                                 List<Symbol> sourceOutputs,
-                                                 Row params,
-                                                 SubQueryResults subQueryResults) {
-        SubQueryAndParamBinder binder = new SubQueryAndParamBinder(params, subQueryResults);
-        List<Symbol> boundOutputs = Lists2.map(outputs, binder);
-        PositionalOrderBy orderBy = executionPlan.resultDescription().orderBy();
-        PositionalOrderBy newOrderBy;
-        if (orderBy == null) {
-            newOrderBy = null;
-        } else {
-            newOrderBy = orderBy.tryMapToNewOutputs(sourceOutputs, boundOutputs);
-            if (newOrderBy == null) {
-                // We've a query like `SELECT x, y FROM t ORDER BY z`
-                //
-                // The previous operator added `z` to the outputs to be able to do a sorted merge;
-                // We couldn't map the PositionalOrderBy to the new outputs (=[x,y]) since they don't contain `z` anymore.
-                // We need to merge to handler *before* we remove `z` from the outputs (which is what the eval here would do)
-                executionPlan = Merge.ensureOnHandler(executionPlan, plannerContext);
-            }
-        }
-        InputColumns.SourceSymbols ctx = new InputColumns.SourceSymbols(Lists2.map(sourceOutputs, binder));
-        executionPlan.addProjection(
-            new EvalProjection(InputColumns.create(boundOutputs, ctx)),
-            executionPlan.resultDescription().limit(),
-            executionPlan.resultDescription().offset(),
-            newOrderBy
-        );
-        return executionPlan;
-    }
-
     @Override
     public String toString() {
         return "FetchOrEval{" +
diff --git a/sql/src/main/java/io/crate/protocols/postgres/RetryOnFailureResultReceiver.java b/sql/src/main/java/io/crate/protocols/postgres/RetryOnFailureResultReceiver.java
index 2229c6b..157319e 100644
--- a/sql/src/main/java/io/crate/protocols/postgres/RetryOnFailureResultReceiver.java
+++ b/sql/src/main/java/io/crate/protocols/postgres/RetryOnFailureResultReceiver.java
@@ -93,7 +93,7 @@ public class RetryOnFailureResultReceiver implements ResultReceiver {
         if (attempt <= Constants.MAX_SHARD_MISSING_RETRIES &&
             (SQLExceptions.isShardFailure(error) || error instanceof ConnectTransportException || indexWasTemporaryUnavailable(error))) {
 
-            if (clusterService.state().blocks().hasGlobalBlockWithStatus(RestStatus.SERVICE_UNAVAILABLE)) {
+            if (RestStatus.SERVICE_UNAVAILABLE.hasGlobalBlockWithStatus(clusterService.state().blocks())) {
                 delegate.fail(error);
             } else {
                 ClusterStateObserver clusterStateObserver =
diff --git a/sql/src/main/java/org/elasticsearch/action/admin/indices/create/CreatePartitionsRequest.java b/sql/src/main/java/org/elasticsearch/action/admin/indices/create/CreatePartitionsRequest.java
index 91327c2..7d2337b 100644
--- a/sql/src/main/java/org/elasticsearch/action/admin/indices/create/CreatePartitionsRequest.java
+++ b/sql/src/main/java/org/elasticsearch/action/admin/indices/create/CreatePartitionsRequest.java
@@ -22,8 +22,11 @@
 package org.elasticsearch.action.admin.indices.create;
 
 import com.google.common.collect.ImmutableList;
+import org.elasticsearch.ResourceAlreadyExistsException;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.support.master.AcknowledgedRequest;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.metadata.MetaDataCreateIndexService;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 
@@ -85,4 +88,15 @@ public class CreatePartitionsRequest extends AcknowledgedRequest<CreatePartition
         }
     }
 
+    public void validateAndFilterExistingIndices(ClusterState currentState,
+                                                 List<String> indicesToCreate, TransportCreatePartitionsAction transportCreatePartitionsAction) {
+        for (String index : indices()) {
+            try {
+                MetaDataCreateIndexService.validateIndexName(index, currentState);
+                indicesToCreate.add(index);
+            } catch (ResourceAlreadyExistsException e) {
+                // ignore
+            }
+        }
+    }
 }
diff --git a/sql/src/main/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsAction.java b/sql/src/main/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsAction.java
index 2aaa53e..c66cdf5 100644
--- a/sql/src/main/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsAction.java
+++ b/sql/src/main/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsAction.java
@@ -29,7 +29,6 @@ import com.google.common.collect.Maps;
 import io.crate.metadata.PartitionName;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.ResourceAlreadyExistsException;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.ActiveShardCount;
@@ -192,7 +191,7 @@ public class TransportCreatePartitionsAction
         List<String> removalReasons = new ArrayList<>(request.indices().size());
         List<Index> createdIndices = new ArrayList<>(request.indices().size());
         try {
-            validateAndFilterExistingIndices(currentState, indicesToCreate, request);
+            request.validateAndFilterExistingIndices(currentState, indicesToCreate, this);
             if (indicesToCreate.isEmpty()) {
                 return currentState;
             }
@@ -312,19 +311,6 @@ public class TransportCreatePartitionsAction
         );
     }
 
-    private void validateAndFilterExistingIndices(ClusterState currentState,
-                                                  List<String> indicesToCreate,
-                                                  CreatePartitionsRequest request) {
-        for (String index : request.indices()) {
-            try {
-                MetaDataCreateIndexService.validateIndexName(index, currentState);
-                indicesToCreate.add(index);
-            } catch (ResourceAlreadyExistsException e) {
-                // ignore
-            }
-        }
-    }
-
     private Settings createIndexSettings(ClusterState currentState, List<IndexTemplateMetaData> templates) {
         Settings.Builder indexSettingsBuilder = Settings.builder();
         // apply templates, here, in reverse order, since first ones are better matching
diff --git a/sql/src/test/java/io/crate/execution/dml/upsert/TransportShardUpsertActionTest.java b/sql/src/test/java/io/crate/execution/dml/upsert/TransportShardUpsertActionTest.java
index 23e911d..edc3cf5 100644
--- a/sql/src/test/java/io/crate/execution/dml/upsert/TransportShardUpsertActionTest.java
+++ b/sql/src/test/java/io/crate/execution/dml/upsert/TransportShardUpsertActionTest.java
@@ -52,7 +52,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.VersionType;
 import org.elasticsearch.index.engine.VersionConflictEngineException;
 import org.elasticsearch.index.mapper.ContentPath;
 import org.elasticsearch.index.mapper.Mapper;
@@ -161,7 +160,7 @@ public class TransportShardUpsertActionTest extends CrateDummyClusterServiceUnit
         DocTableInfo tableInfo = mock(DocTableInfo.class);
         Schemas schemas = mock(Schemas.class);
         when(tableInfo.columns()).thenReturn(Collections.<Reference>emptyList());
-        when(schemas.getTableInfo(any(RelationName.class), eq(Operation.INSERT))).thenReturn(tableInfo);
+        when(any(RelationName.class).getTableInfo(eq(Operation.INSERT), schemas)).thenReturn(tableInfo);
 
         transportShardUpsertAction = new TestingTransportShardUpsertAction(
             Settings.EMPTY,
diff --git a/sql/src/test/java/io/crate/expression/udf/UserDefinedFunctionServiceTest.java b/sql/src/test/java/io/crate/expression/udf/UserDefinedFunctionServiceTest.java
index d61a1d6..5c64631 100644
--- a/sql/src/test/java/io/crate/expression/udf/UserDefinedFunctionServiceTest.java
+++ b/sql/src/test/java/io/crate/expression/udf/UserDefinedFunctionServiceTest.java
@@ -63,14 +63,14 @@ public class UserDefinedFunctionServiceTest extends UdfUnitTest {
 
     @Test
     public void testFirstFunction() throws Exception {
-        UserDefinedFunctionsMetaData metaData = udfService.putFunction(null, same1, true);
+        UserDefinedFunctionsMetaData metaData = null.putFunction(same1, true, udfService);
         assertThat(metaData.functionsMetaData(), hasSize(1));
         assertThat(metaData.functionsMetaData(), contains(same1));
     }
 
     @Test
     public void testReplaceExistingFunction() throws Exception {
-        UserDefinedFunctionsMetaData metaData = udfService.putFunction(UserDefinedFunctionsMetaData.of(same1), same2, true);
+        UserDefinedFunctionsMetaData metaData = UserDefinedFunctionsMetaData.of(same1).putFunction(same2, true, udfService);
         assertThat(metaData.functionsMetaData(), hasSize(1));
         assertThat(metaData.functionsMetaData(), contains(same2));
     }
@@ -78,7 +78,7 @@ public class UserDefinedFunctionServiceTest extends UdfUnitTest {
     @Test
     public void testReplaceNotExistingFunction() throws Exception {
         UserDefinedFunctionsMetaData metaData =
-            udfService.putFunction(UserDefinedFunctionsMetaData.of(same1), different, true);
+            UserDefinedFunctionsMetaData.of(same1).putFunction(different, true, udfService);
         assertThat(metaData.functionsMetaData(), hasSize(2));
         assertThat(metaData.functionsMetaData(), containsInAnyOrder(same1, different));
     }
@@ -109,6 +109,6 @@ public class UserDefinedFunctionServiceTest extends UdfUnitTest {
     public void testReplaceIsFalse() throws Exception {
         expectedException.expect(UserDefinedFunctionAlreadyExistsException.class);
         expectedException.expectMessage("User defined Function 'doc.same()' already exists.");
-        udfService.putFunction(UserDefinedFunctionsMetaData.of(same1), same2, false);
+        UserDefinedFunctionsMetaData.of(same1).putFunction(same2, false, udfService);
     }
 }
diff --git a/sql/src/test/java/io/crate/integrationtests/SnapshotRestoreIntegrationTest.java b/sql/src/test/java/io/crate/integrationtests/SnapshotRestoreIntegrationTest.java
index a5aa261..8a9d0d9 100644
--- a/sql/src/test/java/io/crate/integrationtests/SnapshotRestoreIntegrationTest.java
+++ b/sql/src/test/java/io/crate/integrationtests/SnapshotRestoreIntegrationTest.java
@@ -163,7 +163,7 @@ public class SnapshotRestoreIntegrationTest extends SQLTransportIntegrationTest
                 // Make sure that snapshot clean up operations are finished
                 ClusterStateResponse stateResponse = client().admin().cluster().prepareState().get();
                 SnapshotsInProgress snapshotsInProgress = stateResponse.getState().custom(SnapshotsInProgress.TYPE);
-                if (snapshotsInProgress == null || snapshotsInProgress.snapshot(snapshot) == null) {
+                if (snapshotsInProgress == null || snapshot.snapshot(snapshotsInProgress) == null) {
                     return snapshotInfos.get(0);
                 }
             }
diff --git a/sql/src/test/java/io/crate/metadata/SchemasTest.java b/sql/src/test/java/io/crate/metadata/SchemasTest.java
index 260dc1e..0c45c75 100644
--- a/sql/src/test/java/io/crate/metadata/SchemasTest.java
+++ b/sql/src/test/java/io/crate/metadata/SchemasTest.java
@@ -73,7 +73,7 @@ public class SchemasTest extends CrateDummyClusterServiceUnitTest {
         when(schemaInfo.name()).thenReturn(relationName.schema());
 
         Schemas schemas = getReferenceInfos(schemaInfo);
-        schemas.getTableInfo(relationName, Operation.INSERT);
+        relationName.getTableInfo(Operation.INSERT, schemas);
     }
 
     @Test
diff --git a/sql/src/test/java/io/crate/metadata/doc/DocTableInfoTest.java b/sql/src/test/java/io/crate/metadata/doc/DocTableInfoTest.java
index 5975f23..e0e7234 100644
--- a/sql/src/test/java/io/crate/metadata/doc/DocTableInfoTest.java
+++ b/sql/src/test/java/io/crate/metadata/doc/DocTableInfoTest.java
@@ -64,9 +64,9 @@ public class DocTableInfoTest extends CrateUnitTest {
 
         Reference foobar = info.getReference(new ColumnIdent("o", ImmutableList.of("foobar")));
         assertNull(foobar);
-        DynamicReference reference = info.getDynamic(new ColumnIdent("o", ImmutableList.of("foobar")), false);
+        DynamicReference reference = new ColumnIdent("o", ImmutableList.of("foobar")).getDynamic(false, info);
         assertNull(reference);
-        reference = info.getDynamic(new ColumnIdent("o", ImmutableList.of("foobar")), true);
+        reference = new ColumnIdent("o", ImmutableList.of("foobar")).getDynamic(true, info);
         assertNotNull(reference);
         assertSame(reference.valueType(), DataTypes.UNDEFINED);
     }
@@ -119,11 +119,11 @@ public class DocTableInfoTest extends CrateUnitTest {
 
         ColumnIdent columnIdent = new ColumnIdent("foobar", Arrays.asList("foo", "bar"));
         assertNull(info.getReference(columnIdent));
-        assertNull(info.getDynamic(columnIdent, false));
+        assertNull(columnIdent.getDynamic(false, info));
 
         columnIdent = new ColumnIdent("foobar", Collections.singletonList("foo"));
         assertNull(info.getReference(columnIdent));
-        assertNull(info.getDynamic(columnIdent, false));
+        assertNull(columnIdent.getDynamic(false, info));
 
         Reference colInfo = info.getReference(new ColumnIdent("foobar"));
         assertNotNull(colInfo);
diff --git a/sql/src/test/java/io/crate/planner/node/management/KillPlanTest.java b/sql/src/test/java/io/crate/planner/node/management/KillPlanTest.java
index efa8084..7423e7d 100644
--- a/sql/src/test/java/io/crate/planner/node/management/KillPlanTest.java
+++ b/sql/src/test/java/io/crate/planner/node/management/KillPlanTest.java
@@ -64,7 +64,7 @@ public class KillPlanTest extends CrateDummyClusterServiceUnitTest {
             }
         };
         KillPlan killPlan = new KillPlan();
-        killPlan.execute(killAllNodeAction, mock(TransportKillJobsNodeAction.class), new TestingRowConsumer());;
+        mock(TransportKillJobsNodeAction.class).execute(killAllNodeAction, new TestingRowConsumer(), killPlan);;
         assertThat(broadcastCalls.get(), is(1));
         assertThat(nodeOperationCalls.get(), is(0));
     }
diff --git a/sql/src/test/java/io/crate/testing/IndexEnv.java b/sql/src/test/java/io/crate/testing/IndexEnv.java
index 6e09676..9d7cd2f 100644
--- a/sql/src/test/java/io/crate/testing/IndexEnv.java
+++ b/sql/src/test/java/io/crate/testing/IndexEnv.java
@@ -103,7 +103,7 @@ public final class IndexEnv implements AutoCloseable {
         Environment env = new Environment(nodeSettings, tempDir.resolve("config"));
         IndexSettings idxSettings = IndexSettingsModule.newIndexSettings(index, nodeSettings);
         AnalysisRegistry analysisRegistry = new AnalysisModule(env, Collections.emptyList()).getAnalysisRegistry();
-        IndexAnalyzers indexAnalyzers = analysisRegistry.build(idxSettings);
+        IndexAnalyzers indexAnalyzers = idxSettings.build(analysisRegistry);
         MapperRegistry mapperRegistry = new IndicesModule(Collections.singletonList(new MapperPlugin() {
             @Override
             public Map<String, Mapper.TypeParser> getMappers() {
